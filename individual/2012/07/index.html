<html>
<head>
<link rel="alternate" title="Ocean of Awareness RSS" type="application/rss+xml" title="RSS" href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/index.rss" />
<title>Ocean of Awareness   </title>
<style type="text/css">
   strong {font-weight: 700;}
</style>
</head>
<body>
<div id="header"
  style="color:white;background-color:#38B0C0;padding:1em;clear:left;text-align:center;">
<h1>Ocean of Awareness</h1>
  
</div>
  <div id="menu" style="margin:0;padding:10px;width:150px;float:left;">
  <h2>Jeffrey Kegler's blog</h2>
  <p>About Marpa, his new parsing algorithm,
    and other topics of interest</p>
  <h3>Resources</h3>
  <p><a href="http://www.jeffreykegler.com/">Jeffrey Kegler's website</p>
  <p><a href="http://www.jeffreykegler.com/marpa">The Marpa website</p>
  </div>
  <div id="content" style="margin-left:190px;border-left:2px solid #38B0C0;padding:25px;">
<h3>Tue, 31 Jul 2012</h3>
<br />
<center><a name="rudy-rucker-and-kurt-gdel"> <h2>Rudy Rucker and Kurt Goedel</h2> </a>
</center>
<p>My major interest is in parsing theory.
But,
according to Google Analytics,
most of my web hits are for a side interest.
A few years ago I discovered
the
<a href="http://morgenstern.jeffreykegler.com/">
Lost Morgenstern Document</a>,
an account of 
Kurt G&ouml;del's citizenship hearing which had
gone missing for so long there was doubt it had
ever existed.
Einstein was at the hearing and
Einstein's fame,
plus the fact it's a good yarn,
make the Lost Morgenstern Document
a matter of fairly wide interest.
<p>
This post is about another G&ouml;del document
which recently surfaced.
This document does not make a good yarn.
In fact, in terms of reading difficulty,
it ranges from the moderately hard to the low-grade cryptographic.
But the
<a href="http://www.rudyrucker.com/blog/2012/07/31/conversatons-with-kurt-godel/">
Rucker Notes</a>
are considerably more important
than the Lost Morgenstern Document.
<p>
Rudy Rucker (a well-known sci-fi writer who deserves
to be better known)
talked with G&ouml;del
several times and took notes,
notes which he has just put online.
This is a significant event.
G&ouml;del had unconventional views on a wide range
of topics.
G&ouml;del avoided controversy,
in part out of common sense,
and in part because he suffered from paranoia.
So he avoided publishing unpopular views except
when he had watertight proofs.
But, when talking to Rucker,
G&ouml;del speculated,
and even argued.

<p>
Rucker was almost,
but not quite unique.
Hao Wang talked with G&ouml;del at much greater length,
and Wang's notes remain the best sources for 
the ideas that G&ouml;del would not commit to writing.
But Wang's conversations were restricted by Wang's interests.
<p>
For example, G&ouml;del
had thought a lot about the nature of time.
He'd published a paper on closed timelike curves,
what in a loose sense could be called time travel.
G&ouml;del's result was pioneering.
When G&ouml;del wrote,
professional physicists did not write about time travel.
G&ouml;del made it possible for the topic,
even if it was still somewhat suspect,
to be taken seriously.
Wang, however, was not interested.
Whenever the physics
or philosophy of time
came up,
Wang changed the subject.
<p>
Based on the existence of closed timelike curves
as solutions to the mathematics of relativity,
is the possibility
of time travel to be taken seriously?
If so,
can you travel back and prevent yourself from being born?
Rucker's few pages
are, and will probably remain,
the most direct evidence we have of
G&ouml;del thoughts on these and
a heterogeny of issues.
<br />
<p>posted at: 16:41 |
path: <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/07">/individual/2012/07</a> |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/07/rudy-rucker-and-kurt-gdel.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Thu, 26 Jul 2012</h3>
<br />
<center><a name="prefixing-the-ruby-slippers-and-the-bigfoot-maneuver"> <h2>Prefixing the Ruby Slippers, and the Bigfoot Maneuver</h2> </a>
</center>
<a title="By Frank L Baum (Library of Congress[1]) [Public domain], via Wikimedia Commons" href="http://commons.wikimedia.org/wiki/File%3AGlinda_cover.jpg"><img style="float:left; padding:20px; border-color:White" width="256" alt="Glinda cover" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Glinda_cover.jpg/256px-Glinda_cover.jpg"/></a>
<p>In
<a href="http://blogs.perl.org/users/jeffrey_kegler/2012/07/partial-parsing-and-error-reporting.html">
my last post</a>
I talked about partial parsing of Perl
using my new parsing algorithm,
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>.
This post explains how I do it.
For those interested,
the code for the example in my last post can be found in
<span style="white-space:nowrap; font-family:monospace">t/curly2.t</span>
in
<a href="https://metacpan.org/release/JKEGL/Marpa-R2-2.015_001/">
Marpa::R2 2.015_001</a>
(a developer's version).
For convenience, I've also pulled
<a href="https://gist.github.com/3177276">

<span style="white-space:nowrap; font-family:monospace">t/curly2.t</span>
out as a Github gist</a>.
</p>
<h2>Introducing the problem</h2>
<p>
This technique will work for
languages other than Perl.
In fact, this technique could be used to look for several different
target languages
at once,
for example, when searching a database
of emails that might include code segments
in Perl, HTML, C, etc.
<p>
For clarity, I will often refer to the
Perl and C programs
being sought as targets
in text as "code segments".
In the context of this blog post,
a string is only considered to be a valid
"code segment" if it is also a valid
and complete program.
</p>
<p>
Perl all by itself presents just about every parsing difficulty there is,
and it will work fine for this discussion.
We will search for the "longest first match", which is harder
than most alternatives,
but which is also what applications usually want.
For example,
take the following:
<div style="text-align:center; font-family:monospace">
abcdef ++$a; ++$b; ghijkl
</div>

<p>
Here the null string is the first valid Perl code segment,
and to be pedantic about it,
it is the longest first match.
But zero length Perl code segments are
not of interest to most applications,
so we'll ignore them from here on out.
Ignoring zero-length Perl code segments,
the string "<code class="prettyprint">++$a</code>" is a first match,
but is still not the longest first match.
"<span style="white-space:nowrap; font-family:monospace"> ++$a; ++$b; </span>"
is valid Perl code,
and that is the longest first match.
</p>
<p>
The search can get considerably more complicated.
Consider this code:
<div style="text-align:center; font-family:monospace">
abcdef sub f { ++$a; ++$b; } ghijkl
</div>
<p>
Here
"<span style ="white-space:nowrap; font-family:monospace"> sub f { ++$a; ++$b; } </span>"
is the longest first match, but until the closing curly brace is seen it is not
clear where the longest first match will start, much less end.

</p>
<h2>The Basic Idea</h2>
<p>
We note that no longest first match can start after some other match ends.
That means there are two phases in the search -- one where we should allow
targets to start, and one where we should not.
<p>
Let's assume that,
whenever two different code segments share some of the input tokens,
one contains the other -- that is, if strings
<span style="font-family:monospace">AB</span>
and
<span style="font-family:monospace">BC</span>
are valid code segments, then
<span style="font-family:monospace">ABC</span>
is valid code.
(We'll call this the Overlap Closure Property.)
Our strategy will be to parse in two "modes".
In prefix mode, we track all possible Perl code segments.
Prefix mode ends when the first non-zero length Perl code segment ends.
At that point we know that one of the current candidates must
be the longest first match.
<p>

After prefix mode,
we continue to read tokens,
building all our candidate code segments,
and keeping track of where the most recent one ended.
We do this until either parsing cannot continue,
or we have run out of tokens.
As we'll show more carefully below,
once we can no longer continue parsing,
the Perl code segment that ended most recently will be
the longest first match.
If several end at the same location,
the longest of them will be the longest first match.
<p>
To actually implement this idea,
I'll need to use a series of tricks:
Prefixing, the Ruby Slippers
and the Bigfoot Maneuver.
I'll describe these next,
then I'll put them together as an algorithm.
<p>
The technique I outline in this post
has the advantage that it does not require
rewriting the rules
and symbols of the original, non-partial-parsing, grammar.
New rules and symbols are added "on top of" the original
grammar.
<h2>Prefixing</h2>
<p>
Prefixing is the simplest of the tricks.
As long as it is possible for a longest first match to start,
my Marpa-based Perl parser is in "prefix mode".
Once the end of a non-trivial Perl code segment is seen,
"prefix mode" is turned off.
<p>
Here are rules to define the prefix
<div style="text-align:center; font-family:monospace">
&lt;embedded_perl&gt; ::= &lt;target&gt;<br>

&lt;embedded_perl&gt; ::= &lt;non_perl_prefix&gt; &lt;target&gt;<br>
&lt;non_perl_prefix&gt; ::= &lt;non_perl_token&gt;+
</div>
<p>
The
<span style="font-family:monospace">&lt;target&gt;</span>

symbol represents the longest first match --
the "target" that we are looking for.
The plus sign after
<span style="font-family:monospace">&lt;non_perl_token&gt;</span>
indicates that
<span style="font-family:monospace">&lt;non_perl_prefix&gt;</span>
is a non-zero length sequence of
<span style="font-family:monospace">&lt;non_perl_token&gt;</span>
symbols.
<span style="font-family:monospace">&lt;non_perl_token&gt;</span>'s
are just "aliases"
for the application's normal tokens.
Marpa allows tokens to be ambiguous in this way.
<p>
While prefixing is turned on, every token is read as
both its normal self within the original grammar,
and as a
<span style="font-family:monospace">&lt;non_perl_token&gt;</span>.
Initially, prefixing is turned on.
It will be turned off as described later.
<h2>The Ruby Slippers</h2>

The Ruby Slippers technique, as many of my readers will recall,
is wishful thinking, brought to life and made effective within the world
of parsing.
So, let's ask ourselves, what could we wish for that would make finding
the longest first match easy?
<p>
We close our eyes, click our sanguine heels and wish
that the longest first match had markers in the input,
one at its beginning, and one at its end.
As Glinda gently urges us on,
we add that to our grammar:
<p>
<div style="text-align:center; font-family:monospace">
&lt;target&gt; ::= &lt;target_start_marker&gt; &lt;prog&gt; &lt;target_end_marker&gt;
</div>
<p>
Here <code class="prettyprint">prog</code> is the top level symbol of the Perl grammar --
the original grammar's "start" symbol.

<p>
Recall that in the Ruby Slippers technique, the grammar assumes that the
world is unrealistically easy, orderly, etc.
And the lexer makes the parser's wishes come true.
For the partial Perl parser,
we write the lexer so that, as long as prefixing is on,
whenever the parser wants a
<span style="font-family:monospace">&lt;target_start_marker&gt;</span>,
it gives it one.
<h2>The Bigfoot Maneuver</h2>
<p>
In parsing, the Bigfoot maneuver uses "bigfoot" tokens.
We call them "bigfoot" tokens because,
while we say they're out there,
we never actually encounter one,
and in fact are fortunate not to do so.
<p>
Marpa, at every point, knows which tokens it is expecting.
We can use this feature, along with "bigfoot" tokens, to signal events to the
lexer.
When we want the parser to signal some event to the lexer, we arrange for it
to expect a "bigfoot" token.
Let's look again at this rule:
<div style="text-align:center; font-family:monospace">
&lt;target&gt; ::= &lt;target_start_marker&gt; &lt;prog&gt; &lt;target_end_marker&gt;

</div>
<p>
Here
<span style="font-family:monospace">&lt;target_end_marker&gt;</span>
is a "bigfoot" token.
We won't ever see one, but the fact that the parser is looking
for one will tell us that we have found a Perl
<span style="font-family:monospace">prog</span>.
<p>
We'll use another bigfoot token to deal with
zero-length Perl code segments.
A null string is a legal Perl code segment, but we don't want to count
zero-length code segments as longest first matches.
We could deal with this
by rewriting the Perl grammar slightly,
in order to exclude zero length Perl code segments.
But it is desirable to leave Perl's rules and symbols untouched.
So instead, we introduce another pair of rules
<div style="text-align:center; font-family:monospace">
&lt;target&gt; ::= &lt;target_start_marker&gt; &lt;line&gt; &lt;non_trivial_target_end&gt;<br>

&lt;target&gt; ::= &lt;target_start_marker&gt; &lt;decl&gt; &lt;non_trivial_target_end&gt;<br>
</div>
<p>
<span style="white-space:nowrap; font-family:monospace">&lt;line&gt;</span>
and
<span style="white-space:nowrap; font-family:monospace">&lt;decl&gt;</span>
are two of the original Perl grammar's symbols.

<span style="white-space:nowrap; font-family:monospace">&lt;line&gt;</span>
and
<span style="white-space:nowrap; font-family:monospace">&lt;decl&gt;</span>
are never zero length.
Every Perl
<span style="white-space:nowrap; font-family:monospace">prog</span>
is a sequence of zero or more
<span style="white-space:nowrap; font-family:monospace">&lt;line&gt;</span>'s
and
<span style="white-space:nowrap; font-family:monospace">&lt;decl&gt;</span>'s.
<p>
We define a "non-trivial" Perl code segment as one that contains a
<span style="white-space:nowrap; font-family:monospace">&lt;line&gt;</span>

or a
<span style="white-space:nowrap; font-family:monospace">&lt;decl&gt;</span>.
To signal the lexer that we have found a non-trivial Perl code segment, we use
<span style="white-space:nowrap; font-family:monospace">&lt;non_trivial_target_end&gt;</span>
as a bigfoot token.
<h2>The Strategy</h2>
We can now describe the algorithm.
The program to find all the Perl in an arbitrary text is a loop,
which walks through the input finding one longest first match at a time.
Each search for a longest first match is implemented as a separate parse.
When a longest first match is found, a new search begins at the next token
after the match.
<p>
To find a longest first match,
we start out in prefix mode.
In prefix mode,
every Perl token is read in two ways.
First, it is read
the same way
that it was read in the original Perl grammar.
Second, it is read
as a
<span style="font-family:monospace">&lt;non_perl_token&gt;</span>.
<p>
In addition, as long as we are in prefix mode,
whenever the parser demands a
<span style="font-family:monospace">&lt;target_start_marker&gt;</span>,
we provide it.
This means that while in prefix mode,
we are tracking all possible Perl code segments,
as well as extending the string of

<span style="font-family:monospace">&lt;non_perl_token&gt;</span>'s to
act as the prefix to any new target candidate that we encounter.
Note that the last prefix token -- the one that we read just before we turn prefix mode off --
will be in all of our target candidates.
This is important because it guarantees that they will all overlap.
<p>
When we see that a
<span style="font-family:monospace">&lt;non_trivial_target_end&gt;</span>
bigfoot token is expected,
we turn prefix mode off.
We now have at least one candidate for a target and,
since we are not extending the prefix, we will start no new
target candidates.
For the rest of this parse,
we will only lengthen the already started Perl code segments.
<p>
Whether in prefix mode or not,
every time the parser requests a 
<span style="font-family:monospace">&lt;target_end_marker&gt;</span>
bigfoot token,
we record our location.
We never actually provide a
<span style="font-family:monospace">&lt;target_end_marker&gt;</span>
as input.
Bigfoot tokens are not Ruby Slippers tokens.
This means that rules that have bigfoot tokens are
"virtual" rules in the sense that they will never actually
be completed.
<p>
Parsing ends when it is "exhausted"
or when we run out of tokens.
An "exhausted" parse is one which cannot continue successfully,
although it may have already succeeded.
(In fact, since the partial parser extends the prefix forever
unless a match is found,
in our case an "exhausted" parse MUST be a successful parse.)

<p>
Once parsing ends,
we call the recognizer's
<span style="font-family:monospace">progress()</span>
method to get a list of all the 
<span style="font-family:monospace">prog</span>'s ending
at the last location where we expected a
<span style="font-family:monospace">&lt;target_end_marker&gt;</span>
bigfoot.
The longest of the completed
<span style="font-family:monospace">prog</span> rules
found in our
<span style="font-family:monospace">progress()</span>
report for that last location is our longest first match.
If there is no last location,
we will also have run out of tokens,
and we are done processing the input.
<h2>Other approaches</h2>

<p>
The above approach is not the only way to do partial parsing in Marpa.
In fact, you can do it much more simply using only the Prefixing technique,
along with a similar "Postfixing" technique.
The problem is that this method easily goes cubic (O(n<sup>3</sup>)),
and the worst case
(the one where most or all of the input text is a single Perl code segment)
is also one of practical interest.
The approach outlined above will be linear (O(n)) for all cases of practical interest.
I qualify my assertion by saying "cases of practical interest"
because in fact Perl parsing is, in the general case, undecidable.
<p>
The method outlined in this post could be extended
to deal with languages that do not have
the Overlap Closure Property.
In fact,
it is not completely clear that Perl,
in general,
has the Overlap Closure Property.
The C language does not in general have the Overlap Closure Property,
at least not if the preprocessor is taken into account.
Using the C preprocessor, it would be easy
to construct strings 
<span style="font-family:monospace">X</span>,
<span style="font-family:monospace">Y</span>,
<span style="font-family:monospace">Z</span>
where 
<span style="font-family:monospace">X</span>,
<span style="font-family:monospace">Y</span>,

<span style="font-family:monospace">Z</span>,
<span style="font-family:monospace">XY</span>
and
<span style="font-family:monospace">YZ</span>
are all completely valid C,
but 
<span style="font-family:monospace">XYZ</span>
has a syntax error.
But, for Perl and C code of practical interest,
it is not unreasonable to expect the Overlap Closure Property will hold.
<br />
<p>posted at: 10:11 |
path: <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/07">/individual/2012/07</a> |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/07/prefixing-the-ruby-slippers-and-the-bigfoot-maneuver.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 22 Jul 2012</h3>
<br />
<center><a name="partial-parsing-and-error-reporting"> <h2>Partial parsing and error reporting</h2> </a>
</center>
<blockquote>
"One of the secrets to mathematical problem solving is that one needs to place a high value on partial progress,
as being a crucial stepping stone to fully solving the problem."
-- <a href="https://plus.google.com/u/0/114134834346472219368/posts/Xdm8eiPLWZp">
Terence Tao</a>
</blockquote>
<p>Once an error is found,
a traditional parser is
pretty much lost.
This is true for even
state of the art compilers and interpreters.
One small typo results
in many screens of useless
diagnostics.
If you're an old hand,
you scroll back over these,
knowing that, for the better quality compilers,
the first few lines often have something to
do with the real problem.
With Marpa, we can do better than this.
</p>
<p>
Robust error reporting
is equivalent to the problem of finding code interspersed
among arbitary text.
For example,
consider this mixture of text and Perl fragments.
<code class="prettyprint"><pre>
Note: line:column figures include preceding whitepace
The next line is a perl fragment
{42;{1,2,3;4}}
Code block from 3:5 to 3:13
Code block from 2:33 to 3:14
The next line is a perl fragment
{42;{1,2,3,4}}
Hash from 7:5 to 7:13
Code block from 7:5 to 7:13
Code block from 6:33 to 7:14
The next line is a perl fragment
{42;{;1,2,3;4}}
Code block from 12:5 to 12:14
Code block from 11:33 to 12:15
The next line is a perl fragment
{42;+{1,2,3,4}}
Hash from 16:6 to 16:14
Code block from 15:33 to 16:15
</pre></code>
I have written the prototype of a utility
(<code class="prettyprint">ucurly.pl</code>)
that finds Perl fragments
scattered among other material,
and parses them.
To test the accuracy of the parse,
I have it look for one of Perl's parsing ambiguities ---
anonymous hash constructors that could also be code blocks.
For the example above,
<code class="prettyprint">ucurly.pl</code> finds what there is to be found:

<code class="prettyprint"><pre>
Perl fragment: {42;{1,2,3;4}}
Code block at 3:5 3:13 {1,2,3;4}
Code block at 2:33 3:14 {42;{1,2,3;4}}
Perl fragment: {42;{1,2,3,4}}
Ambiguous Hash at 7:5 7:13 {1,2,3,4}
Ambiguous Code block at 7:5 7:13 {1,2,3,4}
Code block at 6:33 7:14 {42;{1,2,3,4}}
Perl fragment: {42;{;1,2,3;4}}
Code block at 12:5 12:14 {;1,2,3;4}
Code block at 11:33 12:15 {42;{;1,2,3;4}}
Perl fragment: {42;+{1,2,3,4}}
Hash at 16:6 16:14 {1,2,3,4}
Code block at 15:33 16:15 {42;+{1,2,3,4}}
perl tokens = 62; all tokens=267; 23.22%
</pre></code>
<p>
My Marpa-based Perl parser,
as it currently stands,
is a partial Perl parser.
On select problems, it is 100%.
For example,
it understands all of the output from Data::Dumper.
And it scored perfectly in the example in this blog post.
It will parse perhaps 90% of a typical, complex Perl program.
</p>
<p>
At this point in the Marpa-based Perl parser's evolution,
rather than add Perl syntax,
I decided to use it to investigate partial parsing.
Some readers will have observed that "90% coverage"
is a synonym with "useless" in current parsing practice.
That's because traditional parsing algorithms are close to binary.
Traditional parsers only understand input if it is correct or nearly so.
</p>
<p>
When partial parsing is possible,
things are more interesting.
For example, I turned
<code class="prettyprint">ucurly.pl</code>,
my ambiguity-finding utility,
loose on
<a href="http://api.metacpan.org/source/MARKSTOS/CGI.pm-3.59/lib/CGI.pm">
CGI.pm</a>,
a complex bit of Perl code by anyone's standard.
My utility failed to parse a lot of correct Perl code
in CGI.pm,
producing a lot of false negatives.
But this did not prevent it from singling out
line 461:
<code class="prettyprint"><pre>

      @result = map {ref $_ ? $_ : $self->_decode_utf8($_) } @result;
</pre></code>
This line is ambiguous -- the first argument to map
could be either an anonymous hash constructor,
or a code block.
My guess, and I believe, the Perl's parser's guess,
is that it's a code block.
But it'd be nice to have a utility that spots these,
so that all doubt can be removed:
<code class="prettyprint"><pre>
      @result = map { ; ref $_ ? $_ : $self->_decode_utf8($_) } @result;
</pre></code>
<br />
<p>posted at: 19:48 |
path: <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/07">/individual/2012/07</a> |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/07/partial-parsing-and-error-reporting.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 08 Jul 2012</h3>
<br />
<center><a name="two-new-interfaces-to-marpa"> <h2>Two new interfaces to Marpa</h2> </a>
</center>
<blockquote>
"You get to create your own world,
and the only thing that limits what you can do
are the capabilities of the machine --
and, more and more often they days,
your own abiliites"
<cite>Linus Torvalds, <i>Just For Fun</i>, p. 74</cite>
</blockquote>
<p>As of
<a href="https://metacpan.org/release/Marpa-R2">
Marpa::R2 2.010000</a>,
Marpa has two new, documented, interfaces.
(For those new to this blog,
<a href="http://www.jeffreykegler.com/marpa">
Marpa is something new in parsing</a> --
it parses anything you can write in BNF and,
if your grammar is in one of the classes currently in practical use,
parses  it in linear time.
Marpa's parse engine is written in optimized C,
so that Marpa's speed is competitive with parsers of far less power.
Marpa's stable version is
<a href="https://metacpan.org/module/Marpa::XS">
Marpa::XS</a>.)


<h2>Announcing Marpa's C library: Libmarpa</h2>
The first new interface is Libmarpa, a C language library.
Previously, Marpa's only documented interfaces required the
programmer to use it
through Perl.  Using Marpa through Perl had major advantages --
it gave the programmer convenient access not just to Perl's capabiliites,
but to all of CPAN as well.

<p>But there were downsides.
<ul>
<li>
There are other languages besides Perl,
and these have their own advantages
and their own fans.
<li>There was a real cost in efficiency.
Perhaps 90% of the time in the typical Marpa application
was spent running Perl, as opposed to 10% in Marpa's C code.
<li>Finally, making the user interface convenient also meant making choices
for the user.
Not all of the capabilities of
Marpa were available through Marpa::XS and Marpa::R2.
</ul>

With Libmarpa, the programmer has access to the full speed
and flexibility of Marpa's optimized C code.

<h2>Announcing Marpa's "thin" interface: Marpa::R2::Thin</h2>
<p>Together with Libmarpa, I am announcing a "thin" Perl interface to it.
The "thin" interface is a raw interface to Libmarpa.
It's a compromise between the "thick" Marpa::R2 and Marpa::XS
interfaces,
and having to program in C.
The thin interface will be of interest to
<ul>
<li>Programmers creating interfaces to Marpa.  They no longer
have to layer their code on top of Marpa::XS and Marpa::R2.
All interfaces are now equal.

<li>Perl programmers who want direct access to all of
Libmarpa's capabilities.
<li>Programmers in a situation which where lower overhead
justifies extra effort.
</ul>

<h2>The documentation</h2>
If you are new to Marpa, you
do NOT want to head straight to the Libmarpa
and Marpa::R2::Thin documentation.
Instead, I suggest that you look at
<a href="https://metacpan.org/release/Marpa-R2">
the Marpa::R2 documentation</a>,
or
<a href="http://www.jeffreykegler.com/marpa">
the Marpa web page</a>.
The
<a href="https://github.com/downloads/jeffreykegler/Marpa--R2/api-v2.10.0.pdf">
Libmarpa API document</a>
is a reference manual,
which assumes that the user is already familiar with Marpa,
either through Marpa::R2, Marpa::XS or

<a href="https://github.com/downloads/jeffreykegler/Marpa-theory/recce.pdf">Marpa's
theory paper</a>.
Reading
<a href="https://metacpan.org/module/Marpa::R2::Advanced::Thin">
the Marpa::R2::Thin document</a>,
in its turn, requires continual reference back
to the Libmarpa API document.
<br />
<p>posted at: 14:31 |
path: <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/07">/individual/2012/07</a> |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/07/two-new-interfaces-to-marpa.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
</div>
</div>
<div id="footer" style="border-top:thick solid #38B0C0;clear:left;padding:1em;">
<p>This is Ocean of Awareness's
  new home.  This blog has been hosted at
  <a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>
  but I have succumbed to the lure of static blogging.
  I have not yet decided how to deal with comments at this new blog location.
If the post is Marpa-related,
<a href="https://groups.google.com/forum/?hl=en&fromgroups#%21forum/marpa-parser">
the Marpa mailing list</a>
is a good place to comment.
Also,
I will continue to dual-post for some time,
and have not yet frozen comments on the versions of the
post at
<a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>.
</div>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-33430331-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
</body>
</html>
