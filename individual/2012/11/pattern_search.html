<html>
<head>
<link rel="alternate" title="Ocean of Awareness RSS" type="application/rss+xml" title="RSS" href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/index.rss" />
<title>Ocean of Awareness</title>
<style type="text/css">
   strong {font-weight: 700;}
</style>
</head>
<body>
<div
  style="color:white;background-color:#38B0C0;padding:1em;clear:left;text-align:center;">
<h1>Ocean of Awareness</h1>
</div>
  <div style="margin:0;padding:10px 30px 10px 10px;width:150px;float:left;border-right:2px solid #38B0C0">
  <p>
  <strong>Jeffrey Kegler's blog</strong>
  about Marpa, his new parsing algorithm,
    and other topics of interest</p>
  <p><a href="http://www.jeffreykegler.com/">Jeffrey's personal website</a></p>
      <p>
	<a href="https://twitter.com/jeffreykegler" class="twitter-follow-button" data-show-count="false">Follow @jeffreykegler</a>
      </p>
      <p style="text-align:center">
	<!-- Place this code where you want the badge to render. -->
	<a href="//plus.google.com/101567692867247957860?prsrc=3" rel="publisher" style="text-decoration:none;">
	<img src="//ssl.gstatic.com/images/icons/gplus-32.png" alt="Google+" style="border:0;width:32px;height:32px;"/></a>
      </p>
  <h3>Marpa resources</h3>
  <p><a href="http://jeffreykegler.github.com/Marpa-web-site/">The Marpa website</a></p>
  <p>The Ocean of Awareness blog: <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog">home page</a>,
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/chronological.html">chronological index</a>,
  and
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html">annotated index</a>.
  </p>
  </div>
  <div style="margin-left:190px;border-left:2px solid #38B0C0;padding:25px;">
<h3>Sat, 10 Nov 2012</h3>
<br />
<center><a name="pattern_search"> <h2>A Marpa tutorial: Pattern searches</h2> </a>
</center>
  <h3>Pattern searches</h3>
    <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      These days we use regular expression engines for pattern searching.
      And this works beautifully --
      as long as the target pattern is a regular expression.
    </p>
    <p>
      But if what you are searching for is not a regular expression?
      You could approximate with an over-liberal regular expression,
      and sort out any false positives by other means.
      Or you could be out of luck.
    </p>
    <p>
      In this post I will show how to use Marpa to search text files for
      arbitrary context-free expressions.
      As a search target,
      The example I will use will be arithmetic expressions.
    </p>
    <p>
      This tutorial builds on earlier tutorials.
      It is possible to simply dive into it,
      but it may be easier
      to start with earlier posts
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">here</a>
      and
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html">here</a>.
    </p>
    <h3>The grammar</h3>
    <p>
      Even the arithmetic subset of Perl expressions is quite complex,
      but in this case we can get the job done
      with a dozen or so lines of grammar and a table-driven lexer.
      Here is the grammar:
    </p>
    <blockquote>
      <pre>
    <tt>
start ::= prefix target
prefix ::= any_token*
target ::= expression
expression ::=
       number | scalar | scalar postfix_op
    || op_lparen expression op_rparen assoc =&gt; group
    || unop expression
    || expression binop expression`
    </tt>
    </pre>
    </blockquote>
    <p>
      This grammar uses
      <a href="https://metacpan.org/module/Marpa::R2::BNF">
        Marpa::R2's BNF interface</a>.
      It takes considerable advantage of the fact that we are not
      <b>parsing</b>
      these expressions, but
      <b>recognizing</b>
      them.
      Because of this, we don't have to specify whether expressions left- or right-associate.
      We can also ignore what operators mean and group them according to syntax only
      -- binary, prefix unary and postfix unary.
      Similarly, we can ignore the precedence within these large groups.
      This leaves us with numbers, scalars,
      binary, prefix unary and postfix unary operators
      and parentheses.
      (To keep this example simple, this code only deals with Perl scalars.)
    </p>
    <p>
      What we are searching for is defined by the
      <tt>target</tt>
      symbol.
      For
      <tt>target</tt>
      you could substitute any context-free grammar,
      and the technique of this example would still work.
      To turn a parser for
      <tt>target</tt>
      into a pattern searcher, we add a new start
      symbol (unimaginatively named "<tt>start</tt>")
      and two rules that
      allow the target to have a
      <tt>prefix</tt>.
    </p>
    <h3>Ambiguous parsing</h3>
    <p>To do an anchorless pattern search,
      this example will make use of Marpa'a facility with
      ambiguous parsing.
      This grammar always has at least one parse going,
      representing the prefix of zero or more target that it
      will find in the future.
      The prefix will never end, because
      any token (literally
      <tt>any_token</tt>)
      extends it.
    </p>
    <p>
      If we are recognizing a
      <tt>target</tt>,
      we will have one or more other parses going.
      I say "one or more" because using this method a target can be ambiguous.
      In this specific example, the target is not ambiguous,
      so at most two parses will be active:
      one for the prefix and another for the target.
    </p>
    <p>
      Ambiguous parsing has a serious potential downside --
      it is not necessarily efficient.
      But Marpa can parse many types of ambiguous grammar in linear time and,
      grammars in this
      this class of "prefix and unambiguous pattern" are one of them.
      Keeping the prefix going requires a tiny constant overhead per token.
    </p>
    <h3>The lexer table</h3>
    <p>
      The lexer is driven by a table of pairs: token name and regex.
    </p><blockquote>
      <pre>
<tt>
my @lexer_table = (
    [ number     =&gt; qr/(?:\d+(?:\.\d*)?|\.\d+)/xms ],
    [ scalar     =&gt; qr/ [\$] \w+ \b/xms ],
    [ postfix_op =&gt; qr/ [-][-] | [+][+] /xms ],
    [ unop       =&gt; qr/ [-][-] | [+][+] /xms ],
    [   binop =&gt; qr/
          [*][*] | [&gt;][&gt;] | [&lt;][&lt;]
        | [*] | [\/] | [%] | [x] \b
        | [+] | [-] | [&amp;] | [|] | [=] | [,]
    /xms
    ],
    [   unop =&gt; qr/ [-] | [+] | [!] | [~] /xms
    ],
    [ op_lparen =&gt; qr/[(]/xms ],
    [ op_rparen =&gt; qr/[)]/xms ],
);
</tt>
</pre>
    </blockquote>
    <p>
      Order is significant here.
      In particular
      two-character operators are checked for first.
      This guarantees that
      two consecutive minus signs
      will be seen as an
      increment operator, and not as a double negation.
    </p>
    <h3>Ambiguous lexing</h3>
    <p>The very careful reader may have noticed that
      <tt>any_token</tt>
      is not in the lexing table.
      The main loop is written so that every token is read as an
      <tt>any_token</tt>.
      If no token from the lexing table is accepted,
      the next character in the input stream
      is read as an
      <tt>any_token</tt>.
      If a token from the lexing table
      <b>is</b>
      accepted,
      then it gets read twice,
      once as an
      <tt>any_token</tt>,
      and once as the token type taken from the lexing table
      entry.
    </p>
    <p>Ambiguous lexing is a familiar technique to
      the Natural Language Processing community.
      Engish, in particular, is a language that abounds
      in lexemes that can play multiple roles.
      The word "sort", for example, can easily be
      an noun, a verb or an adjective.
    </p>
    <h3>The Ruby Slippers</h3>
    <p>The main loop will also be a simple case of the use
      of the Ruby Slippers.
      For those unfamiliar,
      the "Ruby Slippers" parsing technique handles difficult lexing
      and parsing problems by asking the parser, at the problem point,
      what it is looking for,
      and providing it.
      This seems a fairly obvious approach,
      but the Ruby Slippers are new with Marpa --
      traditional parsers could not easily
      determine where they were in a parse.
    </p>
    <p>
      One way to use the Ruby Slippers is to ask the parser in
      advance what it is looking for.
      The code that follows uses another method.
      Instead of determining in advance what tokens to read,
      it simply feeds them to the parser.
      If the token is rejected, then it tries another one.
      Marpa is 100% accurate about
      what tokens can and cannot result in a successful parse.
      And tokens rejection is a very "soft" error -- it costs
      little to try, and little to retry.
    </p>
    <p>
      In short, in the following code, the way that Marpa
      determine if any entry in the lexing table is appropriate
      is by trying it.
      If the
      <tt>alternative()</tt>
      method returns a Perl
      <tt>undef</tt>
      indicating rejection, then the main loop will try later entries
      in the lexing table.
      If the token is accepted,
      the main loop can assume it is on the right track.
    </p>
    <p>
      My most serious problem in
      developing this technique was convincing myself that
      things could really be this simple.
      So if you are having the same problem,
      I understand.
    </p>
    <h3>The main loop</h3>
    <p>
      The main loop iterates through input looking for tokens.
      Whitespace is skipped.
      Comments are not skipped.
      Finding arithmetic expressions in
      strings and/or comments can be useful.
      We will assume that is the case here.
    </p>
    <p>
      As an example,
      a real problem here is minus signs,
      which can negate a number,
      be a subtraction operation,
      or be part of a decrement operation (postfix or prefix).
      Some of this issue is dealt with by the lexer.
      The order of lexer table puts two-character operators,
      like decrement,
      ("<tt>--</tt>")
      before one-character operators,
      such as negation
      ("<tt>-</tt>").
    </p><p>In this lexer, an initial minus sign is never part of a number.
      A number constant is always positive, though it may have
      a unary negation operator in front of it.
      PPI sometimes includes initial minus signs in numeric
      constants. Unfortunately, lacking the Ruby Slippers,
      it will do this in cases where the minus
      sign is actually a binary operator.
    </p>
    <p>
      The
      <tt>FIND_ALTERNATIVE</tt>
      loop is short,
      but worth a careful look.
      It tries every lexeme, in lexer table order.
      If the
      <tt>alternative()</tt>
      method
      returns a Perl
      <tt>undef</tt>,
      it means the token was "rejected".
      This means the parser was not expecting it.
    </p>
    <p>
      This means that Marpa knows whether a minus sign can be
      a unary or binary operator.
      (Because of Perl's grammar, it can be one or the other,
      but never both in the same position.)
      This is the Ruby Slippers in action --
      a very simple solution to what for
      <tt>perly.y</tt>
      and PPI is a very complicated problem.
    </p>
    <p>
      Once the right token has been determined, the
      <tt>alternative()</tt>
      method is called again to
      ready in an
      <tt>any_token</tt>.
      (Marpa allows ambiguous lexing --
      the same character can be read as two different
      tokens.)
      If the entire lexer table is tried, and no acceptable
      lexeme is found,
      a single character is read as an
      <tt>any_token</tt>.
    </p>
    <blockquote>
      <pre>
<tt>
my $length = length $string;
pos $string = $positions[-1];
TOKEN: while ( pos $string &lt; $length ) {
    next TOKEN if $string =~ m/\G\s+/gcxms;    # skip whitespace
    my $position = pos $string;
    FIND_ALTERNATIVE: {
        TOKEN_TYPE: for my $t (@lexer_table) {
            my ( $token_name, $regex ) = @{$t};
            next TOKEN_TYPE if not $string =~ m/\G($regex)/gcxms;
            if ( not defined $recce-&gt;alternative($token_name) ) {
                pos $string = $position;       # reset position for matching
                next TOKEN_TYPE;
            }
            $recce-&gt;alternative('any_token');
            last FIND_ALTERNATIVE;
        } ## end TOKEN_TYPE: for my $t (@lexer_table)
        ## Nothing in the lexer table matched
        ## Just read the currrent character as an 'any_token'
        pos $string = $position + 1;
        $recce-&gt;alternative('any_token');
    } ## end FIND_ALTERNATIVE:
    $recce-&gt;earleme_complete();
    my $latest_earley_set_ID = $recce-&gt;latest_earley_set();
    $positions[$latest_earley_set_ID] = pos $string;
} ## end TOKEN: while ( pos $string &lt; $length )
</tt>
</pre>
    </blockquote>
    <p>
      The
      <tt>earleme_complete()</tt>
      method tells Marpa that all the alternatives
      for that location have been entered.
      (Marpa's idea of location is called an "earleme", in honor of the great
      parsing theorist, Jay Earley.)
    </p>
    <h3>How to parse without really trying</h3>
    <h3>Finding the targets</h3>
    <p>
      Once the parse is complete, it remains to find
      and print the "targets" found
      by the search.
      In a previous post,
      I showed how, for error reporting, to find the last symbol found,
      given a symbol name.
      That routine needs to be modified to allow repeated searches.
      The code is in the gist,
      and was explained in the previous post,
      so I won't repeat here.
    </p>
    <h3>Pattern searching and incremental development</h3>
    <p>
      You may notice that this pattern searcher is also
      a start on a Perl parser.
      A first priority would have to be restoring proper associativity
      and precedence to the expressions.
      This can be done by copying the
      table at the beginning of the perlop man page
      into the precedence statement in the grammar.
      My first draft of this post broke the operators out
      by precedence
      and gave them the correct associativity,
      but they are unnecessary for pattern recognition,
      and were discarded to keep things simple.
    </p>
    <p>
      From this start, you would adding more and more syntax to the grammar,
      and more and more recognition to the lexer.
      As you expanded the pattern searcher, the target would gradually become
      closer and closer to the entire language.
    </p>
    <p>
      When, for all valid input files, your pattern searcher always finds
      a single match that spans the input file, you can remove rules which
      parse the prefix, and make
      <tt>target</tt>
      the new start symbol.
      Or you may wish to keep them, as an aid to error reporting.
      Either way, your parser is finished.
      My own experience is that parsers are far easier
      to write
      if you can build them incrementally,
      taking advantage of the kind of feedback that Marpa allows.
    </p>
    <h3>Code and comments</h3>
    <p>The example in this post is available as
      a giithub gist.
      It was run with Marpa::R2 2.024000,
      as of this writing the latest full release,
      and tested with the displays from the
      <a href="http://perldoc.perl.org/perlop.html">perlop man page</a>.
    </p><p>
    </p><p>
      Comments can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 19:35 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
</div>
</div>
<div id="footer" style="border-top:thick solid #38B0C0;clear:left;padding:1em;">
<p>This is Ocean of Awareness's
  new home.  This blog has been hosted at
  <a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>
  but I have succumbed to the lure of static blogging.
  I have not yet decided how to deal with comments at this new blog location.
If the post is Marpa-related,
<a href="https://groups.google.com/forum/?hl=en&fromgroups#%21forum/marpa-parser">
the Marpa mailing list</a>
is a good place to comment.
Also,
I will continue to dual-post for some time,
and have not yet frozen comments on the versions of the
post at
<a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>.
</div>
	<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-33430331-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
</body></html>
