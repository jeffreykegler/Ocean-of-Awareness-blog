<html>
<head>
<link rel="alternate" title="Ocean of Awareness RSS" type="application/rss+xml" title="RSS" href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/index.rss" />
<title>Ocean of Awareness</title>
<style type="text/css">
   strong {font-weight: 700;}
</style>
</head>
<body>
<div
  style="color:white;background-color:#38B0C0;padding:1em;clear:left;text-align:center;">
<h1>Ocean of Awareness</h1>
</div>
  <div style="margin:0;padding:10px 30px 10px 10px;width:150px;float:left;border-right:2px solid #38B0C0">
  <p>
  <strong>Jeffrey Kegler's blog</strong>
  about Marpa, his new parsing algorithm,
    and other topics of interest</p>
  <p><a href="http://www.jeffreykegler.com/">Jeffrey's personal website</a></p>
      <p>
	<a href="https://twitter.com/jeffreykegler" class="twitter-follow-button" data-show-count="false">Follow @jeffreykegler</a>
      </p>
      <p style="text-align:center">
	<!-- Place this code where you want the badge to render. -->
	<a href="//plus.google.com/101567692867247957860?prsrc=3" rel="publisher" style="text-decoration:none;">
	<img src="//ssl.gstatic.com/images/icons/gplus-32.png" alt="Google+" style="border:0;width:32px;height:32px;"/></a>
      </p>
  <h3>Marpa resources</h3>
  <p><a href="http://jeffreykegler.github.com/Marpa-web-site/">The Marpa website</a></p>
  <p>The Ocean of Awareness blog: <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog">home page</a>,
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/chronological.html">chronological index</a>,
  and
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html">annotated index</a>.
  </p>
  </div>
  <div style="margin-left:190px;border-left:2px solid #38B0C0;padding:25px;">
<h3>Sun, 07 Sep 2014</h3>
<br />
<center><a name="chron"> <h2>A timeline of parsing</h2> </a>
</center>
<html>
  <head>
  </head>
  <body><p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
    </p>
    <p><b>1960</b>:
      The ALGOL 60 spec comes out.
      It specifies, for the first time, a block structured
      language.
      The ALGOL committee is well aware
      that
      nobody knows how to parse such a language.
      But they believe that if they specify a block-structured
      language, a parser for it will be invented.
      Risky as this approach is, it pays off ...
    </p>
    <p><b>1961</b>: Ned Irons publishes his ALGOL parser.
      In fact, the Irons parser
      is the first parser of any kind to be described
      in print.
      Ned's algorithm was a form of recursive descent,
      but unlike modern
      recursive descent,
      the Irons algorithm
      is general and syntax-driven.
      "General" means it can parse anything written in BNF.
      "Syntax-driven" (aka declarative) means that parser is
      actually created from the BNF -- an Irons parser does not need
      to be hand-written.
    </p>
    <p><b>1961</b>:
      Almost simultaneously hand-coded approaches to left parsing
      appeared.
      These algorithms were we would now call recursive descent.
      Over the following years, hand-coding emerged as more popular
      than syntax-driven algorithms like Irons 1961,
      for perhaps three reasons.
      <ul>
      <li>
      In the 1960's memory and CPU were both extremely limited,
      so that hand-coding to achieve even small savings made practical sense.
      <li>
      Pure left parsing is a very weak parsing technique --
      to overcome its limits,
      hand-coding is almost a necessity, something
      that is as as true today as it was in 1961.
      <li>
      Left parsing and hand-coding do fit together well.
      </ul>
    </p>
    <p><b>1965</b>: Don Knuth invents LR parsing.
      Knuth is primarily interested
      in the mathematics.
      He describes a parsing algorithm,
      but it is not thought practical.
    </p>
    <p><b>1968</b>: Jay Earley invents the algorithm named after him.
      Like the Irons algorithm,
      Earley's algorithm is syntax-driven and fully general.
      Unlike the Irons algorithm, it does not backtrack.
      Earley's core idea was to
      track everything about the parse in tables.
      Earley's algorithm is enticing, but it has three major issues:
      <ul>
      <li>First, there is a bug in the handling of zero-length rules.
      <li>Second, it is quadratic for right recursions.
      <li>Third, the bookkeeping required to set up the tables is,
      by the standards of 1968 hardware, daunting.
      </ul>
    <p><b>1969</b>:
      a PhD thesis by Frank DeRemer described a new variant of Knuth's LR
      parsing.
      DeRemer's LALR algorithm requires only
      a stack and a state table of quite
      manageable size.
    </p>
    <p><b>1972</b>:
      Aho and Ullmann describe
      a straightforward fix to the zero-length rule bug in Earley's original algorithm.
      Unfortunately, this fix involves adding even more bookkeeping to Earley's.
    <p><b>1975</b>:
      Bell Labs converts its C compiler from hand-written recursive
      descent to DeRemer's LALR algorithm.
    </p>
    <p><b>1977</b>:
      The first "Dragon book" comes out.
      The nickname of this classic textbooks comes from the drawing
      on the front cover, in which a knight takes on a dragon.
      Emblazoned on his lance are the letters "LALR".
      And indeed, by this point,
      to speak lightly of LALR is to besmirch the escutcheon
      of parsing theory.
    </p>
    <p><b>1987</b>:
    If you want to date the high point of LALR's reign,
    this might be the right year.
      It is the year that
      Larry Wall introduced Perl 1.
      Perl embraced complexity like no previous language,
      and to do it, Larry used LALR very aggressively --
      to my knowledge more aggressively than anyone before
      or since.
    </p>
    <p><b>1991</b>:
      Joop Leo discovers a way of speeding up right
      recursions in Earley's algorithm.
      This is a major discovery.
      Leo's algorithm
      is linear for just about every unambiguous grammar of
      practical interest, and many ambiguous ones as well.
      And in 1991 hardware was six orders of magnitude faster
      than 1968 hardware, so that the
      issue of bookkeeping overhead had receded
      in importance.
      When it comes to the speed,
      the game has changed, and very much in the Earley algorithm's
      favor.
      But when Leo publishes, Earley parsing has been forgotten by most.
      It takes 20 years for anyone to write a practical
      implementation of Leo's algorithm.
    </p>
    <p><b>1990's</b>:
      So, since Earley's is forgotten, everyone in
      LALR-land is content.  Right?
      Wrong. Far from it, in fact.
      Users of LALR had made some nasty discoveries about it.
      While LALR does automatically
      generates a parser for you,
      it is so hard to debug that it's
      usually just as easy to write one by hand.
      Once written, an LALR parser is fast for correct inputs.
      But almost all it can tell the users about incorrect inputs,
      is that they are incorrect --
      the LALR tables provide little clue as to why.
      In Larry's words, LALR was "fast but stupid".
    </p><b>2000</b>:
    Larry Wall decides on a radical reimplementation
      of Perl -- Perl 6.
      Larry does not even consider using LALR again.
    </p>
    <p><b>2002</b>:
      Aycock&Horspool publish their attempt to speed up Earley's in practice.
      They do not include Joop Leo's improvement --
      they seem not to be aware of it.
      Their own speedup is limited in what it achieves
      and introduces complications.
      But buried in their paper is a solution to the zero-length rule bug --
      and this time it is a solution that requires no additional bookkeeping.
    </p>
    <p><b>2006</b>:
      For three decades,
      the industry's flagship C compilers had been
      parsed with LALR --
      proof of the claim that LALR and serious
      parsing were equivalent.
      But in 2006,
      GNU announces that the GCC compiler's parser has been rewritten.
      LALR's replacement is the technology that
      it replaced a quarter century earlier:
      recursive descent.
    </p>
    <p><b>2000 to today</b>:
    With the retreat from LALR comes a collapse in the
      prestige of parsing theory.
      After a half century of
      research, it looks as if we wound up almost
      exactly where we started.
      In fact,
      if you took Ned Iron's original 1961 algorithm,
      changed the names and dates,
      and translated from code from the mix of assembler and
      ALGOL into Haskell,
      you would easily republish it today,
      billing it as 
      as a revolutionary new approach to parsing.
    </p>
    <p>
    <h3>Marpa</h3>
      Over the years, I'd come back to Earley's algorithm again and again.
      Around 2010, I realized
      that the original, long-abandoned vision --
      an efficient, practical, general and syntax-driven parser --
      was now, in fact, quite possible.
      Over the years,
      the necessary pieces had fallen into place.
    </p>
    <p>
      Aycock&Hospool has solved the zero-length rule bug.
      Joop Leo had found the speedup for right recursion.
      And the issue of bookkeeping overhead had pretty much evaporated on its
      own.
      Machines operations are now a billion times faster than in 1968,
      and probably no longer relevant in any case --
      caches misses are more important.
    </p>
    <p>But while the original issues with Earley's disappeared,
      a new issue emerged.
      With a parsing algorithm as powerful as Earley's behind it,
      a syntax-driven approach can do much more than it can with
      a left parser.
      But with the experience with LALR in their collective consciousness,
      few modern programmers are prepared
      to trust a purely declarative parser.
      As Lincoln said, "Once a cat's been burned,
      he won't even sit on a cold stove."
    </p>
    <p>
      In the process of combining
      the improvements from Aycock&Horspool and Leo,
      I found that the Earley's parse engine can be written so
      that it's easy to pause at any token.
      While paused,
      the application can switch to procedural logic
      and single-step forward token by token.
      The procedural logic can hand control back
      over to syntax-driven parsing at any point it likes.
      Earley's algorithm is actually a even better companion
      for hand-written procedural logic than recursive descent is.
      The Earley tables can provide the procedural logic with
      full knowledge of the state of the
      parse so far:
      all rules recognized
      in all possible parses so far,
      and all symbols expected.
    </p>
    <h3>For more</h3>
    <p>
      For more about Marpa,
      there's
      <a href=http://savage.net.au/Marpa.html">the
      official web site maintained by Ron Savage</a>:
      I also have
      <a href="http://jeffreykegler.github.io/Marpa-web-site/">a Marpa web site</a>.
      Comments on this post can be made in
      <a href="http://groups.google.com/group/marpa-parser">
        Marpa's Google group</a>.
    </p>
  </body>
</html>
<br />
<p>posted at: 16:50 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2014/09/chron.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
</div>
</div>
<div id="footer" style="border-top:thick solid #38B0C0;clear:left;padding:1em;">
<p>This is Ocean of Awareness's
  new home.  This blog has been hosted at
  <a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>
  but I have succumbed to the lure of static blogging.
</div>
	<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-33430331-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
</body></html>
