<html>
<head>
<link rel="alternate" title="Ocean of Awareness RSS" type="application/rss+xml" title="RSS" href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/index.rss" />
<title>Parsing languages versus parsing grammars</title>
<style type="text/css">
   strong {font-weight: 700;}
</style>
</head>
<body>
<div
  style="color:white;background-color:#38B0C0;padding:1em;clear:left;text-align:center;">
<h1>Ocean of Awareness</h1>
</div>
  <div style="margin:0;padding:10px 30px 10px 10px;width:150px;float:left;border-right:2px solid #38B0C0">
  <p>
  <strong>Jeffrey Kegler's blog</strong>
  about Marpa, his new parsing algorithm,
    and other topics of interest</p>
  <p><a href="http://www.jeffreykegler.com/">Jeffrey's personal website</a></p>
      <p>
	<a href="https://twitter.com/jeffreykegler" class="twitter-follow-button" data-show-count="false">Follow @jeffreykegler</a>
      </p>
      <p style="text-align:center">
	<!-- Place this code where you want the badge to render. -->
	<a href="//plus.google.com/101567692867247957860?prsrc=3" rel="publisher" style="text-decoration:none;">
	<img src="//ssl.gstatic.com/images/icons/gplus-32.png" alt="Google+" style="border:0;width:32px;height:32px;"/></a>
      </p>
  <h3>Marpa resources</h3>
  <p><a href="http://jeffreykegler.github.com/Marpa-web-site/">The Marpa website</a></p>
  <p>The Ocean of Awareness blog: <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog">home page</a>,
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/chronological.html">chronological index</a>,
  and
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html">annotated index</a>.
  </p>
  </div>
  <div style="margin-left:190px;border-left:2px solid #38B0C0;padding:25px;">
<h3>Fri, 25 May 2018</h3>
<br />
<center><a name="chomsky_1956"> <h2>Parsing languages versus parsing grammars</h2> </a>
</center>
<html>
  <head>
  </head>
  <body>
    <blockquote>
	But to my mind, though I am native here<br>
	And to the manner born, it is a custom<br>
	More honorâ€™d in the breach than the observance.<a id="footnote-1-ref" href="#footnote-1">[1]</a>
    </blockquote>
    <h2>Chomsky's "Three Models" paper</h2>
    <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      Important papers produce important mistakes.
      A paper can contain a great many errors,
      and they will have no effect if the paper is ignored.
      On the other hand,
      even the good methods of
      a great paper can go badly wrong
      when its methods
      outlive the reasons for using them.
    </p>
    <p>
      Chomsky's "Three Models" paper<a id="footnote-2-ref" href="#footnote-2">[2]</a>
      is about as influential
      as a paper can get.
      Just 12 pages,
      it's the paper in which the most-cited scholar of our
      time first outlined his ideas.
      It transformed linguistics,
      and is one of the most important scientific papers ever.<a id="footnote-3-ref" href="#footnote-3">[3]</a>
      [ TODO: Work on this graf. ]
    </p>
    <p>
      Given its significance,
      it is almost incidental that
      "Three models" is also the foundation paper of computer Parsing Theory,
      the subject of these blog posts.
      Chomsky does not consider himself a computer scientist
      and, after founding our field,
      has paid little attention to it.
      But in fact,
      the Chomskyan model has been more dominant
      in computer parsing than in Chomsky's own
      field of linguistics.
    </p>
    <p>
      "Three Models" also places Chomksy among the great mathematicians
      of all time.
      True, the elegance and rigor of Chomsky's proofs
      better befit a slumming linguist
      than they would a professional mathematician.
      But at its heart,
      mathematics is not a technical field,
      or even about problem-solving --
      at its most fundamental,
      it is about framing problems so that they
      <b>can</b> be solved.
      And Chomsky's skill at framing problems is astonishing.
    </p>
    <h2>A brilliant simplification</h2>
    <p>
      In 1956,
      Chomsky had a new approach to linguistics,
      and needed to prove that his approach to language
      did things that
      the previous approach,
      based on finite-state models,
      could not.
      ("Finite-state" models, also known as Markov chains,
      are the predecessors of the regular expressions
      of today.)
      Brilliantly,
      Chomsky sets out to do this with extremely minimal definition of what
      a language is.
    </p>
    <blockquote>
      By a language then, we shall mean a set (finite or infinite) of
      sentences, each of finite length, all constructed from a finite
      alphabet of sysbols.  If A is an alphabet, we shall say that
      anything formed by concatenating ths symbols of A is a string in
      A. By a grammar of the language L we mean a device of some sort that
      produces all of the strings that are sentences of L and only these.<a id="footnote-4-ref" href="#footnote-4">[4]</a>
    </blockquote>
    <p>Yes, you read that right --
    Chomsky uses a definition of language which has nothing to
    do with language actually meaning anything.
    A language, for the purposes of the math in "Three Models",
    is nothing but a list of strings.
    Similarly, a grammar is just something that enumerates
    those strings.
    The grammar does not have to provide any clue as to what
    the strings might mean.
    </p>
    <p>
        For example, Chomsky would require of a French grammar that one of the
	strings that it lists be
    </p>
    <blockquote>
      (42) Ceci n'est pas une phrase vraie.
    </blockquote>
    <p>But for the purposes of his demonstration,
    Chomsky does not require of his "grammar" that it
    give us any guidance as to what sentence (42) might mean.
    <p>
    </p>
    In addition to simplifying the math, Chomsky has two other good
    reasons to avoid dealing with meaning.
    A second reason is that
    semantics is treacherously dangerous field of study.
    If you can make your point,
    and don't have to drag in semantics,
    you are crazy to do otherwise.
    Sentence (42), above,
    is just one example of the pitfalls
    that await those tackle who semantic issues.
    It echoes
    <a href="https://en.wikipedia.org/wiki/The_Treachery_of_Images">a famous Magritte<a>
    and translates to "This is not a true sentence".
    </p>
    <p>
    A third reason is that most linguists of Chomsky's time
    were Bloomfieldians.
    Bloomfield defined language as follows:
    </p>
    <blockquote>
    The totality of utterances that can be made in a speech
    community is the <b>language</b>
    of that speech-community.<a id="footnote-5-ref" href="#footnote-5">[5]</a>
    </blockquote>
    <p>
    Bloomfield says "totality" instead of "set"
    and "utterances" instead of "strings",
    but for our purposes in this post the idea is the same --
    the definition is without regard to the meaning
    of the members of the set.
    </p>
    <p>
    Bloomfield's omission of semantics is not accidental.
    Bloomfield wanted to establish linguistics as a
    science, and for Bloomfield
    claiming to know the meaning of
    a sentence was dangerously close to
    claiming to be able to read minds.
    You cannot base a field on mind-reading and expect people to
    believe that you are doing science,
    and Bloomfield therefore suggested avoiding,
    totally if possible,
    any discussion of semantics.<a id="footnote-6-ref" href="#footnote-6">[6]</a>
    Most readers of Chomsky's paper in 1956 were Bloomfieldians --
    Chomsky has studied under a Bloomfieldian,
    and originally was seen as one.<a id="footnote-7-ref" href="#footnote-7">[7]</a>
    By excluding semantics from his own model of language,
    Chomsky was making his paper maximally acceptable to
    his readership.
    </p>
    <p>
    You did not have to read Chomsky's mind,
    or predict the future,
    to see that Chomsky
    would get beyond the "set of strings" point of view
    to become a lot more interested in semantics than
    Bloomfield was.
    Already in "Three Models",
    he is suggesting that his model is superior to
    its predecessors,
    because his model,
    when an utterance is ambiguous,
    produces multiple derivations to reflect that.<a id="footnote-8-ref" href="#footnote-8">[8]</a>
    </p>
    <h2>The tradition</h2>
    <p>Given the immense prestige of "Three models",
    it is unsurprising, if unfortunate that the Bloomfield definition of language
    reappears in Chomsky's successors
    within Parsing Theory.
    </p>
    <blockquote>
    A language over an alphabet &Sigma;
    is a set of strings over an alphabet &Sigma;.
    This definition encompasses almost everyone's notion of a language.<a id="footnote-9-ref" href="#footnote-9">[9]</a>
    </blockquote>
    If this "encompasses" this blogger's notion of a language,
    it does so only in the sense that an avalanche encompasses
    a skier.
    </p>
    <p>
    From 1988, thirty years after Chomsky,
    here is another authoritative textbook of Parsing Theory
    defining "language":
    </p>
    <blockquote>
      A set V is an alphabet (or a vocabulary) if it is finite and
      nonempty.
      The elements
      of an alphabet V are called the symbols (or letters or characters) of
      V
      A language L over V is any subset of the free monoid V*.
      The elements
      of a language L are called sentences of L.<a id="footnote-10-ref" href="#footnote-10">[10]</a>
    </blockquote>
    <p>The language is now that of abstract algebra,
    but it is easy to see that the idea is still pure Bloomfield.<a id="footnote-11-ref" href="#footnote-11">[11]</a>
    <h2>A pedantic point?</h2>
    <p>Interesting, you might be saying, that
    some textbook definitions are not everything they could be,
    but is there any effect in the daily practice of
    programming?
    </p>
    <p>
    Consider.
    The languages human beings use with each other 
    are powerful,
    varied, flexible and endlessly retargetable.
    The parsers we use to communicate with computers
    are restrictive, repetitive in form,
    difficult to reprogram,
    and prohibitively hard to retarget.
    Is this because humans have a preternatural language ability?
    </p>
    <p>
    Or is there something wrong with the way we
    go about talking to computers?
    How the Theory of Parsing literature defines the term
    "language" may seem 
    of only pedantic interest.
    But I will argue that it is a mistake which has everything
    to do with the limits of modern computer languages.
    <h2>The problem</h2>
    <p>
    What is the problem with defining a language as a set of strings?
    I have already described the sorry state of Parsing Theory
    <a href="https://jeffreykegler.github.io/personal/timeline_v3#bib-Aho_and_Ullman_1972">
    elsewhere</a>.
    The tale told there is from a slightly point of view,
    but no reader of it will be completely surprised by how I
    develop this point.
    But here is a hint of how I tie the textbook definition
    to daily practice.
    </p>
    <p>
    Here are two grammars,
    call them <tt>STRUCTURE</tt> and
    and <tt>STRING</tt>.
    </p>
    <pre id="g-structure-op"><tt>
      STRUCTURE ::= E
      E ::= E + T
      E ::= T
      T ::= T * P
      T ::= P
      P ::= number
    </tt></pre>
    <pre id="g-string-op"><tt>
      STRING ::= E
      E ::= P OP E
      OP ::= '*'
      OP ::= '+'
      P ::= number
    </tt></pre>
    Both
    <tt>STRUCTURE</tt>
    and <tt>STRING</tt>
    recognize the same set of strings.
    But if the intended meaning of the two grammars is
    that of traditional arithmetic expressions,
    the two grammars are very different
    in the degree to which they capture it.
    <tt>STRUCTURE</tt>.
    recognizes the associativity and precedence of the two operators --
    the parse tree it produces could be used directly to evaluate an arithmetic
    expression and the answer would always be correct.
    The parse tree that <tt>STRING</tt> produces, if evaluated directly,
    will very often produce a wrong answer -- it does not capture
    the structure of an arithmetic expression.
    In order to produce correct results,
    the output of <tt>STRING</tt> could be put through a second phase,
    but that is the point --
    <tt>STRING</tt> left crucial parts of the job of parsing undone,
    and either some other logic does the job <tt>STRING</tt> did not do,
    or a wrong answer results.
    <h2>Comments, etc.</h2>
    <p>
      The background material for this post is in my
    <a href="https://jeffreykegler.github.io/personal/timeline_v3#bib-Aho_and_Ullman_1972">
    Parsing: a timeline 3.0</a>,
    and this post may be considered a supplement to "Timelime".
      To learn about Marpa,
      my Earley/Leo-based parsing project,
      there is the
      <a href="http://savage.net.au/Marpa.html">semi-official web site, maintained by Ron Savage</a>.
      The official, but more limited, Marpa website
      <a href="http://jeffreykegler.github.io/Marpa-web-site/">is my personal one</a>.
      Comments on this post can be made in
      <a href="http://groups.google.com/group/marpa-parser">
        Marpa's Google group</a>,
      or on our IRC channel: #marpa at freenode.net.
    </p>
    <h2>Footnotes</h2>
<p id="footnote-1">1.
	<cite>Hamlet</cite>, Act I, scene iv.
 <a href="#footnote-1-ref">&#8617;</a></p>
<p id="footnote-2">2.
      Chomsky, Noam.
      "Three models for the description of language."
      <cite>IRE Transactions on information theory</cite>,
      vol. 2, issue 3, September 1956, pp. 113-124.
 <a href="#footnote-2-ref">&#8617;</a></p>
<p id="footnote-3">3.
      In this post I am calling the "Three models" paper the "first"
      work of Chomskyan linguistics.
      Other choices can be justified.
      The next year, 1957,
      Chomsky published a book covering the same material: <cite>Syntactic Structures</cite>.
      <cite>Syntactic Structures</cite>
      was much more accessible,
      and attracted much more attention,
      and the Chomskyan revolution did not really begin before
      it came out.
      On the other hand,
      both of these draw their material from Chomsky's
      1000-page
      <cite>Logical Structure of Linguistic Theory</cite>,
      which was completed in June 1955.
      But <cite>Logical Structure of Linguistic Theory</cite>,
      was not published until 1975
      and then only in part.
      (See
      <a href="https://www.journals.uchicago.edu/doi/full/10.1086/686177">
      Radick, Gregory,
      "The Unmaking of a Modern Synthesis: Noam Chomsky, Charles Hockett, and the Politics of Behaviorism, 1955â€“1965"
      </a>.)
 <a href="#footnote-3-ref">&#8617;</a></p>
<p id="footnote-4">4.
      Chomsky 1956, p. 114.
 <a href="#footnote-4-ref">&#8617;</a></p>
<p id="footnote-5">5.
    Bloomfield, Leonard,
    "A set of Postulates
    for the Science of Language",
    <cite>Language</cite>, Vol. 2, No. 3 (Sep., 1926), pp. 153-164.
    The quote is definition 4 on p. 154.
 <a href="#footnote-5-ref">&#8617;</a></p>
<p id="footnote-6">6.
    "The statement of meanings is therefore the weak point in
    language-study, and will remain so until human knowledge 
    advances very far beyond its present state. In practice, we define the
    meaning of a linguistic form, wherever we can, in terms of some
    other science."
    Bloomfield, Leonard.
    <cite>Language</cite>.
    Holt, Rinehart and Winston, 1933, p. 140.
 <a href="#footnote-6-ref">&#8617;</a></p>
<p id="footnote-7">7.
    Harris, Randy Allen,
    <cite>The Linguistics Wars</cite>,
    Oxford University Press, 1993,
    pp 31-34.
 <a href="#footnote-7-ref">&#8617;</a></p>
<p id="footnote-8">8.
    Chomsky 1956, p. 118, p. 123.
 <a href="#footnote-8-ref">&#8617;</a></p>
<p id="footnote-9">9.
    Aho, Alfred V., and Jeffrey D. Ullman.
    <cite>The theory of parsing, translation, and compiling</cite>.
    Vol. 1. Prentice-Hall, 1972, p. 16.
 <a href="#footnote-9-ref">&#8617;</a></p>
<p id="footnote-10">10.
      Sippu, Seppo and Soisalon-Soininen, Eljas.
      <cite>Parsing Theory</cite>, Volume I,
      Springer-Verlag, 1988,
      p. 11.
 <a href="#footnote-10-ref">&#8617;</a></p>
<p id="footnote-11">11.
    A welcome errancy from tradition, however, arrives with
    Grune, D. and Jacobs, C. J. H., <cite>Parsing Techniques: A Practical Guide</cite>, 2nd edition. Springer, 2008.
    On pp. 5-7, they attribute the traditional "set of strings" definition
    to "formal linguistics".
    They
    point out that the computer scientist requires a grammar to
    not only list a set of strings, but provide a
    "structure" for each of them.
    As an aside,
    Grune and Jacobs often depart from the "just stick to the math"
    approach to parsing theory,
    and give the history and motivation behind the math.
    My own work owes much to them.
 <a href="#footnote-11-ref">&#8617;</a></p>
  </body>
</html>
<br />
<p>posted at: 15:31 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2018/05/chomsky_1956.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
</div>
</div>
<div id="footer" style="border-top:thick solid #38B0C0;clear:left;padding:1em;">
<p>This is Ocean of Awareness's
  new home.  This blog has been hosted at
  <a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>
  but I have succumbed to the lure of static blogging.
</div>
	<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-33430331-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
</body></html>
