<?xml version="1.0"?>
<!-- name="generator" content="blosxom/2.0" -->
<!DOCTYPE rss PUBLIC "-//Netscape Communications//DTD RSS 0.91//EN" "http://my.netscape.com/publish/formats/rss-0.91.dtd">

<rss version="0.91">
  <channel>
    <title>Ocean of Awareness   </title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog</link>
    <description>Ocean of Awareness.</description>
    <language>en</language>

  <item>
    <title>Announcing Marpa::XS</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/2011/04/17#announcing-marpaxs</link>
    <description>&lt;p&gt;
I have released
&lt;a href=&quot;http://search.cpan.org/~jkegl/Marpa-XS-0.002000/&quot;&gt;
the first non-developer's version of Marpa::XS:
0.002000&lt;/a&gt;.
Marpa::XS is the XS-accelerated version of
&lt;a href=&quot;http://search.cpan.org/dist/Marpa/&quot;&gt;
Marpa&lt;/a&gt;.
Marpa is a parser generator -- it parses from any
grammar that you can write in BNF.
If that grammar is one of the kinds in practical use
(&lt;kbd&gt;yacc&lt;/kbd&gt;, LALR, recursive descent, LR(k), LL(k), regular expressions, etc.),
Marpa and Marpa::XS parse from it in linear (O(n)) time.
&lt;ul&gt;
&lt;li&gt;The parts of Marpa::XS that were rewritten in C run 100 times faster than
the original Pure Perl.
&lt;li&gt;Typical applications run approximately 10 times faster.
&lt;li&gt;There is a new, simplified, interface for reading input.
&lt;li&gt;The documentation has been improved.

&lt;li&gt;Error reporting and tracing of grammars with right recursion has
been simplified and
is much improved.
&lt;/ul&gt;
&lt;p&gt;Users should keep in mind the following:
&lt;ul&gt;
&lt;li&gt;Marpa::XS is alpha software.
&lt;li&gt;Use of Marpa::XS for production, or anything mission-critical,
would be unwise.
&lt;li&gt;The interface, while I hope it is rapidly stabilizing,
remains subject to change.
&lt;li&gt;The previous interface for reading input, based
on the &lt;kbd&gt;tokens()&lt;/kbd&gt; method, is now strongly deprecated.
It is no longer documented and will be eliminated.
&lt;li&gt;Marpa::XS does not install on a minority of Unix platforms.
The failures all involve either Freebsd's 8.0-release (though Marpa::XS &lt;strong&gt;does&lt;/strong&gt; install on
Freebsd's 8.1-release)
or Linux for the i686-linux architecture (though Marpa::XS
&lt;strong&gt;does&lt;/strong&gt; install
on i686-linux-gnu-thread-multi, as well as every other Linux tested).
Where Marpa does not install, the problem

&lt;a href=&quot;#NOTE1&quot;&gt;lies in dynamically linking with the two Marpa::XS shared
libraries&lt;/a&gt;.
&lt;/ul&gt;
&lt;p&gt;In a future post, I'll talk about my roadmap for Marpa
and Marpa::XS.  So far I have converted Marpa's grammar pre-processing
and parsing to C.
The only part that remains is Marpa's evaluator.
While an afterthought for the theories,
the evaluator is very important in practical use,
and for getting the full benefit of the other speedups.
Conversion of Marpa's evaluator to C will
probably be my next focus.
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;p&gt;&lt;a name=&quot;NOTE1&quot;&gt;Note 1: &lt;/a&gt;
Marpa::XS comes with two shared libraries:
an XS library, which contains Marpa-to-Perl glue,
and &lt;kbd&gt;libmarpa.a&lt;/kbd&gt;, which contains Marpa's core algorithm.
&lt;kbd&gt;libmarpa.a&lt;/kbd&gt; is a standalone shared
library, suitable for linking with other environments
besides Perl XS.
&lt;p&gt;For Marpa::XS to be dynamically linked, three things must happen:
&lt;ul&gt;
&lt;li&gt;First, the Marpa::XS dynamic library must be loaded.
This seems to work just fine everywhere.

&lt;li&gt;Second, to resolve symbols in Marpa::XS,
&lt;kbd&gt;libmarpa.a&lt;/kbd&gt; must be found and linked in.
This also seems to work just fine everywhere.
&lt;li&gt;Third, &lt;kbd&gt;libmarpa.a&lt;/kbd&gt; uses GNU's glib,
so that to resolve symbols in &lt;kbd&gt;libmarpa.a&lt;/kbd&gt;
the glib library must be found and linked in.
In fact, because Marpa::XS uses CPAN's Glib,
GNU's glib should already have been loaded,
so that it is simply a matter of ensuring that
it is used to resolve references in &lt;kbd&gt;libmarpa.a&lt;/kbd&gt;.
It is this step that is failing on a minority of platforms.
&lt;/ul&gt;
&lt;p&gt;With regard to Windows, I believe there is no major obstacle
to porting Marpa::XS to any of the various Perl's for Windows.
The GNU glib that I mentioned is &lt;strong&gt;NOT&lt;/strong&gt;

glibc -- nothing about Marpa::XS requires a POSIX environment.
However, I know of only one attempt to install Marpa::XS on Windows
and no successes.
&lt;/p&gt;</description>
  </item>
  <item>
    <title>Bovicide 5: Parse-time Error Reporting</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/2011/04/10#bovicide-5-parse-time-error-reporting</link>
    <description>&lt;p&gt;
This post is one of
&lt;a href=&quot;#NOTE1&quot;&gt;a series&lt;/a&gt;
prompted by 
&lt;a href=&quot;#NOTE2&quot;&gt;an exchange of papers on the Internet&lt;/a&gt;.
That exchange discussed what it would take to produce
an acceptable replacement for &lt;var&gt;yacc&lt;/var&gt;
and the entire family of LALR-based parsers.
&lt;p&gt;&lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2010/12/killing-yacc-1-2-3.html&quot;&gt;My first post
&lt;/a&gt;
concentrated on speed and
power -- the ability to parse all context-free grammars in O(n**3) time,
and the ability to parse just about every
grammar in practical use,
including all &lt;var&gt;yacc&lt;/var&gt;-able grammars,
in linear (O(n)) time.
This is the second of &lt;a href=#NOTE1&gt;two posts&lt;/a&gt;

about error reporting.

&lt;p&gt;Error reporting is often ignored,
but it is extremely important.
In &lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2010/12/why-the-bovicidal-rage-killing-yacc-4.html&quot;&gt;
a previous post&lt;/a&gt;,
I suggested that its poor error reporting properties are
the real reason why production parsers are abandoning the once-dominant LALR
in favor of hand-written recursive descent.
LALR's feedback on grammar errors could pass for
low-grade encryption.

&lt;p&gt;Theory heavily influences how programmers look
at their craft.
Error detection is a good example.
Great theoreticians are people who know what to ignore.
As Michangelo is alleged to have said,
the statue is already in the marble,
you just have to chip away the extra stuff.
Error detection is certainly grotty detail.
So the first examinations of parsing pretty much ignored
it.  As did the second, third, fourth, ...

&lt;p&gt;Things did eventually get better.
These days parsing texts often look carefully
at an algorithm's parse-time error detection properties.
Classification of the parsers by error detection currently
focuses on their
ability to determine &lt;b&gt;where&lt;/b&gt; the error is.
It makes sense to focus on this because it's simpler than determining
why there is an error,
and in any case, you aren't likely to find the why if you don't know
the where.

&lt;p&gt;A error is said to occur at the first token which is not part of a &lt;b&gt;correct prefix&lt;/b&gt;.
(I will call that token the &lt;b&gt;error location&lt;/b&gt;.)
A correct prefix is a string of tokens which is a prefix of some input that parses successfully.
Note that this definition of &lt;b&gt;error location&lt;/b&gt; may not always match your intuition
of where the error is.
Intuitively, the error is the first token which cannot be part of
one of the inputs &lt;b&gt;that you intended&lt;/b&gt; -- it is the point
where you &quot;went wrong&quot;.
But neither the theoreticians or I have any idea of how to determine what
a programmer really intended,
short of a Vulcan Mind Meld.
So correct prefixes are going to have to be good enough.


&lt;p&gt;Here's the theoretician's breakdown, using
&lt;a href=&quot;#NOTE2&quot;&gt;my names&lt;/a&gt;.
&lt;ul&gt;
&lt;li&gt;Clueless Parsers.  After it's all over, these parsers realize
the something went wrong,
but they have no idea where.
&lt;li&gt;Clueish Parsers.  These parsers don't always know it immediately
when things go wrong, but they clue in soon after.
&lt;li&gt;Clueful Parsers.  These parsers know exactly when things go wrong.
&lt;/ul&gt;

&lt;h2&gt;The Fifth Requirement for Replacing &lt;var&gt;yacc&lt;/var&gt;:
Good Reporting of Parse-time Errors&lt;/h2&gt;

&lt;p&gt;Clueless parsers stay confined to the pages of
textbooks, as you might expect.
You might also expect this of clueish parsers, but in fact
LALR
is clueish, which means clueish parsing
was the industry standard for production parsing
for decades.
Generations of programmers got used to mysterious
error messages from even the best compilers,
and as a result standards for parse-time error reporting
remain low.

&lt;p&gt;I don't expect them to stay that way.
I hope in the future clueful parsing will be seen
as a minimum in production quality parsing.
Regular expressions are clueful.

&lt;p&gt;Recursive descent is hard to characterize.
The underlying algorithm is usually less than full LL(1),
which makes recursive descent in theory clueish.
But hand-written recursive descent is attractive because it can be
extended as needed with hacks,
so in practice a hand-written recursive descent grammar might
be clueful when it counts.


&lt;p&gt;&lt;a href=&quot;http://search.cpan.org/dist/Marpa/&quot;&gt;Marpa&lt;/a&gt;
is clueful and much more.
Marpa breaks new ground in other areas,
like &lt;a href=&quot;#NOTE3&quot;&gt;speed&lt;/a&gt;,
but I think better error reporting will be its most
important contribution.

&lt;h2&gt;The Ruby Slippers Property&lt;/h2&gt;

&lt;p&gt;Marpa has the Ruby Slippers Property -- Marpa not only knows
exactly where the parse went wrong, it knows &lt;b&gt;why&lt;/b&gt;, and
can report that to the user in convenient form.
If a lexer passes Marpa a bad token,
Marpa can easily tell the lexer
which token or tokens it &lt;b&gt;will&lt;/b&gt; accept.

&lt;p&gt;&lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2010/06/parsing-with-ruby-slippers.html&quot;&gt;
The Ruby Slippers&lt;/a&gt;

are useful for much more than error reporting.
For example, writing BNF to parse very liberal HTML is
a difficult task using conventional methods.
Just dealing with the cases of missing
start or end tags makes the grammar very complex,
and very hard
to maintain and modify.

&lt;p&gt;With Marpa, you can skip all that work.
You write the BNF for strict HTML, on the assumption
that all the start and end tags will be there.
Then, while running, if the parser rejects a token,
the lexer can ask Marpa what it wanted instead.
If it was an start or end tag, the lexer can invent
one and pass it on to keep the parse going.
&lt;a href=&quot;#NOTE4&quot;&gt;
And that's all you need to do to handle the issue of missing
HTML start and end tags.&lt;/a&gt;

&lt;p&gt;Marpa knows not only what tokens it is looking for,
but what rules it is working on and how far it
has progressed into them.
So far,
the only application I've put this additional information to
is &lt;a href=&quot;http://search.cpan.org/~jkegl/Marpa-XS-0.001_033/pod/Debug.pod&quot;&gt;debugging&lt;/a&gt;.
I call the lists of rules in progress,
&quot;progress reports&quot;.

&lt;p&gt;I created progress reports when I started to work on complex grammars in Marpa,
hoping to make a traditionally difficult task easier.
Right off the bat, these &quot;progress reports&quot; were a big improvement.
Instead of struggling with the internals of the parser generator,
as I then had to do with Marpa,
and as users of &lt;var&gt;yacc&lt;/var&gt; still must,
I now had a parser which provided
a window directly into my grammar.

&lt;h2&gt;Notes&lt;/h2&gt;

&lt;p&gt;&lt;a name=&quot;NOTE1&quot;&gt;Note 1: &lt;/a&gt;

&lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2010/12/why-the-bovicidal-rage-killing-yacc-4.html&quot;&gt;The other
post&lt;/a&gt; addressed the reporting of grammar errors.

&lt;p&gt;&lt;a name=&quot;NOTE2&quot;&gt;Note 2: &lt;/a&gt;
Why my terms?  Because the theoretician's terms are cumbersome and misleading.
Theoreticians defined &quot;the immediate error detection property&quot; and
&quot;the correct prefix property&quot;.
Clueless parsers lack both properties.
Clueish parsers have the correct prefix property, but lack the immediate
error detection property.
Clueful parsers have both properties.
&lt;p&gt;The &quot;immediate error detection property&quot; is what you'd think it is,
which is why all parsers with that property are clueful.
What's not so clear is why the
&quot;immediate detection property&quot;
is different from
the &quot;correct prefix property&quot;.
Parsers with the &quot;correct prefix property&quot; are those which reject as
soon as an incorrect prefix &lt;b&gt;has been processed&lt;/b&gt;.
That is not the same as 
&quot;the immediate error detection property&quot; because &quot;processing&quot;
often involves reading input well beyond the correct
prefix, as well as destroying useful evidence
about where the last correct prefix was.

&lt;p&gt;&lt;a name=&quot;NOTE3&quot;&gt;Note 3: &lt;/a&gt;
Marpa's speed improvements 
derive from one algorithm
published by John Aycock and Nigel Horspool,
and another published by Joop Leo.
Marpa is the first parser to combine the algorithms into one,
and Marpa is the first practical implementation of Leo's algorithm.

&lt;p&gt;&lt;a name=&quot;NOTE4&quot;&gt;Note 4: &lt;/a&gt;
My Ruby Slippers HTML parser is &lt;a href=&quot;http://search.cpan.org/dist/Marpa-HTML/&quot;&gt;Marpa::HTML&lt;/a&gt;.
There is more about Ruby Slippers parsing in

&lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2010/06/parsing-with-ruby-slippers.html&quot;&gt;
one of my previous posts&lt;/a&gt;.</description>
  </item>
  </channel>
</rss>
