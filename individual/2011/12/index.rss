<?xml version="1.0"?>
<!-- name="generator" content="blosxom/2.0" -->
<!DOCTYPE rss PUBLIC "-//Netscape Communications//DTD RSS 0.91//EN" "http://my.netscape.com/publish/formats/rss-0.91.dtd">

<rss version="0.91">
  <channel>
    <title>Ocean of Awareness   </title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog</link>
    <description>Ocean of Awareness.</description>
    <language>en</language>

  <item>
    <title>A new web site for Marpa</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/2011/12/26#a-new-web-site-for-marpa</link>
    <description>&lt;p&gt;
I have created an
&lt;a href=&quot;http://www.jeffreykegler.com/marpa&quot;&gt;official web site
for Marpa&lt;/a&gt;.
Marpa is attracting new users,
to the point where I thought it might be useful to have a site to act as
a central directory.
The official web site won't have much in the way of new content.
With new content,
I plan to continue to do
what I've been doing -- post it to this blog.
&lt;/p&gt;
&lt;p&gt;
I've started the site with an annotated list of the
most important Marpa-related posts in this blog.
I hope this will help people newly interested in
Marpa figure out where they want to start.
Those who've been following this blog for a while
might also want to check the list to see if they've
missed anything worthwhile.
&lt;/p&gt;</description>
  </item>
  <item>
    <title>Marpa::XS is now 1.000000</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/2011/12/20#marpaxs-is-now-1000000</link>
    <description>&lt;p&gt;
&lt;a href=&quot;https://metacpan.org/release/Marpa-XS&quot;&gt;
Marpa::XS is now
1.000000&lt;/a&gt;.
Marpa::XS is the current lead implementation of Marpa,
an algorithm that I hope will become
standard for
those parsing problems which are too
complex for regular expressions.
Apparently quite a number of people have put
the beta to use.
Feedback has been positive -- often extremely so.
&lt;/p&gt;
&lt;h1&gt;What is Marpa?&lt;/h1&gt;
&lt;p&gt;
Marpa is a general BNF parser --
it parses anything you can write in BNF, no exceptions.
Left-recursion, right-recursion, ambiguity and
even infinite ambiguity, you name it, Marpa parses it.
If the grammar is of
&lt;a href=&quot;#LINEAR&quot;&gt;a class in practical use&lt;/a&gt;,
Marpa parses it in linear time -- O(n).
&lt;/p&gt;
&lt;p&gt;
Marpa's
parse-time error detection is a breakthrough.
When previous parsers failed, they often offered very
little clue as to why.
Marpa knows exactly what input it expects and why.
Marpa is always fully aware of exactly where it is in the parse,
in terms of the rules of the grammar,
and it can share that information with the application.
So good is Marpa at 
error detection,
once considered a desperate last resort,
that error detection can be used as
&lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2010/06/parsing-with-ruby-slippers.html&quot;&gt;
a parsing technique in itself&lt;/a&gt;.

&lt;/p&gt;
&lt;p&gt;
While Marpa is intended to computer with production parsers,
it does have special advantages for developers and experimenters.
Marpa is highly tolerant of difficult grammars --
it parses all of them,
and in times which are &lt;a href=&quot;#OPTIMAL&quot;&gt;considered optimal&lt;/a&gt;.
&lt;/p&gt;
&lt;h1&gt;New with this release&lt;/h1&gt;
&lt;p&gt;
For Marpa::XS 1.000000,
only the version number and the README file were changed
from the previous, beta, release.
&lt;/p&gt;
&lt;h1&gt;What is next with Marpa?&lt;/h1&gt;
&lt;p&gt;
Marpa::XS is aimed at users who want a stable platform for applications.
To ensure the stability of Marpa::XS,
active development of Marpa is moving into a new fork: Marpa::R2.
This will isolate Marpa::XS users from the accidental changes
and bugs that can be the side effect of active development.
&lt;/p&gt;
&lt;p&gt;

Initially, changes to Marpa::XS will be restricted to
bug fixes and those justified from a maintainability standpoint.
The feature set will be kept stable.
(As it stands, Marpa::XS is much more fully featured
than competing parsers.)
If I enhance the features of Marpa::XS,
the new features will be back-ported from Marpa's active development forks,
and I will preserve backward compatibility.
&lt;h1&gt;Limitations&lt;/h1&gt;
&lt;p&gt;
Marpa::XS is, as the name suggests, XS only --
installation requires access to a C compiler,
and to many of the &lt;a href=&quot;#GNU&quot;&gt;GNU utilities and libraries as well&lt;/a&gt;.
Marpa::XS has been tested on a wide variety of POSIX systems.
In theory Marpa::XS is NOT restricted to POSIX systems --
all the tools it uses have Windows versions, for example.
However, Marpa::XS has not,
to my knowledge,
been installed on a non-POSIX system.
&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;&lt;h2&gt;Notes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a name=&quot;LINEAR&quot;&gt;&quot;in linear time&quot;: &lt;/a&gt;
To be specific, Marpa parses any LR-regular grammar in linear time -- O(n).
LR-regular is a vast class of grammars that includes LALR,
LR(k) for all k,
and LL(k) for all k.
This means that Marpa parses,
in linear time,
every class of grammar parsed by yacc,
recursive descent and regular expressions.
&lt;/li&gt;
&lt;li&gt;&lt;a name=&quot;OPTIMAL&quot;&gt;&quot;considered optimal&quot;: &lt;/a&gt;

The phrase &quot;considered optimal&quot; elides some
irrelevant bits of theory.
I would be mildly surprised
if it turns out that there is an
O(n) algorithm for general BNF parsing,
but nobody has proved that such a thing cannot exist.
And there is an algorithm which, in theory,
beats Marpa's O(n**3) worst case.
The Valiant algorithm parses general BNF
and is O(n**2.373...) or better.
But Valiant's algorithm is only faster for huge problems,
and for those it
needs a machine with many terabytes of main memory
to deliver on its speed claims.
So it won't be competing with Marpa any time soon.
&lt;li&gt;&lt;a name=&quot;GNU&quot;&gt;&quot;GNU utilities and libraries&quot;: &lt;/a&gt;
These dependences can be an inconvenience, I admit, but
the alternative is installing
my attempt to portably re-create
all the things the GNU people have developed.
I think that it is clear that the GNU software is the easier
and more reliable alternative.
&lt;/p&gt;
&lt;p&gt;
If you browse the package, you may see that it uses TeX as well.
TeX is ONLY needed is you are working on libmarpa,
the highly mathematical, low-level core library that provides
the parse engine.
To do this, you'd need to have studied a lot of the mathematics
of parsing -- and you'd understand why I feel forced to do the
documentation in TeX.
All the non-mathematical parts are either in Perl, or in C code
which can be read and changed on systems which do not have TeX
installed.
&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/p&gt;</description>
  </item>
  <item>
    <title>How to parse HTML, part 3</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/2011/12/14#how-to-parse-html-part-3</link>
    <description>&lt;p&gt;
When a solution has the same shape
as the problem,
it is a very good thing,
and not just because it looks pretty.
In
&lt;a href=&quot;#PREVIOUS&quot;&gt;previous posts&lt;/a&gt;,
I have described
&lt;a href=&quot;https://metacpan.org/module/Marpa::HTML&quot;&gt;Marpa::HTML&lt;/a&gt;,
a Marpa-based, &quot;Ruby Slippers&quot;
approach to parsing liberal
and defective HTML.
A major advantage
of
&lt;a href=&quot;https://metacpan.org/module/Marpa::HTML&quot;&gt;Marpa::HTML&lt;/a&gt;
is that it looks like
the problem it solves.
&lt;/p&gt;
&lt;h2&gt;HTML parsing: the problem&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
The problem of parsing an HTML document
is essentially
the problem of finding
the hierarchy of its HTML elements.
Conceptually,
HTML elements are delimited by start and end tags.
&lt;li&gt;
The HTML standards specify that certain of the
start and end tags can be omitted.

&lt;li&gt;
In liberal and defective HTML,
any HTML tag might be missing.
&lt;li&gt;
In liberal and defective HTML,
unknown and spurious tags
may be present in the physical input.
&lt;/ol&gt;
&lt;h2&gt;HTML parsing: the solution&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
The parse engine uses an over-strict grammar,
one which requires all HTML start and end tags.
&lt;li&gt;
When the parse engine runs into a token it cannot accept,
if there is exactly one start or end tag which it
could accept at that point,
the parser uses &quot;the Ruby Slippers&quot;.
It invents a virtual token representing the desired
tag, and feeds it to the parse engine.
&lt;li&gt;
If there is more than one virtual token is possible,
&lt;a href=&quot;https://metacpan.org/module/Marpa::HTML&quot;&gt;Marpa::HTML&lt;/a&gt;
chooses a token to pass on to the parse engine.
In the current
implementation,
this is done using rules of thumb.

&lt;li&gt;
If no virtual token is possible,
the physical token is treated as &quot;cruft&quot;.
The grammar allows cruft to be a part of the contents
of any HTML element,
and the application can decide what to do
with it.
&lt;/ol&gt;
&lt;p&gt;
This outline of the solution
follows the structure of the problem point for point.
In turn, the code follows this outline.
It may seem
that I just stated the painfully obvious,
but in fact the design of
the parsers in use today typically
does NOT reflect the structure of their target languages
in any straightforward way.
In particular, the more a parser is
considered &quot;production quality&quot;,
the less likely its code will bear any resemblance to
the problem it is solving.
&lt;/p&gt;
&lt;h2&gt;Toward hackable parsers&lt;/h2&gt;
&lt;p&gt;
A lot could be said about the
aesthetics and philosophy of this.
In this post,
let me cut straight to the bottom line.
&lt;/p&gt;
&lt;p&gt;
First and least important,
it is usually easier to code a solution which looks like the problem.
I say &quot;least important,&quot;
because this perspective views the problem as static,
and if the problem is static you can code it up
and forget it.
It does not matter too much whether
the coding effort is fast,
if it only has to be done once.
But what if the problem keeps changing?
&lt;/p&gt;
&lt;p&gt;
You might say that most parsing is of the static type,
and that's true.
But that is
because previous technology has left little
choice in the matter.
I believe that,
if programmers had the option of hacking production-quality
parsers, they'd be doing it all the time.
&lt;/p&gt;

&lt;p&gt;
In the past,
hacking production quality parsers has been,
for practical purposes, impossible.
Look at those existing utilities which do work with, for
example, C, HTML or Perl.
These usually do NOT even attempt to leverage the production parser
for these languages.
Instead these tools use a new parser,
one created from scratch.
One consequence is that
they must tolerate a considerable amount
of approximation in the parsing.
&lt;/p&gt;
&lt;p&gt;
Why don't programmers take the production parsers for a language
as the basis for tools working with that language?
If you look at those production parsers,
you'll see why.
They reflect the structure of the languages so little,
and are so complex,
that they simply are unusable as a starting point
for tools.
&lt;p&gt;
&lt;/p&gt;
A Marpa-powered &quot;Ruby Slippers&quot; approach to HTML,
like the one implemented in 
&lt;a href=&quot;https://metacpan.org/module/Marpa::HTML&quot;&gt;Marpa::HTML&lt;/a&gt;
but with its HTML interpretation layer rewritten in C,
would be very competitive as a production HTML parser.
Not the least of its advantages would be that it would make
an excellent basis for HTML utilities.
&lt;p&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a name=&quot;PREVIOUS&quot;&gt;&quot;previous posts&quot;&lt;/a&gt;:
The previous posts in this series were
&quot;&lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2011/11/how-to-parse-html.html&quot;&gt;How
to parse HTML&lt;/a&gt;&quot;
and 
&quot;&lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2011/12/how-to-parse-html-part-2.html&quot;&gt;How
to parse HTML, part 2&lt;/a&gt;&quot;.
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
  </item>
  <item>
    <title>Marpa::XS release candidate now available</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/2011/12/11#marpaxs-release-candidate-now-available</link>
    <description>&lt;p&gt;
I am very happy to announce that
&lt;a href=&quot;https://metacpan.org/release/JKEGL/Marpa-XS-0.026000/&quot;&gt;
the latest release of Marpa::XS&lt;/a&gt;
is a release candidate&lt;/a&gt; for the first full release,
Marpa::XS 1.000000.
Most user's experience with the previous beta releases
seems to have been trouble-free.
The one significant issue that was identified
was a failure to properly evaluate null symbols under
&lt;a href=&quot;#JIROTKA&quot;&gt;
an unusual combination of circumstances&lt;/a&gt;.
This problem
(a one line error in the C rewrite of the parse engine)
is fixed in this release.
Unusual as the issue is,
when it does occur it results in a parse failure,
so that
I recommend that all users of Marpa::XS upgrade to
&lt;a href=&quot;https://metacpan.org/release/JKEGL/Marpa-XS-0.026000/&quot;&gt;
the latest release&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
Marpa::XS is being kept stable.
Bug fixes, even of minor and cosmetic bugs,
will be made, as 
will changes that improve maintainability.
But no new features will be added.
Interface changes will be especially avoided.

&lt;/p&gt;
&lt;h2&gt;What is Marpa?&lt;/h2&gt;
&lt;p&gt;Marpa is an advance over recursive descent
and yacc.
I hope the Marpa algorithm
will become the standard parser for
problems too
big for regular expressions.
&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Marpa parses,
&lt;a href=&quot;#LINEAR&quot;&gt;
in linear time&lt;/a&gt;,
those
classes of grammar that are currently in practical use.
&lt;/li&gt;
&lt;li&gt;The importance of parse-time debugging is often underestimated.
Marpa's parse-time error detection breaks new ground -- Marpa is
fully aware of exactly where in the parse it is at all times,
and of exactly what input it expects and why.
This means parse-time error detection, once a desperate last
resort, now can be used as
&lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2010/06/parsing-with-ruby-slippers.html&quot;&gt;
a parsing technique in itself&lt;/a&gt;.

&lt;/li&gt;
&lt;li&gt;Marpa is a general BNF parser -- that means if you feed it anything
written in BNF, it &quot;just parses&quot; it.
This includes grammars which are left-recursive, right-recursive and
ambiguous -- even infinitely ambiguous.
&lt;/li&gt;

&lt;li&gt;Marpa never goes exponential -- worst case, even for highly ambiguous
grammars, is O(n**3), which is
&lt;a href=&quot;#OPTIMAL&quot;&gt;considered optimal&lt;/a&gt;.
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;New with this release&lt;/h2&gt;
&lt;p&gt;
Since the beta release,
several bugs have been fixed,
The most important one was a failure to properly evaluate
null symbols
&lt;a href=&quot;#JIROTKA&quot;&gt;under certain unusual circumstances&lt;/a&gt;.
This problem, identified and described by
Tom&amp;aacute;&amp;#353; Jirotka,
is fixed in
&lt;a href=&quot;https://metacpan.org/release/JKEGL/Marpa-XS-0.026000/&quot;&gt;
this latest release&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
In some previous Marpa::XS releases, the
documentation, while part of the distribution,
did not install automatically.
As of this release, that problem is fixed.
The documentation now
installs, as it should,
along with the rest of Marpa::XS.
&lt;/p&gt;
&lt;p&gt;
No interface has been deprecated since
Marpa::XS went beta -- the interface has remained stable.
But many interfaces deprecated BEFORE Marpa
went beta were used in the test suite.
To make the test suite more useful for readers,
I eliminated deprecated practices
except in code whose purpose it is
to test that deprecated practice.
Where tests continue to use a deprecated practice,
comments explicitly point this out.
&lt;/p&gt;
&lt;h2&gt;What is next with Marpa?&lt;/h2&gt;
&lt;p&gt;
Based on the feedback,
I have confidence that Marpa::XS have been extensively
used and found reliable.
With the fixes for this release,
I expect that Marpa::XS can be taken out
of beta and into a full 1.000000 release shortly.
&lt;/p&gt;
Development of new features for
Marpa continues, but in another distribution:
&lt;a href=&quot;http://search.cpan.org/dist/Marpa-R2/&quot;&gt;Marpa::R2&lt;/a&gt;.
This isolates Marpa::XS users from the accidental changes
and bugs that can be the side effect of active development.</description>
  </item>
  <item>
    <title>How to parse HTML, part 2</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/2011/12/07#how-to-parse-html-part-2</link>
    <description>&lt;p&gt;
This is the second of a series of posts that details
a Marpa-based, &quot;Ruby Slippers&quot;
approach to parsing liberal
and defective HTML.
This post assumes you have 
read
&lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2011/11/how-to-parse-html.html&quot;&gt;
the first post&lt;/a&gt;.
&lt;/p&gt;
&lt;h2&gt;First, reduce the HTML to a token stream&lt;/h2&gt;
&lt;p&gt;
Most computer languages can be viewed
as a token stream.
HTML is not an exception.
HTML tokens can be blocks of text;
comments and various other SGML entities;
HTML element start tags;
and HTML element end tags.
The HTML token stream is unusual in that
some of its tokens can
be quite complex internally.
&lt;/p&gt;
In parsing computer languages,
it is a frequent practice to divide the
work between a tokenizer (&quot;lexer&quot;)
and a &lt;a href=&quot;#HIGH-LEVEL&quot;&gt;high-level parser&lt;/a&gt;.
The lexer takes the raw input
and turns it into a token stream.
Tokenizing HTML is a difficult job,
and one for which there is an excellent CPAN module:
&lt;a href=&quot;https://metacpan.org/module/HTML::Parser&quot;&gt;HTML::Parser&lt;/a&gt;.
&lt;a href=&quot;https://metacpan.org/module/Marpa::HTML&quot;&gt;Marpa::HTML&lt;/a&gt;

relies on
&lt;a href=&quot;https://metacpan.org/module/HTML::Parser&quot;&gt;HTML::Parser&lt;/a&gt;
to do its tokenization.
&lt;p&gt;
&lt;/p&gt;
&lt;a href=&quot;https://metacpan.org/module/Marpa::HTML&quot;&gt;Marpa::HTML&lt;/a&gt;
determines the large scale structure of the HTML document --
what I will call in this post, &quot;high-level&quot; parsing.
The result of high-level parsing can be
seen as a hierarchical structure.
The goal of high-level parsing is
to build a hierarchy which reflects
the structure of the document.
Conventionally, this hierarchy is visualized
as an upside-down tree,
one where the &quot;leaves&quot; are the tokens,
and where the &quot;root&quot; node represents the
document as a whole.</description>
  </item>
  </channel>
</rss>
