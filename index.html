<html>
<head>
<link rel="alternate" title="Ocean of Awareness RSS" type="application/rss+xml" title="RSS" href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/index.rss" />
<title>Ocean of Awareness</title>
<style type="text/css">
   strong {font-weight: 700;}
</style>
</head>
<body>
<div id="header"
  style="color:white;background-color:#38B0C0;padding:1em;clear:left;text-align:center;">
<h1>Ocean of Awareness</h1>
</div>
  <div id="menu" style="margin:0;padding:10px;width:150px;float:left;">
  <h2>Jeffrey Kegler's blog</h2>
  <p>About Marpa, his new parsing algorithm,
    and other topics of interest</p>
  <h3>Resources</h3>
  <p><a href="http://www.jeffreykegler.com/">Jeffrey Kegler's website</a></p>
  <p><a href="http://www.jeffreykegler.com/marpa">The Marpa website</a></p>
  <p>Ocean of Awareness blog <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog">home page</a>
  and <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/chronological.html">chronological index</a>
  </p>
  </div>
  <div id="content" style="margin-left:190px;border-left:2px solid #38B0C0;padding:25px;">
<h3>Mon, 03 Sep 2012</h3>
<br />
<center><a name="r2_is_beta"> <h2>Marpa::R2 is beta</h2> </a>
</center>
<a href="https://metacpan.org/release/Marpa-R2">Marpa::R2</a>
is now beta.
Marpa is a new parsing algorithm,
based on decades of prior art.
It is a practical and efficient solution
targeted at all parsing problems that are too
complex for regular expressions.
<p>
The
<a href="https://metacpan.org/release/Marpa-R2">Marpa::R2</a>
module is the most recent Marpa module.
Marpa is also available as the
<a href="https://metacpan.org/release/Marpa-XS">
Marpa::XS</a>
module,
which is stable and bug-fix only.
Both Marpa modules:
<ol>
<li><p>Parse everything you can write in BNF.
<li><p>
Parse all
classes of grammar in practical use today in linear time.
<li><p>Parse all BNF grammars
in times considered theoretically optimal.
For unambiguous grammars, Marpa is never worse than
O(n<sup>2</sup>).
For ambiguous grammars, Marpa is never worse than
O(n<sup>3</sup>).
Marpa never goes exponential.
<li><p>
Are fully aware, at every point in the parse, of
all the rules they are parsing,
how far into them they have proceeded,
and of what tokens they expect next.
Especially with Marpa::R2,
this information is available
to the application
conveniently and efficiently.
<li><p>
Do not need to be handwritten.
Marpa is available as a open-source library.
It is written in C,
and the C library can be used
<a href="http://jeffreykegler.github.com/Marpa/libmarpa.html">
directly</a>
or via
<a href="https://metacpan.org/release/Marpa-R2">
a Perl interface</a>.
<li><p>
For general BNF parsing,
do not require
the user to craft
a lookahead or backtracking strategy -- Marpa
does not use lookahead and never backtracks.
<li><p>
Come
with the traditional theoretical apparatus of
proofs based on prior literature.
</ol>
<p>
<a href="https://metacpan.org/release/Marpa-R2">Marpa::R2</a>
is a major rewrite of the Marpa internals.
The most visible of these changes:
<ol>
<li><p>Marpa::R2 is faster.
<li><p>Marpa::R2 is easier to install.
In particular the dependency on Glib has been removed.
Marpa::R2 now has no non-core CPAN dependencies.
<li><p>Marpa::R2's internal symbols are now invisible
to the user, even when tracing and debugging.
<li><p>
<a href="http://jeffreykegler.github.com/Marpa/libmarpa">
Libmarpa, the C library which is at the core of Marpa</a>,
is now documented
and separately installable.
(Libmarpa remains alpha at this point.)
<li><p>Another new documented interface,
<a href="https://metacpan.org/module/Marpa::R2::Advanced::Thin">
Marpa::R2::Thin</a>,
is a "thin" interface to Libmarpa from Perl.
(Marpa::R2::Thin remains alpha at this point.)
</ol>
<br />
<p>posted at: 17:16 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/r2_is_beta.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 26 Aug 2012</h3>
<br />
<center><a name="dsl"> <h2>Domain-Specific Languages made simpler</h2> </a>
</center>
<h2>Writing your own language</h2>
<p>Creating your own language has been A Big Deal (tm).
What if you could create a simple language in hours or minutes?
There's been a serious obstacle up to now.
No practical parser "just parsed" BNF.
With
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>,
that restriction is lifted.
<p>
In this post, I will describe
a small, sample
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>
domain-specific language (DSL).
In designing it I am inspired by
<a href="http://blog.plover.com/oops/blosxom-sux.html">
Mark Dominus's description</a>
of the
<a href="http://en.wikipedia.org/wiki/Worse_is_better">
"Worse is Better" philosophy</a>,
and its implementation in the form of
<a href="http://en.wikipedia.org/wiki/Blosxom">
Blosxom</a>.
This DSL is feature-poor,
but short, simple and extensible.
<h2>A calculator</h2>
<p>
This DSL is a calculator.
Calculators are familiar and,
after all, whatever tool you build this
DSL into, it will probably be useful
to have a calculator as part of it.
What follows contains only the parts of the code
relevant to the discussion,
not necessarily in lexical order.
If you find the following interesting,
you'll almost certainly want the full code,
which is available as
<a href="https://gist.github.com/3521836">
a Github gist</a>.
<p>
<h2>The grammar</h2>
<p>
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>
allows you to build your DSL as a clean modular
structure,
with a separate grammar, tokenizer and semantics.
If you're used to doing parsing with regexes or recursive descent,
you expect to see things mixed together,
and much as you might like modularity in other contexts,
this cleaner approach may make you uneasy.
And not without reason.
Traditionally, parsing tools that
took a modular approach
were painful to use and,
for practical grammars,
often rewarded the extra effort
they required by failing to work.
<p>Here's the grammar for our calculator.

<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">
my $rules = Marpa::Demo::OP2::parse_rules(
    <<'END_OF_GRAMMAR'
reduce_op ::=
    '+'                   => do_arg0
  | '-'                   => do_arg0
  | '/'                   => do_arg0
  | '*'                   => do_arg0
script ::= e              => do_arg0
script ::= script ';' e   => do_arg2
e ::=
     NUM                  => do_arg0
   | VAR                  => do_is_var
   | :group '(' e ')'     => do_arg1
  || '-' e                => do_negate
  || :right e '^' e       => do_binop
  || e '*' e              => do_binop
   | e '/' e              => do_binop
  || e '+' e              => do_binop
   | e '-' e              => do_binop
  || e ',' e              => do_array
  || reduce_op 'reduce' e => do_reduce
  || VAR '=' e            => do_set_var
END_OF_GRAMMAR
);
</div>

<p>This is a simple language, but it's already an advance over,
<a href="http://blog.plover.com/prog/bash-expr.html">
say, shell arithmetic</a>.
And the <tt>reduce</tt> operator is even a bit
of fanciness.
It's a second-order binary operator,
whose left operand is another operator.
<p>The grammar is written in another DSL, <tt>Marpa::Demo::OP2</tt>,
which is bundled into the same file.
(OP2's grammar is defined directly in
<a href="https://metacpan.org/release/Marpa-R2">
Marpa::R2</a>.)
Together, these two quite useable DSL's require 600 lines,
self-testing included.
<p>
I'm using OP2 in this post, as it presents the <strong>idea</strong>
of a grammar more clearly.
<a href="https://metacpan.org/release/Marpa-R2">
Marpa::R2</a>'s
lower level syntax, while more stable, flexible and efficient,
is more cluttered.
OP2 itself is interesting as an extension and generalization of
precedence parsing,
as I described in
<a href="http://blogs.perl.org/users/jeffrey_kegler/2012/08/precedence-parsing-made-simpler.html">
a previous post</a>.
Here's its syntax:
<dl>
<dt><strong><tt>::=</tt></strong><dd>A BNF rule in LHS <tt>::=</tt> RHS form
<dt><strong><tt>'abc'</tt></strong><dd>A literal token.
<dt><strong><tt>|</tt></strong><dd>Separates alternative RHS's at the <strong>same</strong> precedence level
<dt><strong><tt>||</tt></strong><dd>Separates alternative RHS's at the <strong>different</strong> precedence levels.
  The tighter ("higher") precedence alternative is first, the
  looser ("lower") precedence alternative is second.
<dt><strong><tt>=&gt;</tt></strong><dd><tt>rule =&gt; semantics</tt>, where <tt>semantics</tt>
is a Perl closure.
<dt><strong><tt>:left</tt></strong><dd>The alternative is left-associative (the default)
<dt><strong><tt>:right</tt></strong><dd>The alternative is right-associative
<dt><strong><tt>:group</tt></strong><dd>The alternative is grouping-associative -- that is, its
operator(s), regardless of their own precedence,
group expressions of the loosest precedence
</dl>

<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">
my $grammar = Marpa::R2::Grammar->new(
    {   start          => 'script',
        actions        => __PACKAGE__,
        rules          => $rules,
    }
);
$grammar->precompute;
</div>

<p>The code just above creates a new grammar from the OP2-generated rules.
The only other information needed to fully define
the grammar is the name of the start symbol
("<tt>script</tt>") and the name of the package where
the semantics can be found
(the current one, <tt>__PACKAGE__</tt>).
<p>
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>
does a lot of precomputation to its grammars.
Once a grammar is fully defined,
and before a recognizer can be created from it,
the <tt>precompute()</tt> method must be called.
<h2>The semantics</h2>
<p>
Those curious about the semantics of this calculator
can look at
<a href="https://gist.github.com/3521836">
the Github gist</a>.
They are somewhat interesting.
But this post is about how to get <strong>your</strong> interesting
semantics out easily and quickly,
in the form of a powerful
language specifically designed for them.
<h2>The lexer</h2>
<h3>The token table</h3>
<p>The calculator's lexer is table-driven.
The table is quite simple -- it's an array
of two element arrays.
In the inner arrays, the first element is the symbol name,
as specified in the grammar,
and the second is a regex which matches it.

<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">
my @terminals = (
    [ q{'reduce'}, qr/reduce\b/xms ],
    [ 'NUM',       qr/\d+/xms ],
    [ 'VAR',       qr/\w+/xms ],
    [ q{'='},      qr/[=]/xms ],
    [ q{';'},      qr/[;]/xms ],
    [ q{'*'},      qr/[*]/xms ],
    [ q{'/'},      qr/[\/]/xms ],
    [ q{'+'},      qr/[+]/xms ],
    [ q{'-'},      qr/[-]/xms ],
    [ q{'^'},      qr/[\^]/xms ],
    [ q{'('},      qr/[(]/xms ],
    [ q{')'},      qr/[)]/xms ],
    [ q{','},      qr/[,]/xms ],
);
</div>

<p>
Order in the above table matters when you have
terminals, one of which can prefix another.
An example would be the operators
<tt>==</tt> and <tt>=</tt>.
There is no such pair here,
however,
so that
in this application,
the order makes no difference.
<p>
As you can see,
I am one of those who specify <tt>xms</tt> for every
regex.
The symbol names preserve the surrounding single quotes.
This is convenient for processing,
and it also makes diagnostic messages involving
those symbols more comprehensible.
Finally, note that the <tt>reduce</tt> operator is required to end on a word boundary.
<h3>The tokenizing engine</h3>

<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">
    my $rec = Marpa::R2::Recognizer->new( { grammar => $grammar } );

    my $length = length $string;
    pos $string = 0;
    TOKEN: while ( pos $string < $length ) {

        # skip whitespace
        next TOKEN if $string =~ m/\G\s+/gcxms;

        # read other tokens
        TOKEN_TYPE: for my $t (@terminals) {
            next TOKEN_TYPE if not $string =~ m/\G($t->[1])/gcxms;
            if ( not defined $rec->read( $t->[0], $1 ) ) {
                die_on_read_problem( $rec, $t, $1, $string, pos $string );
            }
            next TOKEN;
        } ## end TOKEN_TYPE: for my $t (@terminals)

        die q{No token at "}, ( substr $string, pos $string, 40 ),
            q{", position }, pos $string;
    } ## end TOKEN: while ( pos $string < $length )
</div>
<p>The calculator's token engine creates a
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>
recognizer
with the <tt>new()</tt> constructor,
and feeds it tokens with the <tt>read()</tt> method.
In this token engine,
I use Perl's progressive matching capabilities:
the
<tt>g</tt> and
<tt>c</tt> modifiers, the
<tt>\G</tt> assertion and the
<tt>pos</tt> function.
When writing a token engine,
there is, as the expression goes, more than one way
to do it,
many of them somewhat easier than this approach.
But progressive matching is powerful, efficient,
very flexible,
and it has the advantage that
it leaves the original string intact.
<p>
Those who go on to look at the
<a href="https://gist.github.com/3521836">
code in the gist</a>
may find
<tt>die_on_read_problem()</tt>,
the DSL's function for handling <tt>read()</tt> errors,
helpful.
It produces a very specific and comprehensive error message.
One of
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>'s
greatest improvements over previous
parsers is that, when a parse fails,
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>
can explain why in considerable detail.
It makes sense to take full advantage of that ability.

<h2>Evaluating the parse</h2>
<p>
<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">

    my $value_ref = $rec->value;

    if ( !defined $value_ref ) {
        say $rec->show_progress() or die "say failed: $ERRNO";
        die 'Parse failed';
    }
    return ${$value_ref};

</div>
<p>Evaluation of the parse is done with the <tt>value()</tt> method.
This can return all the parse results of an ambiguous parse.
We want only one parse here,
so we call <tt>value()</tt> only once.
<tt>value()</tt> returns a reference to the value of the parse,
and a Perl <tt>undef</tt> if the parse failed.
The error handling is worth noticing.
One of
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>'s
strengths is that it is fully aware of which rules
are being tried at any point,
and of how far into those rules recognition has progressed.
The <tt>show_progress()</tt> method reports that information.

<h2>OP2</h2>
<p>
This ends our description of the calculator code.
In
<a href="https://gist.github.com/3521836">
the Github gist</a>
a second DSL immediately follows the
calculator DSL.
This second DSL is OP2,
which is used to define the grammar for the calculator.
OP2 is more complicated than the calculator,
but its design is similar,
and it can be used as a second DSL example.
<h2>Alernatives</h2>
<h3>Marpa::R2 verus Marpa::XS</h3>
<p>This calculator uses
<a href="https://metacpan.org/release/Marpa-R2">
Marpa::R2</a>.
<a href="https://metacpan.org/release/Marpa-R2">
Marpa::R2</a>
is beta,
while
<a href="https://metacpan.org/module/Marpa::XS">
Marpa::XS</a>
is in a stable, bug-fix only release.
On the other hand
<a href="https://metacpan.org/release/Marpa-R2">
Marpa::R2</a>
is somewhat faster,
and its reporting of parse-time problems is better.
<h3>Specifying the grammar</h3>
The grammar of the calculator is specified in OP2,
which is a clear and elegant way to do it.
But OP2 is an experimental DSL created just for this
one use.
<p>
A more robust way to 
specify grammars is to do it directly in
<a href="https://metacpan.org/release/Marpa-R2">
Marpa::R2</a>.
OP2's grammar is specified directly in
<a href="https://metacpan.org/release/Marpa-R2">
Marpa::R2</a>.
A compromise between elegance and stability would be
to use OP2 (or a derivative)
to generate the rules (or some of them).
The OP2-generated rules can be used
as is, or edited to taste.
When you are happy with them,
Data::Dumper can turn the OP2-generated rules
into code,
which you can
then incorporate into your DSL program.
<h3>Error messages</h3>
It is hard to compare
the quality of the
messages from these DSL's,
unfamiliar programs which explore new ground,
against, for example,
the comprehensibility of a C compiler's
error messages.
With the C compiler, I have the advantage of
over 40 years of Pavlovian training in guessing what
they really mean.
<p>
I believe that this DSL's error messages
are already, on average, up to the level
of typical production languages.
My main reason for this bold assertion is that
production parsers have set the bar,
frankly, extremely low.
I hasten to add,
this is often not because of lack of care or effort
by the implementers.
The traditional parsing technologies simply
do not provide enough information to support
accurate and helpful error reporting.
<p>
Much more could be done in error message handling
than is done by this calculator DSL.
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>'s
situational awareness
makes much easier to write usefully
accurate error messages than has been the case.
And I find better error messages often repay a high priority,
even in programs that are strictly for personal use.
<br />
<p>posted at: 09:20 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<br />
<center><a name="announce"> <h2>A new home for the Ocean of Awareness blog</h2> </a>
</center>
The folks at <a href="blogs.perl.org">blogs.perl.org</a>
has provided
my Ocean of Awareness blog
a wonderful home for some time.
But the call of static blogging is becoming impossible to resist.
A <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/">
github based site</a>
will, most likely, soon
become the new home
of the Ocean of Awareness blog.
<p>
One consideration still up in the air is comments on the blog.
For some bloggers, the loss of comments has been one of the
attractions of static blogging,
but comments have been valuable to me.
I've heard of Disqus being used for comments on static blogs,
and I'm looking into that.
<p>
For those who want to comment
in the meantime,
if the post is Marpa-related,
<a href="https://groups.google.com/forum/?hl=en&fromgroups#%21forum/marpa-parser">
the Marpa mailing list</a>
is a good place to comment.
Also,
I will continue to dual-post for some time,
and have not yet frozen comments on the versions of the
post at
<a href="blogs.perl.org">blogs.perl.org</a>.
<br />
<p>posted at: 09:20 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/announce.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Wed, 22 Aug 2012</h3>
<br />
<center><a name="precedence-parsing-made-simpler"> <h2>Precedence parsing made simpler</h2> </a>
</center>
<p>This post describes a new approach to precedence parsing,
one that makes it simpler and
more flexible.
Many programmers find precedence
is an intuitive way to
look at problems.
The traditional rules of arithmetic
are a familiar example:
<tt><pre>
E ::= ( E )
E ::= n
E ::= E * E
E ::= E + E
</pre></tt>
<p>
Here, as in the rest of this post,
the rules are ranked from tightest ("highest") precedence
to loosest ("lowest").
The order in the above display indicates that multiplication
takes precedence over addition, and parentheses take precedence
over everything else.
<h2>The old way and the new way</h2>
<p>The traditional way to deal with precedence
centers on symbols.
The symbols are divided sharply in two:
those that define structure
and those that carry information.
The structural symbols (often called "operators")
are assigned associativities and precedence.
To help guide the parse,
symbols may be further classified as infix, prefix,
circumfix, etc.
<p>
Many rules, even those which intuitively seem part of
the precedence order,
do not fit into this symbol-oriented view of precedence.
Implied operators are ruled out,
as is any rule with two non-terminals in a row.
Rules with an arity of 3 or above, when not also impossible,
are a challenge.
<p>The approach of this post is 100% rule-based.
There is no attempt to identify operators or structural
symbols,
and no attempt to assign properties to them.
This rule-based approach allows
the convenient expression and
efficient implementation of
implied operators,
of rules of arity 3 or higher,
and of rules with any pattern of terminals or non-terminals.
<h2>Simpler</h2>
<p>
Before getting into new features,
it is probably best to show the new approach as applied
to a grammar that
can be parsed with the traditional methods.
My notation is mostly standard or transparent,
but here are details:
<tt><pre>
    ::=       separates the lhs of a rule from its rhs alternatives
    |         separates alteratives at the same precedence level
    ||        separates alteratives at different precedence levels
    :group    indicates 'grouping' associativity
    :left     indicates left associativity (the default)
    :right    indicates right associativity
</pre></tt>
<p>
Here is the grammar:
<tt><pre>
e ::=
     NUM
   | VAR
   | :group '(' e ')'
  || '-' e
  || :right e '^' e
  || e '*' e
   | e '/' e
  || e '+' e
   | e '-' e
  || VAR '=' e
</pre></tt>
<p>
The above fully states the
precedence and associativity for the grammar's rules.
(As a reminder, the precedence follows the order of the rules,
from tightest to loosest.)
This is significantly simpler than what is required
to set up a traditional precedence parser.
On the other hand,
intuitively, it looks like all the required
information is there.
And, in fact, this is the source from which
Marpa::Demo::OP1 creates the grammar for a calculator.
The code is
<a href="https://gist.github.com/3427294">
a Github gist</a>.
<p>In real life, users of a calculator grammar,
like the above,
will be interested
in a numeric result.
However, in this post we are not interested in double-checking
Perl's ability to do basic arithmetic,
so instead we capture
the syntactic structure that the calculator creates.
Here are sample outputs, with square brackets
added to show the parse.
<tt><pre>
Input: "4 * 3 + 42 / 1"
  Parse: [[4*3]+[42/1]]
Input: "4 * 3 / (a = b = 5) + 42 - 1"
  Parse: [[[[4*3]/[([a=[b=5]])]]+42]-1]
Input: "4 * 3 /  5 - - - 3 + 42 - 1"
  Parse: [[[[[4*3]/5]-[-[-3]]]+42]-1]
Input: "- a - b"
  Parse: [[-a]-b]
Input: "1 * 2 + 3 * 4 ^ 2 ^ 2 ^ 2 * 42 + 1"
  Parse: [[[1*2]+[[3*[4^[2^[2^2]]]]*42]]+1]
</pre></tt>
<h2>More flexible</h2>
<p>
In the next grammar, I'll introduce an implied operator.
An implied operator is prominent among the features
that traditional precedence parsers
simply could not handle.
In the grammar that follows,
a missing operator will indicate multiplication,
just as in algebra.
<p>
Traditional precedence parsers also
were stymied by
rules with an arity of 3 or more.
For Marpa::Demo::OP1, these are no problem at all.
I'll introduce two ternary operations,
and a quaternary operation.
(New in the notation below is the "<tt>=> xyz</tt>",
which specifies a non-default semantics,
in this case "<tt>xyz()</tt>".)
<p>
<tt><pre>
e ::=
     NUM
   | VAR
   | :group '(' e ')'
  || '-' e
  || :right e '^' e
  || e '*' e
   | e e                                          => implied_multiply
   | e '/' e
  || e '+' e
   | e '-' e
  || VAR '=' e
  || :right e '?' e ':' e                         => spaced
   | :right e '??' e ':' e ':' e                  => spaced
  || 'payment' 'on' e 'over' e 'years' 'at' e '%' => spaced
</pre></tt>
<p>The code for this second example is also
<a href="https://gist.github.com/3427312">
a Github gist</a>.
And here is the output.
(To make it easy to spot them,
implied multiplications are shown with an "<code class="prettyprint">x</code>"
instead of a "<code class="prettyprint">*</code>".)
<tt><pre>
Input: "4 3 42 + 1"
  Parse: [[[4 x 3] x 42]+1]
Input: "e = m c^2"
  Parse: [e=[m x [c^2]]]
Input: "4 * 3 5 (6 7) 8 9 10"
  Parse: [[[[[[4*3] x 5] x [([6 x 7])]] x 8] x 9] x 10]
Input: "1 ? 42 : 2 ?? 3 : 4 : 5 ? 6 : 7"
  Parse: [1 ? 42 : [2 ?? 3 : 4 : [5 ? 6 : 7]]]
Input: "payment on 1000 + 1000 over months/12 years at 5 + 1 %"
  Parse: [payment on [1000+1000] over [months/12] years at [5+1] %]
</pre></tt>
<h2>How rule-based precedence works</h2>
<p>
Rule-based precedence parsing uses
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>,
a new and efficient general BNF parsing algorithm.
With Marpa,
the rest is straightforward.
The grammars in the examples above are rewritten,
using the included precedence and associativity information,
into an "order-explicit grammar".
The BNF of an order-explicit grammar
enforces the 
precedence and associativity of the original, source grammar.
Many textbooks on parsing describe
how to write order-explicit BNF
by hand.
<p>
Creating an algorithm to produce an order-explicit BNF grammar
required some careful thought,
but no flashes of brilliance.
Previously, the major obstacle to this approach would have been
the parse engine.
Traditional parsers did not "just parse" arbitrary BNF -- far from it.
Without (and often even with) programmer intervention,
there would be little reason to hope that
an LALR or LL parse engine would parse
an arbitrary order-explicit BNF grammar.
<a href="http://www.jeffreykegler.com/marpa">
Marpa</a>,
on the other hand, does "just parse" arbitrary BNF,
and a successful parse is guaranteed.
<p>
Any grammar which could have been parsed by yacc (LALR)
or an operator-precedence parser will be parsed by Marpa in linear
time.
LALR and operator precedence are subsets of LR(1), while
Marpa is linear for LR-regular,
and for LR(k) for all k.
This means that Marpa will stay linear for vast classes of grammars
that the traditional techniques
had no hope of ever parsing.
<p>
<h2>Acknowledgements</h2>
<p>
This post is the outcome of a line of thinking started
by an exchange with Alberto Sim&otilde;es,
begun when he graciously shared with me
a pre-release
copy of
<a href="http://drops.dagstuhl.de/opus/volltexte/2012/3513/pdf/6.pdf">
an article on lexical analysis</a>,
which he authored jointly.
And, in creating the DSL used for the examples,
I benefited immensely from studying the approaches used by Peter Stuifzand.
<br />
<p>posted at: 09:58 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/08/precedence-parsing-made-simpler.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 12 Aug 2012</h3>
<br />
<center><a name="the-solved-problem-that-isnt-is"> <h2>The solved problem that isn't, is</h2> </a>
</center>
<p>In the title of
<a href="http://tratt.net/laurie/tech_articles/articles/parsing_the_solved_problem_that_isnt">
an excellent blog post</a>,
Laurence Tratt calls parsing,
"the solved problem that isn't".
I thought this
phrase captured the current situation
in parsing theory and practice very nicely.
In stating that parsing is not a solved problem,
Tratt realized he was taking on a consensus.
But the consensus is fading --
for example, neither side in the interchange
between
<a href="http://arxiv.org/abs/1010.5023">
Might/Darais</a>
and
<a href="http://research.swtch.com/yaccalive">
Russ Cox</a>
expresses complete
contentment with the state of the art.
<p>
What would be a real solution to the parsing problem?
I wish to suggest that
<a href="http://www.jeffreykegler.com/marpa">Marpa</a>
is that solution.
I say that based on a list of features.
Marpa is the first parser to have all of these features,
and I claim they are enough to justify the assertion
that, with Marpa,
parsing is no longer an unsolved problem.
Specifically,
<ol>
<li><p>Marpa parses everything you can write in BNF.
<li><p>Marpa parses in times considered theoretically optimal.
For unambiguous grammars, Marpa is never worse than O(n²).
For ambiguous grammars, Marpa is never worse than O(n³).
Marpa never goes exponential.
<li><p>
Marpa parses all
classes of grammar in practical use today in linear time, O(n).
Marpa is linear for all LR-regular grammars.
The LR-regular grammars include regular expressions,
LL(k) for all k,
and LR(k) for all k.
<li><p>A serious practical issue has been parse-time error detection.
Marpa breaks new ground here.
Marpa is fully aware, at every point in the parse, of
all the rules it is parsing,
how far into them it has proceeded,
and of what tokens it expects next.
This information is available
to the application
conveniently and efficiently.
<li><p>
Marpa parsers do not need to be handwritten.
Marpa is available as a open-source library.
It is written in C,
and the C library can be used
<a href="http://jeffreykegler.github.com/Marpa/libmarpa.html">
directly</a>
or via
<a href="https://metacpan.org/release/Marpa-R2">
a Perl interface</a>.
<li><p>
For general BNF parsing,
the user does not need to craft
a lookahead or backtracking strategy -- Marpa
does not use lookahead and never backtracks.
<li><p>
Marpa's complexity and correctness claims come
with the traditional theoretical apparatus of
proofs based on prior literature.
</ol>
<p>
In his post,
Tratt focuses his discontent on the problem of "language composition" -- the
problem of combining two grammars into one.
Tratt knew that an efficient and practical general BNF parser, like Marpa,
would make language composition easy.
But he was not aware that any such parser existed.
Language composition is a topic to which I hope to return.
<br />
<p>posted at: 20:07 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/08/the-solved-problem-that-isnt-is.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
</div>
</div>
<div id="footer" style="border-top:thick solid #38B0C0;clear:left;padding:1em;">
<p>This is Ocean of Awareness's
  new home.  This blog has been hosted at
  <a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>
  but I have succumbed to the lure of static blogging.
  I have not yet decided how to deal with comments at this new blog location.
If the post is Marpa-related,
<a href="https://groups.google.com/forum/?hl=en&fromgroups#%21forum/marpa-parser">
the Marpa mailing list</a>
is a good place to comment.
Also,
I will continue to dual-post for some time,
and have not yet frozen comments on the versions of the
post at
<a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>.
</div>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-33430331-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
</body>
</html>
