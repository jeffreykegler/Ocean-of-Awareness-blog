<html>
<head>
<link rel="alternate" title="Ocean of Awareness RSS" type="application/rss+xml" title="RSS" href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/index.rss" />
<title>Ocean of Awareness</title>
<style type="text/css">
   strong {font-weight: 700;}
</style>
</head>
<body>
<div
  style="color:white;background-color:#38B0C0;padding:1em;clear:left;text-align:center;">
<h1>Ocean of Awareness</h1>
</div>
  <div style="margin:0;padding:10px 30px 10px 10px;width:150px;float:left;border-right:2px solid #38B0C0">
  <p>
  <strong>Jeffrey Kegler's blog</strong>
  about Marpa, his new parsing algorithm,
    and other topics of interest</p>
  <p><a href="http://www.jeffreykegler.com/">Jeffrey's personal website</a></p>
      <p>
	<a href="https://twitter.com/jeffreykegler" class="twitter-follow-button" data-show-count="false">Follow @jeffreykegler</a>
      </p>
      <p style="text-align:center">
	<!-- Place this code where you want the badge to render. -->
	<a href="//plus.google.com/101567692867247957860?prsrc=3" rel="publisher" style="text-decoration:none;">
	<img src="//ssl.gstatic.com/images/icons/gplus-32.png" alt="Google+" style="border:0;width:32px;height:32px;"/></a>
      </p>
  <h3>Marpa resources</h3>
  <p><a href="http://jeffreykegler.github.com/Marpa-web-site/">The Marpa website</a></p>
  <p>The Ocean of Awareness blog: <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog">home page</a>,
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/chronological.html">chronological index</a>,
  and
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html">annotated index</a>.
  </p>
  </div>
  <div style="margin-left:190px;border-left:2px solid #38B0C0;padding:25px;">
<h3>Fri, 16 Nov 2012</h3>
<br />
<center><a name="iterative"> <h2>A Marpa tutorial: iterative parser development</h2> </a>
</center>
  <h3>Developing a parser iteratively</h3>
    <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
    This post is about how to write a parser complex parser a little bit
    at a time, testing as you go.
    You could also call this approach test-driven,
    or even extreme,
    although to my mind the term has never fit.
    The traditional approach, creating a huge mass of code and then one
    day putting it all together to see if it worked,
    strikes me as the "extreme" one.
    </p>
    <p>
    This tutorial will "iterative" a parser one development step.
    The parser we will use is the one from
    the last tutorial.
    That parsed a Perl subset.
    </p>
    <p>
    You may recall that previous tutorial was about pattern search.
    This illustrates another point --
    pattern search and iterative parser development are
    essentially the same thing,
    and the same approach can be used for both.
    Our first cut at a Perl parser will be doing a pattern search
    for the Perl subset it parses.
    This will allow us to check our progress.
    The subset we are attempting to parse is our "search target".
    When our "searches" succeed in finding all instances
    of the target,
    we have completed that subset,
    and can move on to the next step of the iteration.
    </p>
    <h3>What we need to do</h3>
    <p>
    This tutorial is the latest of
    <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL">
    a series</a>,
    each of which describes one self-contained template.
    In this tutorial we will take
    <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html">
    the previous tutorial</a>
    as the first iteration in the iterative development of a Perl parser.
     In this example, we will add two pieces.
     <ul>
     <li><p>The last step was more of a recognizer than a parser.
     In particular, its grammar was too simplified to support a semantics,
     even for the Perl subset it recognized.
     We'll fix that.
     <li>Having amplified the grammar, we will add a semantics,
     simple, but quite powerful enough to use in checking our progress
     in developing the parser.
     </ul>
     <h3>The grammar</h3>
     <p>Here  is our grammar from the previous post, all eight lines of it:
     <blockquote>
      <pre>
    <tt>
start ::= prefix target
prefix ::= any_token*
target ::= expression
expression ::=
       number | scalar | scalar postfix_op
    || op_lparen expression op_rparen assoc =&gt; group
    || unop expression
    || expression binop expression`
    </tt>
    </pre>
    </blockquote>
     These eight lines were enough to descibe arithmetic expressions sufficiently well
     for a recognizer, as well as to provide the "scaffolding" for the unanchored search.
     Nice compression, but now that we are talking about supporting a Perl semantics,
     we will need more.
     <p>Adding the appropriate grammar is a matter of turning to the
     <a href="http://perldoc.perl.org/perlop.html#Operator-Precedence-and-Associativity">
     appropriate section of the <tt>perlop</tt> man page</a>
     and copying what you see there.
     I have to change the format and come up with name for all the operators,
     but the process is pretty much rote, as you can see:
     <blockquote>
      <pre>
    <tt>
my $perl_grammar = Marpa::R2::Grammar-&gt;new(
    {   start          =&gt; 'start',
        actions        =&gt; 'main',
        default_action =&gt; 'do_what_I_mean',
        rules          =&gt; [ &lt;&lt;'END_OF_RULES' ]
start ::= prefix target action =&gt; do_arg1
prefix ::= any_token* action =&gt; do_undef
target ::= expression action =&gt; do_target
expression ::=
     number
   | scalar
   | op_lparen expression op_rparen assoc =&gt; group
  || op_predecrement expression
   | op_preincrement expression
   | expression op_postincrement
   | expression op_postdecrement
  || expression op_starstar expression assoc =&gt; right
  || op_uminus expression
   | op_uplus expression
   | op_bang expression
   | op_tilde expression
  || expression op_star expression
   | expression op_slash expression
   | expression op_percent expression
   | expression kw_x expression
  || expression op_plus expression
   | expression op_minus expression
  || expression op_ltlt expression
   | expression op_gtgt expression
  || expression op_ampersand expression
  || expression op_vbar expression
   | expression op_caret expression
  || expression op_equal expression assoc =&gt; right
  || expression op_comma expression
END_OF_RULES
    }
);
    </tt>
    </pre>
    </blockquote>
    <h3>The lexer</h3>
    <p>
    The lexer is table-driven.
    I've used this same approach to lexing in every post
    in this tutorial series.
    Those interested in
    an explanation of how the lexer works can
    <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html">
    find one in the first tutorial</a>.
    </p>
    <p>
    Having broken out the operators, I had to rewrite
    the lexing table,
    but that was even more more rote than the rewriting
    the grammar.
    I won't repeat the 
    lexer table here --
    it can be found in
    <a href="https://gist.github.com/4093504">the Github gist</a>.
    </p>
    <h3>Adding a semantics</h3>


     <blockquote>
      <pre>
    <tt>
## no critic (Subroutines::RequireFinalReturn)
sub do_undef       { undef; }
sub do_arg1        { $_[2]; }
sub do_what_I_mean { shift; return $_[0] if scalar @_ == 1; return \@_ }
## use critic
    </tt>
    </pre>
    </blockquote>

     <blockquote>
      <pre>
    <tt>
sub do_target {
    my $origin = ( Marpa::R2::Context::location() )[0];
    return if $origin != $ORIGIN;
    return $_[1];
} ## end sub do_target
    </tt>
    </pre>
    </blockquote>

     <blockquote>
      <pre>
    <tt>
my $end_of_search;
my @results = ();
RESULTS: while (1) {
    my ( $origin, $end ) =
        $self-&gt;last_completed_range( 'target', $end_of_search );
    last RESULTS if not defined $origin;
    push @results, [ $origin, $end ];
    $end_of_search = $origin;
} ## end RESULTS: while (1)
    </tt>
    </pre>
    </blockquote>

     <blockquote>
      <pre>
    <tt>
RESULT: for my $result ( reverse @results ) {
    my ( $origin, $end ) = @{$result};

    <big><b>... Print out the original text ...</b></big>

    $recce-&gt;set( { end =&gt; $end } );
    my $value;
    VALUE: while ( not defined $value ) {
        local $main::ORIGIN = $origin;
        my $value_ref = $recce-&gt;value();
        last VALUE if not defined $value_ref;
        $value = ${$value_ref};
    } ## end VALUE: while ( not defined $value )
    if ( not defined $value ) {
        say 'No parse'
            or die "say() failed: $ERRNO";
        next RESULT;
    }
    say Data::Dumper::Dumper($value)
        or die "say() failed: $ERRNO"
        if not $quiet_flag;
    $recce-&gt;reset_evaluation();
} ## end RESULT: for my $result ( reverse @results )
    </tt>
    </pre>
    </blockquote>


    <h3>Code and comments</h3>
    <p>The example in this post is available as
    <a href="https://gist.github.com/4093504">a Github gist</a>.
      It was run with
      <a href="https://metacpan.org/release/JKEGL/Marpa-R2-2.024000/">
      Marpa::R2 2.024000</a>,
      as of this writing the latest full release.
      Its main test, which is included in the gist,
      used displays from the
      <a href="http://perldoc.perl.org/perlop.html">perlop man page</a>.
    </p>
    <p>
      Comments on this post
      can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 21:10 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/iterative.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 11 Nov 2012</h3>
<br />
<center><a name="pattern_search"> <h2>A Marpa tutorial: pattern searches</h2> </a>
</center>
  <h3>Pattern searches</h3>
    <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      We use regular expressions for pattern searching these days.
      But what if your search target is not a regular expression?
      In this post I will show how to use Marpa to search text files for
      arbitrary context-free expressions.
    </p>
    <p>
      This tutorial builds on earlier tutorials.
      It is possible to simply dive into it,
      but it may be easier
      to start with two of my earlier posts,
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html">here</a>
      and
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">here</a>.
    </p>
    <h3>The grammar</h3>
    <p>
      I will use arithmetic expressions as
      the example of a search target.
      Even the arithmetic subset of Perl expressions is quite complex,
      but in this case we can get the job done
      with eight lines of grammar and a lexer driven
      by a table of just over a dozen lines.
      Here is the grammar:
    </p>
    <blockquote>
      <pre>
    <tt>
start ::= prefix target
prefix ::= any_token*
target ::= expression
expression ::=
       number | scalar | scalar postfix_op
    || op_lparen expression op_rparen assoc =&gt; group
    || unop expression
    || expression binop expression`
    </tt>
    </pre>
    </blockquote>
    <p>
      This grammar uses
      <a href="https://metacpan.org/module/Marpa::R2::BNF">
        Marpa::R2's BNF interface</a>.
      It takes considerable advantage of the fact that we are not
      <b>parsing</b>
      these expressions, but
      <b>recognizing</b>
      them.
      Because of this, we don't have to specify whether expressions left- or right-associate.
      We can also ignore what operators mean and group them according to syntax only
      -- binary, prefix unary and postfix unary.
      Similarly, we can ignore the precedence within these large groups.
      This leaves us with numbers, scalars,
      parentheses,
      and binary, prefix unary and postfix unary operators.
      (To keep this example simple, we restrict the primaries
      to numeric constants and Perl scalars.)
    </p>
    <p>
      What we are searching for is defined by the
      <tt>target</tt>
      symbol.
      For
      <tt>target</tt>
      you could substitute
      the start symbol of
      any context-free grammar,
      and the structure of this example will still work.
      To turn a parser for
      <tt>target</tt>
      into a pattern searcher, we add a new start
      symbol (unimaginatively named "<tt>start</tt>")
      and two rules that
      allow the target to have a
      <tt>prefix</tt>.
    </p>
    <h3>Ambiguous parsing</h3>
    <p>To do an anchorless pattern search,
      this example will use ambiguous parsing.
      This grammar always has at least one parse going,
      representing the prefix for
      the zero or more targets
      that our parser
      expects to find in the future.
      The prefix will never end, because
      any token (as indicated by a token
      named, literally,
      <tt>any_token</tt>)
      extends it.
    </p>
    <p>
      If we are in the process of recognizing a
      <tt>target</tt>,
      we will have one or more other parses going.
      I say "one or more" because the search method
      described in this post
      allows <tt>target</tt> to be ambiguous.
      But arithmetic expressions,
      the target pattern used in this example,
      are not ambiguous.
      So our example will have
      at most two parses active at any point:
      one for the prefix and another for the target.
    </p>
    <p>
      Ambiguous parsing has a serious potential downside --
      it is not necessarily linear
      and therefore not necessarily efficient.
      But Marpa can parse many classes of ambiguous grammar in linear time.
      Grammars like the one in this post --
      a prefix and an unambiguous search target --
      fall into one of the linearly parseable classes.
      Keeping the prefix going requires a tiny constant overhead per token.
    </p>
    <h3>The lexer table</h3>
    <p>
      The lexer is driven by a table of pairs: token name and regex.
    </p><blockquote>
      <pre>
<tt>
my @lexer_table = (
    [ number     =&gt; qr/(?:\d+(?:\.\d*)?|\.\d+)/xms ],
    [ scalar     =&gt; qr/ [\$] \w+ \b/xms ],
    [ postfix_op =&gt; qr/ [-][-] | [+][+] /xms ],
    [ unop       =&gt; qr/ [-][-] | [+][+] /xms ],
    [   binop =&gt; qr/
          [*][*] | [&gt;][&gt;] | [&lt;][&lt;]
        | [*] | [\/] | [%] | [x] \b
        | [+] | [-] | [&amp;] | [|] | [=] | [,]
    /xms
    ],
    [   unop =&gt; qr/ [-] | [+] | [!] | [~] /xms
    ],
    [ op_lparen =&gt; qr/[(]/xms ],
    [ op_rparen =&gt; qr/[)]/xms ],
);
</tt>
</pre>
    </blockquote>
    <p>
      Order is significant here.
      In particular
      two-character operators are checked for first.
      This guarantees that
      two consecutive minus signs
      will be seen as an
      decrement operator, and not as a double negation.
    </p>
    <h3>Ambiguous lexing</h3>
    <p>The very careful reader may have noticed that
      <tt>any_token</tt>
      is not in the lexing table.
      The main loop is written so that every token is read as an
      <tt>any_token</tt>.
      If no token from the lexing table is accepted,
      the next character in the input stream
      is read as an
      <tt>any_token</tt>.
      If a token from the lexing table
      <b>is</b>
      accepted,
      then it gets read twice,
      once as an
      <tt>any_token</tt>,
      and once as the token type taken from the lexing table
      entry.
    </p>
    <p>Ambiguous lexing is a familiar technique to
      the Natural Language Processing community.
      Engish, in particular, is a language that abounds
      in lexemes that can play multiple roles.
      The word "sort", for example, can easily be
      an noun, a verb or an adjective.
    </p>
    <h3>The Ruby Slippers</h3>
    <p>The main loop will also be a simple case of the use
      of the Ruby Slippers.
      For those unfamiliar,
      the "Ruby Slippers" parsing technique handles difficult lexing
      and parsing problems by asking the parser, at the problem point,
      what it is looking for,
      and providing it.
      This seems a fairly obvious approach,
      but the Ruby Slippers are new with Marpa --
      traditional parsers could not easily
      determine where they were in a parse.
    </p>
    <p>
      One way to use the Ruby Slippers is to ask the parser in
      advance what it is looking for.
      The code that follows uses another method.
      Instead of determining in advance what tokens to read,
      it simply feeds tokens to the parser.
    </p>
    <p>
      Token rejection is a "soft" error -- it costs
      little to try, and little to retry.
      The following code can
      efficiently determine which entry in the lexing table is appropriate,
      simply by trying each of them in order.
      If the
      <tt>alternative()</tt>
      method returns a Perl
      <tt>undef</tt>,
      indicating that a token was rejected,
      then the main loop will try later entries in the lexing table.
    </p>
    <p>
      When a token is accepted,
      the main loop can safely assume that it is on the right track.
      Marpa is 100% accurate about
      which tokens can and cannot result in a successful parse.
    </p>
    <h3>The main loop</h3>
    <p>
      The main loop iterates through input looking for tokens.
      Whitespace is skipped.
      Comments are not skipped.
      Finding arithmetic expressions in
      strings and/or comments can be useful.
      We will assume that is the case here.
    </p>
    <blockquote>
      <pre>
<tt>
my $length = length $string;
pos $string = $positions[-1];
TOKEN: while ( pos $string &lt; $length ) {
    next TOKEN if $string =~ m/\G\s+/gcxms;    # skip whitespace
    my $position = pos $string;
    FIND_ALTERNATIVE: {
        TOKEN_TYPE: for my $t (@lexer_table) {
            my ( $token_name, $regex ) = @{$t};
            next TOKEN_TYPE if not $string =~ m/\G($regex)/gcxms;
            if ( not defined $recce-&gt;alternative($token_name) ) {
                pos $string = $position;       # reset position for matching
                next TOKEN_TYPE;
            }
            $recce-&gt;alternative('any_token');
            last FIND_ALTERNATIVE;
        } ## end TOKEN_TYPE: for my $t (@lexer_table)
        ## Nothing in the lexer table matched
        ## Just read the currrent character as an 'any_token'
        pos $string = $position + 1;
        $recce-&gt;alternative('any_token');
    } ## end FIND_ALTERNATIVE:
    $recce-&gt;earleme_complete();
    my $latest_earley_set_ID = $recce-&gt;latest_earley_set();
    $positions[$latest_earley_set_ID] = pos $string;
} ## end TOKEN: while ( pos $string &lt; $length )
</tt>
</pre>
    </blockquote>
    <p>
      The
      <tt>earleme_complete()</tt>
      method tells Marpa that all the alternatives
      at one location have been entered,
      and that the parse should now move on to the next location.
      (Marpa's idea of location is called an "earleme", in honor of the great
      parsing theorist, Jay Earley.)
    </p>
    <h3>How to parse without really trying</h3>
    <p>
    At this point, I want to draw the reader's attention to the code
    that deals with special cases for the minus sign.
    Specifically, to the fact that there is no such code.
    The more familiar you are with PPI and/or
      <tt>perly.y</tt>,
      the more remarkable this will seem.
      </p>
      <p>
      To take one example, PPI correctly realizes that the minus
      sign in
      "<tt>1+2-3</tt>" is a binary operator.
      However PPI fails on "<tt>(1+2)-3</tt>" --
      it thinks the minus sign is part of the number "-3".
      Why don't the authors of PPI just look at the Perl
      interpreter and copy the logic there?
      Take a glance at <tt>perly.y</tt>
      and <tt>toke.c</tt> 
      and you will know the answer to that question.
      </p>
      <p>What is PPI's problem here?
      The problem is that,
      without knowing where you are in the expression,
      you cannot tell whether a minus sign is a unary
      operator or a binary operator.
      And the parse engines for PPI and for Perl itself,
      while quite different in many respects,
      share a property common to traditional parsers --
      in determining context
      they offer the lexer, respectively,
      little and no help.
      </p>
      <p>
      In the code in this example,
      Marpa's <tt>alternative()</tt> method is, by accepting
      and rejecting tokens, guiding the lexer to the right choice.
      Because of Perl's grammar, a minus sign at a given position
      cannot be both a unary operator and a binary operator.
      And Marpa is 100% accurate in its knowledge of which
      tokens are possible.
      So Marpa's
      <tt>alternative()</tt> method
      always knows whether a minus sign can be
      a unary or binary operator and accepts
      or rejects the token accordingly.
    </p>
    <p>
      This is the Ruby Slippers in action --
      a very simple solution to what for the Perl
      interpreter and PPI
      is a very complicated problem.
      When I developed the Ruby Slippers technique,
      my most serious problem 
      was convincing myself that something
      so simple could really work.
    </p>
    <h3>Finding the targets</h3>
    <p>
      Once the parse is complete, it remains to find
      and print the "targets" found
      by the search.
      In
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">
      a previous post</a>,
      I showed how, 
      given a symbol name,
      to find the last occurrence of the symbol in a Marpa parse.
      That routine needed to be modified to allow repeated searches,
      but the change was straightforward.
      The code is in the
      <a href="https://gist.github.com/4057239">
      gist</a>,
      and the ideas behind it were explained
      in
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">
      the previous post</a>,
      so I won't repeat them here.
    </p>
    <h3>Code and comments</h3>
    <p>The example in this post is available as
    <a href="https://gist.github.com/4057239">
      a Github gist</a>.
      It was run with
      <a href="https://metacpan.org/release/JKEGL/Marpa-R2-2.024000/">
      Marpa::R2 2.024000</a>,
      as of this writing the latest full release.
      My main test, which is included in the gist,
      used displays from the
      <a href="http://perldoc.perl.org/perlop.html">perlop man page</a>.
    </p>
    <p>
      Comments on this post
      can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 20:15 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 04 Nov 2012</h3>
<br />
<center><a name="self_parse"> <h2>A grammar that exemplifies, describes and parses itself</h2> </a>
</center>
  <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      I've written a grammar in Marpa's new BNF interface,
      to parse Marpa's new BNF interface.
      In the 70's, when I learned parsing theory,
      this was a very fashionable thing to do, perhaps because
      yacc had done it,
      in Appendix B of
      <a href="http://dinosaur.compilertools.net/yacc/">
        the original 1975 paper</a>.
      By 1979, Hoftstadter's book Godel-Escher-Bach (GEB) was out,
      and the next year it took the Pulitzer for
      General Nonfiction.
      Self-description, recursion, self-reference, self-embedding,
      you
      (preferably
      <a href="http://en.wikipedia.org/wiki/Autological_word">autologically</a>)
      name it,
      these things were all the rage.
    </p>
    <p>Reading code
    that is at once both self-example and self-description
    still holds a certain magic for me.
      Regular expressions cannot describe themselves.
      Recursive descent parsers are hand-written
      in another general-purpose language,
      so there can be no concise self-description.
      Ironically, yacc actually cannot parse its own description language.
      ("Ironically" is the word used in the paper.)
      Like almost all useful grammars, yacc's description language
      goes beyond the capabilities of yacc's LALR parser,
      and a lexer hack is needed to make the code in Appendix B work.
    </p>
    <p>Marpa is a general BNF parser and requires no special hacks
    to parse the following efficiently:
    </p>
    <blockquote>
      <pre>
rules ::= rule+ action => do_rules
rule ::= empty_rule | priority_rule | quantified_rule
priority_rule ::= lhs op_declare priorities
  action => do_priority_rule
empty_rule ::= lhs op_declare adverb_list
  action => do_empty_rule
quantified_rule ::= lhs op_declare name quantifier adverb_list
    action => do_quantified_rule
priorities ::= alternatives+
    separator => op_tighter proper => 1
    action => do_discard_separators
alternatives ::= alternative+
    separator => op_eq_pri proper => 1
    action => do_discard_separators
alternative ::= rhs adverb_list action => do_alternative
adverb_list ::= adverb_item* action => do_adverb_list
adverb_item ::=
      action
    | left_association | right_association | group_association
    | separator_specification | proper_specification

action ::= kw_action op_arrow name action => do_action
left_association ::= kw_assoc op_arrow kw_left
  action => do_left_association
right_association ::= kw_assoc op_arrow kw_right
  action => do_right_association
group_association ::= kw_assoc op_arrow kw_group
  action => do_group_association
separator_specification ::= kw_separator op_arrow name
  action => do_separator_specification
proper_specification ::= kw_proper op_arrow boolean
action => do_proper_specification

lhs ::= name action => do_lhs
rhs ::= names
quantifier ::= op_star | op_plus
names ::= name+ action => do_array
name ::= bare_name | reserved_word | quoted_name
name ::= bracketed_name action => do_bracketed_name

reserved_word ::= kw_action | kw_assoc | kw_separator | kw_proper
  | kw_left | kw_right | kw_group
</pre>
    </blockquote>
    <p>
    The conventions are standard or transparent.
    The "<tt>::=</tt>" symbol separates the left and right hand sides of rules.
    The "<tt>|</tt>" symbol separates alternative right hand sides.
    The "<tt>*</tt>" and
    "<tt>+</tt>" are quantifiers, similar to those in regular expressions,
    and indicate, respectively, zero or more repetitions and one or more repetitions
    of the preceding symbol.
    Adverbs take the form "<tt>keyword => value</tt>",
    and indicate semantics or the style of sequence separation.
    Full documentation can be found
    <a href="https://metacpan.org/module/JKEGL/Marpa-R2-2.023_010/pod/BNF.pod">
    here</a>.
    <p>
      Self-parsing compiler compilers ruled the earth
      in the age of bellbottoms.
      Self-parsing has lasted better, but not by much.
      When some years I wrote a self-describing language as an interface to
      Marpa, it seemed to confuse people.
      They wondered what Marpa did --
      parsing your own description did not seem to be
      about <b>doing</b> anything.
      These days my examples feature a lot of calculators.
      ("Ironically", Hofstadter seems to have had the same problem with
      GEB -- he felt that
      people did not understand what his book was saying --
      even those who liked it.)
    </p>
    <p>
      But ideas from Larry Wall and Peter Stuifzand
      have re-ignited my interest in self-parsing.
      And this time the self-parsing parser was written
      with a specific purpose.
      I plan to enhance this language.
      I have found that the convenience of this interface
      more than compensates for the circular
      dependency issues.
      The BNF source in this post is
      <a href="https://metacpan.org/source/JKEGL/Marpa-R2-2.023_010/lib/Marpa/R2/meta/Stuifzand.bnf">
      the source</a>
      for its own parser,
      and I plan to use it
      to produce improved versions
      of itself.
    </p>
    <h3>Comments</h3>
    <p>
      Comments on this post can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 16:00 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/self_parse.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Tue, 30 Oct 2012</h3>
<br />
<center><a name="error"> <h2>A Marpa DSL tutorial: Error reporting made easy</h2> </a>
</center>
  <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      Using
      Marpa's facilities for error reporting,
      a quickly written domain-specific language can,
      as of its first draft,
      have error reporting whose helpfulness and precision exceeds
      that of carefully hand-crafted production compilers.
      This post will show how, with an example.
    </p><p>
      Two techniques will be used.
      First and most basic,
      Marpa's knowledge of the point
      at which the parse
      can no longer proceed is 100% accurate and immediate.
      This is not the case with yacc-derived parsers,
      and is not the case with most recursive descent parsers.
    </p>
    <p>
      However, even Marpa's 100% accuracy in pinpointing
      the problem location is only accuracy
      in the technical sense -- it cannot take into account what the
      programmer intended.
      A second technique allows the programmer to double-check his
      intentions against what the parser has actually seen.
      Marpa can tell the programmer exactly how it thinks
      the input parsed, up to the point at which it could no
      longer proceed.
      The Marpa parser can report the answer to questions like
    </p><blockquote><p>
        "What was the last statement you successfully parsed?"<br>
        "What was the last expression you successfully parsed?"<br>
        "What was the last arithmetic expression you successfully parsed?"<br>
        "Where did the last successfully parsed block start?  End?"<br>
      </p>
    </blockquote>
    <h3>The language</h3>
    <p>
      To focus on the logic of the error reporting,
      I looked for a language that was error-prone,
      but extremely simple.
      For this purpose,
      prefix arithmetic is like a gift from the dakinis.
      It is almost trivial in concept,
      and almost impossible to get right when it is more than a few
      characters long.
      Two valid strings in this language are
      <q>say + 1 2</q>
      and
      <q>+++ 1 2 3 + + 1 2 4</q>.
      Their results are, in order, 3 and 13.
    </p><p>
      I restricted the calculator to addition, because even with one
      operator, prefix notation is more than confusing enough to serve our purposes.
      I have included an optional
      <tt>say</tt>
      keyword, in order
      to illustrate rejection of a token by type.
      In pure prefix arithmetic, either all tokens are valid or none are.
      The
      <tt>say</tt>
      keyword is only valid as the first token.
    </p><h3>The grammar</h3><p>
      The full code for this post is in
      <a href="https://gist.github.com/3974816">
        a Github gist</a>.
      It was run using
      <a href="https://metacpan.org/release/JKEGL/Marpa-R2-2.023_008">
        a release candidate for the full release of Marpa::R2</a>.
      Here is the grammar.
    </p><blockquote><pre><tt>
my $prefix_grammar = Marpa::R2::Grammar-&gt;new(
    {   start          =&gt; 'Script',
        actions        =&gt; 'My_Actions',
        default_action =&gt; 'do_arg0',
        rules          =&gt; [ &lt;&lt;'END_OF_RULES' ]
Script ::=
     Expression
   | kw_say Expression action =&gt; do_arg1
Expression ::=
     Number
   | op_add Expression Expression action =&gt; do_add
END_OF_RULES
    }
);
</tt></pre></blockquote>
    <p>The rules are specified in another DSL,
      of the kind I've used
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html">
        in previous posts</a>.
      This one is incorporated in Marpa::R2 itself,
      and is
      <a href="https://metacpan.org/module/JKEGL/Marpa-R2-2.023_008/pod/BNF.pod">
        documented here</a>.
      Here are its features relevant to this example:
    </p><dl>
      <dt><strong><tt>::=</tt></strong></dt>
      <dd>A BNF rule in LHS
        <tt>::=</tt>
        RHS form</dd>
      <dt><strong><tt>|</tt></strong></dt>
      <dd>Separates alternative RHS's at the
        <strong>same</strong>
        precedence level</dd>
      <dt><strong><tt>=&gt;</tt></strong></dt>
      <dd><tt>keyword =&gt; value</tt>, where
        <tt>keyword</tt>
        is the name of an adverb.</dd>
    </dl>
    <p>The
      "<tt>action =&gt; do_add</tt>"
      adverb indicates that the semantics for the alternative
      are in the Perl closure named
      <tt>do_add</tt>.
    </p><p>The rest of the grammar's definition will be familiar to Marpa users.
      <tt>Script</tt>
      is the start symbol,
      the Perl closures implementing semantics are to be found in the
      <tt>My_Actions</tt>
      package,
      and where no semantics are explicitly specified,
      the Perl closure
      <tt>do_arg0</tt>
      is the default.
    </p><h3>The semantics</h3>
    <p>The semantics for this example are easy.
    </p><blockquote><pre><tt>
sub My_Actions::do_add  { shift; return $_[1] + $_[2] }
sub My_Actions::do_arg0 { shift; return shift; }
sub My_Actions::do_arg1 { shift; return $_[1]; }
</tt></pre></blockquote>
    <p>
      The first argument to a Marpa semantic closure is a "per-parse variable",
      which is not used in this application.
      The other arguments are the values of the child nodes,
      as determined recursively and in lexical order.
    </p><h3>The lexing table</h3>
    <p>
      In this post,
      I am skipping around in the code --
      <a href="https://gist.github.com/3974816">
        the full code is in the gist</a>.
      But lexical analysis is of particular interest to new
      Marpa users.
      The lexer I use for this example is overkill --
      table-driven and using Perl's progressive matching
      capabilities, it is capable of serving a much more
      complex language.
      (I talked about lexing more
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html">
        in a previous example</a>.)
      Here is the lexing table:
    </p>
    <blockquote>
      <pre>
my @terminals = (
    [ Number =&gt; qr/\d+/xms,   'Number' ],
    [ op_add =&gt; qr/[+]/xms,   'Addition operator' ],
    [ kw_say =&gt; qr/say\b/xms, qq{"say" keyword} ],
);
</pre></blockquote>
    <p>The lexing table is an array of 3-element arrays.
      Each sub-array contains the symbol name, a regular expression
      that is used to recognize it, and a "long name",
      a human-readable name more appropriate for error messages
      than the symbol name.
      For some languages,
      the order of our lexing tables may be significant,
      although in the case of this language it makes no difference.
    </p>
    <h3>Types of parsing error</h3>
    <p>Before plunging into the error-handling code,
      I will describe the forms parsing errors take
      and the messages they produce.
    </p>
    <h4>No valid token</h4>
    <p>The lexer may reach a point in the input
      where it does not find one of the allowed tokens.
      An example in this language would be an input with an
      an exclamation point.
      This is no need to talk much about this kind of error,
      which has always been relatively easy to diagnose,
      pinpoint and, usually, to fix.
    </p>
    <h4>The parser rejects a token</h4>
    <p>
      In some cases the lexer finds a token,
      but it is not one
      that the parser will accept at that point,
      so the parser rejects the token.
      An example for this language would be the input
      "<tt>+ 1 say 2</tt>", which causes the following diagnostic:
    </p>
    <blockquote>
      <pre>
Last expression successfully parsed was:  1
A problem occurred here:  say 2
Parser rejected token ""say" keyword"
</pre>
    </blockquote>
    <p>Marpa successfully determined that
      "<tt>1</tt>" is a valid expression of the language, but
      "<tt>+ 1</tt>" is not.
    </p>
    <h4>The parser becomes exhausted</h4>
    <p>
      In other cases, the parser may "dead end" -- reach a point
      where no more input can be accepted.
      One example is with the input
      "<tt>+ 1 2 3 + + 1 2 4</tt>".
      This causes the following diagnostic:
    </p><blockquote><pre>
Last expression successfully parsed was: + 1 2
The parse became exhausted here: " 3 + + 1 2 4"
</pre></blockquote>
    <p>The parser has completed a prefix expression.
      Unlike infix and postfix expressions, once a prefix
      expression has been
      allowed to end
      there is no way to "extend" or "restart" it.
      The parse is "exhausted".
    </p><p>A second example of an exhausted parse
      occurs with the the input
      "<tt>1 + 2 +3  4 + 5 + 6 + 7</tt>".
      Here is the diagnostic:
    </p><blockquote><pre>
Last expression successfully parsed was: 1
The parse became exhausted here: " + 2 +3  4 + 5 + 6 + 7"
</pre></blockquote>
    <h4>The input is fully accepted, but there is no parse</h4><p>
      Finally, it may happen that lexer and parser read and accept
      the entire input, but do not find a valid parse in it.
      For example, if the input is
      "<tt>+++</tt>", the diagnostic will be:
    </p><blockquote><pre>
No expression was successfully parsed
No parse was found, after reading the entire input
</pre></blockquote>
    <p>The input was a good start for a prefix expression,
      but no numbers were ever found,
      and our DSL reports that it never recognized any
      prefix expressions.
    </p><p>A more complicated case is this input:
      "<tt>++1 2++</tt>".
      Here is what our DSL tells us:
    </p><blockquote><pre>
Last expression successfully parsed was: +1 2
No parse was found, after reading the entire input
</pre></blockquote>
    <p>
      Our DSL did find a good expression, and tells us where it was.
      If there is more than one good expression, our DSL tells us
      the most recent.
      With input "<tt>++1 2++3 4++</tt>",
      the diagnostic becomes
    </p><blockquote><pre>
Last expression successfully parsed was: +3 4
No parse was found, after reading the entire input
</pre></blockquote>
    <p>In fact, if we thought it would be helpful
      our DSL could show all the expressions found,
      or the last
      <i>N</i>
      expressions for some
      <i>N</i>.
      This is a simple language with nothing but expressions
      involving a single operator.
      More interesting languages will have statements and blocks,
      and layers of subexpressions.
      The logic below can be straightforwardly modified to show us
      as much about these as we think will be helpful.
    </p><h3>Parsing the DSL</h3>
    <blockquote><pre>
sub my_parser {
    my ( $grammar, $string ) = @_;
    my @positions = (0);
    my $recce = Marpa::R2::Recognizer-&gt;new( { grammar =&gt; $grammar } );

    my $self = bless {
        grammar   =&gt; $grammar,
        input     =&gt; \$string,
        recce     =&gt; $recce,
        positions =&gt; \@positions
        },
        'My_Error';

    my $length = length $string;
    pos $string = $positions[-1];

    <big><b>... "Reading the tokens" goes here ...</b></big>

    my $value_ref = $recce-&gt;value;
    if ( not defined $value_ref ) {
        die $self-&gt;show_last_expression(), "\n",
            "No parse was found, after reading the entire input\n";
    }
    return ${$value_ref};
} ## end sub my_parser
</pre></blockquote>
    <p>The above closure takes a grammar and an input string, and either produces a parse
      value,
      or a diagnostic telling us exactly why it could not.
      For truly helpful diagnostics, I find it necessary to be able to quote
      the input exactly.
      The
      <tt>@positions</tt>
      array will be used to map the locations that the Marpa
      parser uses back to positions in the original input string.
      Marpa location 0 is always before any input symbol, so it is initialized
      to string position 0.
    </p>
    <p>
      The
      <tt>$self</tt>
      object is a convenience.
      It collects the information the error handler needs,
      and allows an elegant syntax for the error-handling calls.
    </p>
    <p>The loop for reading tokens will be described below.
      After it, but before the
      <tt>return</tt>,
      is our first error check.
      "No parse" errors show up after all the tokens have been read,
      when the
      <tt>$recce-&gt;value()</tt>
      call returns a Perl
      <tt>undef</tt>.
      In that case,
      we produce the message we showed above.
      The tricky details are hidden in the
      <tt>show_last_expression()</tt>
      method,
      which we will come to.
    </p><h3>Reading the tokens</h3>
    <blockquote>
      <pre>
TOKEN: while ( pos $string &lt; $length ) {
    next TOKEN if $string =~ m/\G\s+/gcxms;    # skip whitespace
    if ( $recce-&gt;exhausted() ) {
	die $self-&gt;show_last_expression(), "\n",
	    q{The parse became exhausted here: "},
	    $self-&gt;show_position( $positions[-1] ), qq{"\n},
	    ;
    } ## end if ( $recce-&gt;exhausted() )

    <big><b>...  "Looping through the lexing table" goes here ...</b></big>

    die 'A problem occurred here: ',
	$self-&gt;show_position( $positions[-1] ), "\n",
	q{No valid token was found};
} ## end TOKEN: while ( pos $string &lt; $length )
</pre>
    </blockquote>
    <p>This loop implements part of our progressive matching
      within
      <tt>$string</tt>,
      and contains two of our four error checks.
      The
      <tt>exhausted()</tt>
      method check if the parse is
      exhausted,
      and again the hard work is done by the
      <tt>show_last_expression()</tt>
      method.
    </p><p>If we get through the lexing table without finding a token,
      we produce an invalid token message
      and report the position using the
      <tt>show_position()</tt>
      method.
      For invalid tokens, position should be all that
      the user needs to know.
      Position is also reported in the case of an exhausted parse.
      Implementation of the
      <tt>show_position()</tt>
      method presents
      no difficulties -- the code can be found in the gist.
    </p><h3>Looping through the lexing table</h3>
    <blockquote><pre>
TOKEN_TYPE: for my $t (@terminals) {
    my ( $token_name, $regex, $long_name ) = @{$t};
    next TOKEN_TYPE if not $string =~ m/\G($regex)/gcxms;
    if ( defined $recce-&gt;read( $token_name, $1 ) ) {
	my $latest_earley_set_ID = $recce-&gt;latest_earley_set();
	$positions[$latest_earley_set_ID] = pos $string;
	next TOKEN;
    }
    die $self-&gt;show_last_expression(), "\n",
	'A problem occurred here: ',
	$self-&gt;show_position( $positions[-1] ), "\n",
	qq{Parser rejected token "$long_name"\n};
} ## end TOKEN_TYPE: for my $t (@terminals)
</pre></blockquote>
    <p>
      Our innermost loop is through the lexing table,
      checking each table entry against the input string.
      If a match is found, the Marpa recognizer's
      <tt>read()</tt>
      method is called.
      This may fail due to our fourth and last type of error:
      a rejected token.
      Again,
      <tt>show_position()</tt>
      reports position
      and
      <tt>show_last_expression()</tt>
      does the interesting stuff.
    </p><h3>Showing the last expression</h3>
    <blockquote><pre><tt>
sub My_Error::show_last_expression {
    my ($self) = @_;
    my $last_expression =
        $self-&gt;input_slice( $self-&gt;last_completed_range('Expression') );
    return
        defined $last_expression
        ? "Last expression successfully parsed was: $last_expression"
        : 'No expression was successfully parsed';
} ## end sub My_Error::show_last_expression
</tt></pre></blockquote>
    <p>At its top level,
      <tt>show_last_expression()</tt>
      finds the parse locations of the last completed
      <tt>Expression</tt>
      symbol,
      using the
      <tt>last_completed_range()</tt>
      method.
      (In Marpa,
      as in other Earley parsers, a symbol or rule that has been recognized
      from start to finish is said to be "completed".)
      The parse locations are passed to the
      <tt>input_slice()</tt>
      method,
      which translates them into the corresponding substring of the input
      string.
    </p><blockquote>
      <pre>
sub My_Error::input_slice {
    my ( $self, $start, $end ) = @_;
    my $positions = $self-&gt;{positions};
    return if not defined $start;
    my $start_position = $positions-&gt;[$start];
    my $length         = $positions-&gt;[$end] - $start_position;
    return substr ${ $self-&gt;{input} }, $start_position, $length;
} ## end sub My_Error::input_slice
</pre>
    </blockquote>
    <h3>Finding the last successful parse of a symbol</h3>
    <p>The
      <tt>last_completed_range()</tt>
      method does the
      complicated part of the error handling -- finding the last
      successfully recognized ("completed")
      occurrence of a symbol.
      The
      <tt>last_completed_range()</tt>
      method does not use
      any internals, but it certainly gets technical
      in its use of the external methods.
      It or something like it
      is a prime candidate to be folded into the Marpa
      interface someday.
    </p><p>
      Successful recognitions of a symbol are called,
      again following standard Earley parsing terminology,
      "completions".
      Completions are recorded by rule,
      so the first thing that must be done is to turn the
      symbol name into a list of those rules which have
      that symbol on their left hand side.
      These are called the
      <tt>@sought_rules</tt>.
      We also need to initialize the loop by
      recording the last parse location ("latest Earley set").
      <tt>$earley_set</tt>
      will be our loop variable.
    </p>
    <blockquote><pre>
sub My_Error::last_completed_range {
    my ( $self, $symbol_name ) = @_;
    my $grammar      = $self-&gt;{grammar};
    my $recce        = $self-&gt;{recce};
    my @sought_rules = ();
    for my $rule_id ( $grammar-&gt;rule_ids() ) {
        my ($lhs) = $grammar-&gt;rule($rule_id);
        push @sought_rules, $rule_id if $lhs eq $symbol_name;
    }
    die "Looking for completion of non-existent rule lhs: $symbol_name"
        if not scalar @sought_rules;
    my $latest_earley_set = $recce-&gt;latest_earley_set();
    my $earley_set        = $latest_earley_set;

    <big><b>... "Traversing the Earley sets" goes here ...</b></big>

    return if $earley_set &lt; 0;
    return ( $first_origin, $earley_set );
} ## end sub My_Error::last_completed_range
</pre></blockquote>
    <p>
      Once we have traversed the Earley sets, we need only return
      the appropriate value.
      If the Earley set number fell below 0, we never found any completions
      of the "sought rules",
      a circumstance which we report with a bare
      <tt>return</tt>
      statement.
      Otherwise,
      <tt>$first_origin</tt>
      and
      <tt>$earley_set</tt>
      will be set to the first and last parse locations of the completion,
      and we return them.
    </p>
    <h3>Traversing the Earley sets</h3>
    <p>This is our final code sample, and the buck stops here.
      Marpa::R2 introduced more detailed user access to the progress reporting
      information, and
      <a href="https://metacpan.org/module/JKEGL/Marpa-R2-2.023_008/pod/Progress.pod">
        that interface</a>
      is used here.
    </p>
    <p>We traverse the Earley sets in reverse order,
      beginning with the latest and going back, if necessary to Earley set 0.
      For each Earley sets, there are "progress items", reports of the progress
      as of that Earley set.
      Of these, we are only interested in completions,
      which have a "dot position" of -1.
      (Those interested in a fuller explanation of "dot positions",
      progress items, and
      progress reports, can look in
      <a href="https://metacpan.org/module/JKEGL/Marpa-R2-2.023_008/pod/Progress.pod">
        the documentation for progress reports</a>.)
      Of the completions, we are interested only in those for one of
      the
      <tt>@sought_rules</tt>.
    </p>
    <p>
      For any given set of sought rules, more than one might end at
      an given Earley set.
      Usually we are most interested in the longest of these,
      and this logic assumes that we are only interested in the
      longest completion.
      We check if the start of the completion (its "origin") is prior to
      our current match, and if so its becomes our new
      <tt>$first_origin</tt>.
    </p>
    <p><tt>$first_origin</tt>
      was initialized to an non-existent Earley set,
      higher in number than any actual one.
      Once out of the loop through the progress items, we check if
      <tt>$first_origin</tt>
      is still at its initialized value.
      If so, we need to iterate backward one more Earley set.
      If not, we are done, and
      <tt>$first_origin</tt>
      and
      <tt>$earley_set</tt>
      contain the information that we were looking for -- the start and end
      locations of the most recent longest completion of one of the
      <tt>@sought_rules</tt>.
    </p><blockquote>
      <pre>
my $first_origin = $latest_earley_set + 1;
EARLEY_SET: while ( $earley_set &gt;= 0 ) {
    my $report_items = $recce-&gt;progress($earley_set);
    ITEM: for my $report_item ( @{$report_items} ) {
	my ( $rule_id, $dot_position, $origin ) = @{$report_item};
	next ITEM if $dot_position != -1;
	next ITEM if not scalar grep { $_ == $rule_id } @sought_rules;
	next ITEM if $origin &gt;= $first_origin;
	$first_origin = $origin;
    } ## end ITEM: for my $report_item ( @{$report_items} )
    last EARLEY_SET if $first_origin &lt;= $latest_earley_set;
    $earley_set--;
} ## end EARLEY_SET: while ( $earley_set &gt;= 0 )
</pre>
    </blockquote>
    <h3>Comments</h3>
    <p>
      Comments on this post can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 09:30 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 21 Oct 2012</h3>
<br />
<center><a name="config_html3"> <h2>Configuring the Ruby Slippers for HTML</h2> </a>
</center>
  <p>
      <!--
      perl ./marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      This post is part of
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html#PARSE_HTML">
        a series</a>
      describing Marpa::R2::HTML,
      a configurable HTML parser.
      The last two posts described how to change
      the context and contents of the HTML
      elements, both new and existing.
      This post describes how to configure
      optional start tags: how to change 
      which start tags
      are optional,
      and how to specify the circumstances
      in which they will be supplied.
    </p>
    <h3>How the parser works</h3>
    <p>
      In the first posts in this series I went into some detail describing
      my Marpa-based approach to HTML parsing.
      Briefly, it combines a parse engine using a "wishful thinking" grammar
      with a Ruby Slippers lexer.
      The "wishful thinking" grammar expects all elements,
      without exception,
      to have both start and end tags.
      This overstrict grammar demands tags even in cases
      where the
      <a href="http://www.w3.org/TR/1999/PR-html40-19990824/sgml/dtd.html#inline">
        HTML 4.01 Strict DTD</a>
      mandates that they be treated as optional.
    </p>
    <p>
      The overstrict grammar is liberalized by the Ruby Slippers.
      Marpa has an unusual property among parsers -- it is fully
      informed about the state of the parse at all points,
      and can conveniently and efficiently share that information
      with the application.
      In Marpa::R2::HTML, when the parse engine, with its
      overstrict grammar, grinds to a halt for lack
      of a tag that does not exist
      in the physical input,
      the lexer can ask the parse engine which tag it is looking for.
      It can then dummy one up, feed it to the parse engine,
      and start things back up.
      It's as simple as that.
    </p>
    <p>
      For HTML end tags,
      the Ruby Slippers work stunningly well.
      Only one end tag will be expected at any point.
      In cases where a stack of elements must be properly terminated,
      the parse engine will request the end tags, one at a time,
      in proper order.
      The grammar can simplify life for itself by demanding a perfect
      world, and on the lexer's side, things are no harder -- it just
      has to do what it is told.
    </p>
    <p>
      For the very few start tags
      that are optional according to the Strict HTML 4.01 DTD,
      things are just as simple -- they occur in places where only one
      at a time will be demanded, and the Ruby Slippers lexer need
      only do what it is told to.
      However, if you want to further liberalize HTML, there will be
      cases where there is a choice between start tags;
      or between
      starting one element and ending another.
    </p>
    <h3>Configuring the Ruby Slippers</h3>
    <p>
      In the last post,
      I showed how to configure Marpa::R2::HTML to allow or disallow
      text directly in the
      <tt>&lt;body&gt;</tt>
      element.
      If Marpa::R2::HTML
      was configured to disallow 
      text directly in the
      <tt>&lt;body&gt;</tt>
      element,
      and it encountered such text,
      Marpa::R2::HTML would start a block.
      The block was started
      by supplying a
      <tt>&lt;p&gt;</tt>
      start tag in front of the text.
      In other words, Marpa::R2::HTML treated
      the
      <tt>&lt;p&gt;</tt>
      start tag as optional.
    </p>
      Let me give an example.
      Suppose the HTML document consisted of the string
    </p>
    <blockquote>
      <pre><tt>Hello, world</tt></pre>
    </blockquote>
    <p>
      and that, using the default configuration,
      we ran <tt>html_fmt</tt> as  follows:
    </p>
    <blockquote>
      <pre><tt>echo 'Hello, world' |
/Users/jeffreykegler/perl5/bin/marpa_r2_html_fmt --no-added-tag-comment</tt></pre>
    </blockquote>
    <p>
      This would be our result:
    </p>
    <blockquote>
      <pre><tt>&lt;html&gt;
  &lt;head&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;p&gt;
      Hello, world
    &lt;/p&gt;&lt;/body&gt;
&lt;/html&gt;
</tt></pre>
    </blockquote>
    <p>
      This was produced using the default configuration,
      which resides in
      <a href="http://api.metacpan.org/source/JKEGL/Marpa-R2-2.022000/g/config/default.txt">
        the
        <tt>g/config/default.txt</tt>
        file</a>.
      (All the examples is this post use version 2.022000 of Marpa::R2.)
    </p>
    <h3>First, the results</h3>
    <p>
      Let's change the behavior of 
      Marpa::R2::HTML so that,
      instead of starting a new
      <tt>&lt;p&gt;</tt>
      element,
      it will reject the text as cruft.
      We create a new configuration,
      putting it into a file named
      <tt>g/config/reject_text.txt</tt>.
    <p>
      Creating the
      configuration will not be difficult,
      but it will perhaps be easiest to understand
      if we first see the result
      that we are aiming at.
      Again we run <tt>html_fmt</tt>:
    </p>
    <blockquote>
      <pre><tt>echo 'Hello, world' |
/Users/jeffreykegler/perl5/bin/marpa_r2_html_fmt \
  --compile reject_pcdata.txt  --no-added-tag-comment</tt></pre>
    </blockquote>
    <p>
      And this is our new result:
    </p><blockquote><pre><tt>&lt;html&gt;
  &lt;head&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;!-- html_fmt: Next line is cruft --&gt;
    Hello, world
&lt;/body&gt;
</tt></pre>
    </blockquote>
    <p>Note that in this second example, there are no tags
      for the
      <tt>&lt;p&gt;</tt>
      element,
      and that the text is now labeled as "cruft", as desired.
    </p>
    <h3>How it was done</h3>
    <p>
      How would we change the default configuration file to refuse to start a new
      <tt>&lt;p&gt;</tt>
      element in front of text?
      The three relevant lines are:
    </p>
    <blockquote>
      <pre><tt>@block_rubies  = &lt;html&gt; &lt;head&gt; &lt;body&gt;
@inline_rubies = @block_rubies &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;
PCDATA -&gt; @inline_rubies
</tt></pre>
    </blockquote>
    <p>The symbols with an "<tt>@</tt>" sigil are lists,
      which the configuration file uses as a convenient shorthand for groups
      of symbols which occur frequently.
      For convenience in this discussion,
      let's expand them, so that relevant extract looks like this
    </p>
    <blockquote>
      <pre><tt>PCDATA -&gt; &lt;html&gt; &lt;head&gt; &lt;body&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;</tt></pre>
    </blockquote>
    <p>
      In the configuration file,
      <tt>PCDATA</tt>
      can be thought of as non-whitespace text,
      occurring in a context which is parsed
      for markup and entities.
      (Precisely, it is whatever
      HTML::Parser returns as text that is not whitespace
      and does not turn on the
      <tt>is_cdata</tt>
      flag.)
      What this line says is that, whenever
      a <tt>PCDATA</tt> token
      is rejected,
      Marpa::R2::HTML should try to fix the problem as follows:
    </p>
    <ul>
      <li>1. If possible, start an
        <tt>&lt;html&gt;</tt>
        element.
      </li>
      <li>2. Otherwise, if possible, start a
        <tt>&lt;head&gt;</tt>
        element.
      </li>
      <li>3. Otherwise, if possible, start a
        <tt>&lt;body&gt;</tt>
        element.
      </li>
      <li>4. Otherwise, if possible, start a
        <tt>&lt;tbody&gt;</tt>
        element.
      </li>
      <li>5. Otherwise, if possible, start a
        <tt>&lt;tr&gt;</tt>
        element.
      </li>
      <li>6. Otherwise, if possible, start a
        <tt>&lt;td&gt;</tt>
        element.
      </li>
      <li>7. Otherwise, if possible, start a
        <tt>&lt;p&gt;</tt>
        element.
      </li>
      <li>8. Otherwise, if it is possible to end
        a non-structural or a 
        <tt>&lt;head&gt;</tt>
	element at this point, do so.
	(At any point, it will be possible to end
	at most one element.)
      </li>
      <li>9. Finally, if nothing else works, mark the "PCDATA" as cruft.
      </li>
    </ul>
    <p>
      Of these alternatives, the first three allow Marpa::R2::HTML to supply missing
      structural start tags, as required by the standards.
      Alternatives 4, 5 and 6 allow Marpa::R2::HTML to continue building a table
      if table-building is in progress.
      (But note that the line does not allow Marpa::R2::HTML
      to deal with rejected
      PCDATA by starting a new table.)
      Alternative 7 allows Marpa::R2::HTML to start a new
      <tt>&lt;p&gt;</tt>
      element if PCDATA is rejected.
      <p>
      Alternatives 8 and 9 are implicit.
      By default, after all the explicit Ruby Slippers
      alternatives have been tried,
      Marpa::R2::HTML will create a Ruby Slippers tags
      for any end tag that is allowed,
      with two exceptions:
      Marpa::R2::HTML will not create
      <tt>&lt;/body&gt;</tt> and
      <tt>&lt;/html&gt;</tt> end tags except at the end of file.
      And Marpa::R2::HTML always reserves the possibility of,
      as a last resort,
      labeling a token as "cruft" and moving on.
    </p>
    <p>
      Once you understand how the Ruby Slippers configuration lines work,
      the fix in this case becomes obvious:
      In the expanded line,
      elminate the
      <tt>&lt;p&gt;</tt>
      as one of the alternatives considered for the Ruby Slippers.
      In terms of the expanded line,
      this means changing it to
    </p>
    <blockquote>
      <pre><tt>PCDATA -&gt; &lt;html&gt; &lt;head&gt; &lt;body&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;</tt></pre>
    </blockquote>
    <p>
      In terms of the original set of lines,
      this means changing the one for the
      <tt>@inline_rubies</tt>
      list:
    </p>
    <blockquote>
      <pre><tt>@inline_rubies = @block_rubies &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;</tt></pre>
    </blockquote>
    <p>
      In the Ruby Slippers configuration lines of
      the default configuration file,
      the <tt>@inline_rubies</tt> list is the only place that
      the
      <tt>&lt;p&gt;</tt> tag is mentioned.
      So changing
      <tt>@inline_rubies</tt>
      has effect
      of eliminating
      <tt>&lt;p&gt;</tt>
      as an optional start tag.
      Only <tt>&lt;p&gt;</tt> tags actually in the physical
      input will be recognized.
      This is what was actually done
      in
      <a href="https://gist.github.com/3925571">
        <tt>g/config/reject_text.txt</tt>,
        the configuration file used in our example</a>.
    </p>
    <h3>Code and comments</h3>
    <p>
      Comments on this post can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 09:48 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/config_html3.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
</div>
</div>
<div id="footer" style="border-top:thick solid #38B0C0;clear:left;padding:1em;">
<p>This is Ocean of Awareness's
  new home.  This blog has been hosted at
  <a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>
  but I have succumbed to the lure of static blogging.
  I have not yet decided how to deal with comments at this new blog location.
If the post is Marpa-related,
<a href="https://groups.google.com/forum/?hl=en&fromgroups#%21forum/marpa-parser">
the Marpa mailing list</a>
is a good place to comment.
Also,
I will continue to dual-post for some time,
and have not yet frozen comments on the versions of the
post at
<a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>.
</div>
	<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-33430331-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
</body></html>
