<html>
<head>
<link rel="alternate" title="Ocean of Awareness RSS" type="application/rss+xml" title="RSS" href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/index.rss" />
<title>Ocean of Awareness</title>
<style type="text/css">
   strong {font-weight: 700;}
</style>
</head>
<body>
<div
  style="color:white;background-color:#38B0C0;padding:1em;clear:left;text-align:center;">
<h1>Ocean of Awareness</h1>
</div>
  <div style="margin:0;padding:10px 30px 10px 10px;width:150px;float:left;border-right:2px solid #38B0C0">
  <p>
  <strong>Jeffrey Kegler's blog</strong>
  about Marpa, his new parsing algorithm,
    and other topics of interest</p>
  <p><a href="http://www.jeffreykegler.com/">Jeffrey's personal website</a></p>
      <p>
	<a href="https://twitter.com/jeffreykegler" class="twitter-follow-button" data-show-count="false">Follow @jeffreykegler</a>
      </p>
      <p style="text-align:center">
	<!-- Place this code where you want the badge to render. -->
	<a href="//plus.google.com/101567692867247957860?prsrc=3" rel="publisher" style="text-decoration:none;">
	<img src="//ssl.gstatic.com/images/icons/gplus-32.png" alt="Google+" style="border:0;width:32px;height:32px;"/></a>
      </p>
  <h3>Marpa resources</h3>
  <p><a href="http://jeffreykegler.github.com/Marpa-web-site/">The Marpa website</a></p>
  <p>The Ocean of Awareness blog: <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog">home page</a>,
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/chronological.html">chronological index</a>,
  and
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html">annotated index</a>.
  </p>
  </div>
  <div style="margin-left:190px;border-left:2px solid #38B0C0;padding:25px;">
<h3>Sun, 07 Sep 2014</h3>
<br />
<center><a name="chron"> <h2>A parsing chronology</h2> </a>
</center>
<html>
  <head>
  </head>
  <body><p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
    </p>
<p><b>1960</b> -- The ALGOL 60 spec comes out.
It specifies, for the first time, a block structured
language.
The ALGOL committee is well aware
that
nobody know how to parse such a language,
but they are confident that if they specify a block-structured
language, a parser for it will be invented.
And they are right.
<p>In <b>1961</b>, Ned Irons publishes an ALGOL parser --
in fact the first parser of any kind ever described
in print.
Ned's algorithm was a form of recursive descent,
but unlike modern
recursive descent,
the Irons algorithm
is general and syntax-driven.
"General" means it can parse anything written in BNF.
"Syntax-driven" (aka declarative) means that parser is
actually created from the BNF -- an Irons parser does not need
to be hand-written.
<p><b>1965</b> -- Don Knuth invents LR parsing.  Knuth is mainly interested
in the mathematics.
He describes a parsing algorithm,
but it is not thought practical.
<p><b>1968</b> -- Jay Earley invents the algorithm named after him.
Like the Irons algorithm,
it is also syntax-driven and fully general.
Unlike the Irons algorithm, it does not backtrack.
Earley's core idea was to 
track everything about the parse in tables.
Earley's algorithm is enticing, but it has four serious issues.
First, there is a bug in the handling of null productions.
Second, it is quadratic for right recursions.
Third, the bookkeeping required to set up the tables is,
by the standards of 1968 hardware, daunting.
<p>
A fourth problem might be noted with Earley's algorithm --
there is no way to mix it with
hand-written, procedural logic.
This is not explicitly stated as a problem,
at least anywhere that I have seen,
but it definitely seems to have been felt.
By now, most parsers are left-parsers,
children of the Irons algorithm,
but hand-written instead of syntax-driven.
Left parsers turn out to be easy to custom hack.
<p>But the textbooks continue to discuss Earley's algorithm.
In <b>1972</b>, Aho and Ullmann describe
a straightforward fix to the null-production bug in Earley's original algorithm.
Unfortunately, this fix involves even more bookkeeping to the algorithm.
The search for an efficient, powerful, syntax-driven algorithm
seem to be at a dead-end until ...
<p>In <b>1969</b>,
a PhD thesis by Frank DeRemer describes a new variant of Knuth's LR
parsing.
DeRemer's LALR algorithm requires only
a stack and a state table of quite
manageable size.
The world takes notice.
<p>In <b>1975</b>,
Bell Labs converts its C compiler from hand-written recursive
descent to DeRemer's LALR algorithm.
<p>In <b>1977</b>,
the first "Dragon book" comes out.
The nickname of this classic textbooks comes from the drawing
on the front cover, in which a knight takes on a dragon.
Emblazoned on his lance are the letters "LALR".
From here on,
to speak lightly of LALR will be to besmirch the escutcheon
of parsing theory.
Earley's original algorithm had a bug, to which Aho
and Ullman's vast two volume suggests a straightforward
remedy, but this fix slows
down an algorithm
whose speed was already an issue.
<p>In <b>1987</b>, Larry Wall introduces Perl 1.
The very complex parsers of Perls 1 through 5
represent the
high water mark in the application of LALR.
Earley's algorithm, however,
has not been forgotten by everyone, because ...
<p>In <b>1991</b>, Joop Leo discovers a way of speeding up right
recursions in Earley's algorithm.
With Leo's improvement, Earley's algorithm
is now linear for just about every unambiguous grammar of
practical interest, and many ambiguous ones as well.
And Earley's parsing is now very far off the radar.
Joop's discovery is especially important,
because since the bookkeeping issue had also become
far less relevant.
1991 hardware was six orders of magnitude faster
than 1968 hardware.
But Earley's parsing is now far off the radar.
Despite the significance of this result,
For the next 20 years,
Joop's algorithm
attracts no practical implementations.
This is not to say that everyone in 
LALR-land was content.
Far from it, in fact ...
<p>In <b>2000</b>, Larry Wall decides on a radical reimplementation
of Perl -- Perl 6.  He does not even consider using LALR again.
Practitioners have discovered that, while LALR automatically
generates a parser for you, it is so hard to debug that it's
just as easy to write one by hand.
Worse, once written, an LALR parser,
while efficient with correct inputs,
provides little clue as to why an incorrect input is correct.
In Larry's words, LALR is "fast but stupid".
Discontent with LALR
is also spreading inside academia ...
<p>In <b>2002</b>
Aycock&Horspool describe a attempt to speed up Earley's in practice.
Buried in their paper is a solution to the null-production bug --
one that requires no additional bookkeeping.
They do not include Joop Leo's improvement --
they seem not to be aware of it.
And their own speedup is limited in what it achieves
and introduces complications.
The Aycock&Horpsool has little effect on practical parsing.
On the other hand,
nothing can slow the fall of LALR from favor.
<p>In <b>2006</b>,
GNU announces that the GCC compiler's parser has been
completely rewritten.
For past three decades, the flagship C compilers had been
parsed with LALR.
No more.
LALR is replaced by the 1960's technology that
it originally replaced.
Recursive descent is the once-and-future algorithm.
<p>The retreat from LALR causes a collapse in the
prestige of parsing theory.
The result of more than a half century of
research is exactly zero.
If you took Ned Iron's original 1961 algorithm,
and republished it today under another name,
you could easily describe it as
being not just state of the art,
but as having ground-breaking new features as well.
<p>Around <b>2010</b>, I noticed that the 
long-abandoned vision of
an efficient, practical, general and syntax-driven parser --
was now quite possible.
The pices were all there.
Aycock&Hospool has solved the null-production bug.
Joop Leo had found the speedup for right recursion.
As an issue, bookkeeping overhead had nearly lost relevance.
machines operations are now a billion times faster than in 1968,
and in any case
have ceased to be the relevant metric --
caches misses are more important.
<p>But one issue had become more relevant.
In the 1970's,
a purely declarative approach to parsing -- 100% syntax-driven --
was very acceptable to the 1970's programming community --
syntax-driven was cool.
Modern programmers has been
forced to fall back on hand-written recursive descent,
and are reluctant to abandon the methods which has proved reliable.
<p>
The Marpa algorithm combines the work of Jay Earley,
Aycock&Horspool and Leo, but it has an addition of my own --
it allows the application to switch back and forth between
declarative and procedural logic.
Marpa is actually more helpful
for procedural logic than recursive descent.
Marpa's Earley engine has available, and can share,
full information about the current state of the parse.
    <h3>Comments</h3>
    <p>
      Comments on this post can be made in
      <a href="http://groups.google.com/group/marpa-parser">
        Marpa's Google group</a>.
    </p>
  </body>
</html>
<br />
<p>posted at: 16:50 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2014/09/chron.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Mon, 01 Sep 2014</h3>
<br />
<center><a name="website"> <h2>Marpa has a new web page</h2> </a>
</center>
<html>
  <head>
  </head>
  <body><p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      Marpa has
      <a href="http://savage.net.au/Marpa.html">a
      new official public website</a>,
      which Ron Savage has generously agreed to manage.
      For those who have not heard of it,
      Marpa is a parsing algorithm.
      It is new, but very much based
      on earlier work by Jay Earley, Joop Leo, John Aycock and R. Nigel Horspool.
      Marpa is intended to replace, and to go well beyond,
      recursive descent and the yacc family of parsers.
    </p><ul>
      <li>
        Marpa is fast. It parses in linear time:
        <ul>
          <li>all the grammar classes that recursive descent parses;</li>
          <li>the grammar class that the yacc family parses;</li>
          <li>in fact, all unambiguous grammars, as long as they are free of unmarked middle recursions;
	  and</li>
	  <li>all
	  ambiguous grammars that are unions of a finite set of any of the above grammars.</li>
        </ul>
      </li>
      <li>
        Marpa is powerful. Marpa will parse anything that can be
	written in BNF.
	This includes any mixture of left, right and middle recursions.
      </li>
      <li>Marpa is convenient.
      Unlike recursive descent, you do not have to write a parser --
      Marpa generates one from BNF.
      Unlike PEG or yacc, parser generation is unrestricted and exact.
      Marpa converts any grammar which can be written as BNF
      into a parser which recognizes everything
      in the language described by that BNF, and which rejects everything that is
      not in that language.
      The programmer is not forced to make arbitrary choices while parsing.
      If a rule has several alternatives,
      all of the alternatives are considered for as long as they might yield a valid parse.
      </li>
      <li>
        Marpa is flexible. Like recursive descent, Marpa allows you to stop and
        do your own custom processing. Unlike recursive descent, Marpa makes available
        to you detailed information about the parse so far --
        which rules and symbols have been recognized, with their locations,
        and which rules and symbols are expected next.
      </li>
      </ul>
    <h3>Comments</h3>
    <p>
      Comments on this post can be made in
      <a href="http://groups.google.com/group/marpa-parser">
        Marpa's Google group</a>.
    </p>
  </body>
</html>
<br />
<p>posted at: 20:17 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2014/09/website.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Mon, 18 Aug 2014</h3>
<br />
<center><a name="ambig"> <h2>Language design: Exploiting ambiguity</h2> </a>
</center>
<html>
  <head>
  </head>
  <body><p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      Currently, in designing languages,
      we don't allow ambiguities --
      not even potential ones.
      We insist that it must not be
      even
      <b>possible</b>
      to write an ambiguous program.
      This is unnecessarily restrictive.
    </p>
    <p>
      This post is written in English, which is full of ambiguities.
      Natural languages are always ambiguous,
      because human beings find that that's best way for versatile,
      rapid, easy communication.
      Human beings arrange things so that every
      sentence is unambiguous in context.
      Mistakes happen, and ambiguous sentences occur,
      but in practice, the problem is manageable.
      In a conversation, for example,
      we would just ask for clarification.
    </p>
    <p>
      If we allow our computer languages to take their most natural forms,
      they will often have the
      <b>potential</b>
      for ambiguity.
      This is even less of a problem on a computer than it is in
      conversation -- a computer can always spot an actual ambiguity
      immediately.
      When
      <b>actual</b>
      ambiguities occur, we can deal with them
      in exactly the same way that we deal with
      any other syntax problem:
      The computer catches it and reports it,
      and we fix it.
    </p>
    <h3>An example</h3>
    <p>
      To illustrate,
      I'll use a DSL-writing DSL language.
      It'll be tiny -- just lexeme declarations and BNF rules.
      Newlines will
      <b>not</b>
      be significant.
      Statements can end with a semicolon, but that's optional.
      (The code for this post is in
      <a href="https://gist.github.com/jeffreykegler/ed64bf00983f7be666bc">
        a Github gist</a>.)
    </p>
    <p>Here is a toy calculator written in our tiny DSL-writing language:
    </p><blockquote>
      <pre>
  Number matches '\d+'
  E ::= T '*' F
  E ::= T
  T ::= F '+' Number
  T ::= Number
</pre>
    </blockquote>
    <h3>Trying an improvement</h3>
    <p>With a grammar this small, just about
      <b>anything</b>
      is readable.
      But let's assume we want to improve it, and that we decide
      that the lexeme declaration of
      <tt>Number</tt>
      really belongs
      after the rules which use it.
      (If our grammar was longer, this could make a real difference.)
      So we move the lexeme declaration to the end:
    </p><blockquote>
      <pre>
  E ::= T '*' F
  E ::= T
  T ::= F '+' Number
  T ::= Number
  Number matches '\d+'
</pre>
    </blockquote>
    <h3>But there's an issue</h3>
    <p>
      It turns out the grammar for our toy DSL-writer is ambiguous.
      When a lexeme declaration follows a BNF rule,
      there's no way to tell whether or not it is actually a
      lexeme declaration, or part of the BNF rule.
      Our parser catches that:
    </p><blockquote>
      <pre>
Parse of BNF/Scanless source is ambiguous
Length of symbol "Statement" at line 4, column 1 is ambiguous
  Choices start with: T ::= Number
  Choice 1, length=12, ends at line 4, column 12
  Choice 1: T ::= Number
  Choice 2, length=33, ends at line 5, column 20
  Choice 2: T ::= Number\nNumber matches '\\d
</pre></blockquote>
    <p>
      Here Marpa tells you why it thinks your script is ambiguous.
      Two different statements can start at line 4.
      Both of them are BNF rules, but one is longer than the other.
    </p>
    <h3>Just another syntax error</h3>
    <p>Instead of having to design a language where ambiguity was not
      even possible, we designed one where ambiguities can happen.
      This allows us to design a much more flexible language,
      like the ones we choose when we humans communicate with each other.
      The downside is that actual ambiguities will occur,
      but they can be reported, and fixed,
      just like any other syntax error.
    </p><p>In this case, we
      recall we allowed semi-colons to terminate a rule,
      and our fix is easy:
    </p>
    <p>
    </p><blockquote>
      <pre>
  E ::= T '*' F
  E ::= T
  T ::= F '+' Number
  T ::= Number ;
  Number matches '\d+'
</pre>
    </blockquote>
    <h3>To learn more</h3>
    <p>
      The code for this post is
      <a href="https://gist.github.com/jeffreykegler/ed64bf00983f7be666bc">
        a gist on Github</a>.
      It was written using
      <a href="https://metacpan.org/module/Marpa::R2">Marpa::R2,
        which is available on CPAN</a>.
      A list of my Marpa tutorials can be found
      <a href="http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL">
        here</a>.
      There are
      new tutorials by
      <a href="http://marpa-guide.github.io/chapter1.html">Peter Stuifzand</a>
      and
      <a href="http://longanswers.blogspot.de/2013/06/transforming-syntax.html">amon</a>.
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/">
        The Ocean of Awareness blog</a>
      focuses on Marpa,
      and it has
      <a href="http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html">an annotated guide</a>.
      Marpa has
      <a href="http://jeffreykegler.github.com/Marpa-web-site/">a web page that I maintain</a>
      and Ron Savage maintains
      <a href="http://savage.net.au/Perl-modules/html/marpa.papers/index.html">
        another</a>.
      For questions, support and discussion, there is
      <a href="http://groups.google.com/group/marpa-parser">
        a "marpa parser"
        Google Group</a>
      and an IRC channel:
      <tt>#marpa</tt>
      at
      <tt>irc.freenode.net</tt>.
    </p>
    <h3>Comments</h3>
    <p>
      Comments on this post can be made in
      <a href="http://groups.google.com/group/marpa-parser">
        Marpa's Google group</a>.
    </p>
  </body>
</html>
<br />
<p>posted at: 14:12 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2014/08/ambig.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Mon, 10 Mar 2014</h3>
<br />
<center><a name="kv"> <h2>Evolvable languages</h2> </a>
</center>
<html>
  <head>
  </head>
  <body><p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      Ideally, if a syntax is useful and clear,
      and a programmer can easily read it at a glance,
      you should be able to add it to an existing language.
      In this post, I will describe
      a modest incremental change to the Perl syntax.
    </p>
    <p>
      It's one I like, because that's beside the point, for two
      reasons.
      First, it's simply intended as an example of language evolution.
      Second, regardless of its merits, it is unlikely to happen,
      because of the way that Perl 5 is parsed.
      In this post I will demonstrate a way of writing a parser,
      so that this change,
      or others, can be made in a straightforward way,
      and without designing your language into a corner.
    </p>
    <p>
      When initializing a hash, Perl 5 allows you to use not just commas,
      but also the so-called "wide comma" (<tt>=&gt;</tt>).
      The wide comma is suggestive visually, and it also has some smarts
      about what a hash key is:
      The hash key is always converted into a string, so that wide comma
      knows that in a key-value pair like this:
    </p><blockquote>
      <pre>
    key1 => 711,
</pre>
    </blockquote><p>
      that
      <tt>key1</tt>
      is intended as a string.
    </p>
    <p>
      But what about something like this?
    </p>
    <blockquote>
      <pre>
  {
   company name => 'Kamamaya Technology',
   employee 1 => first name => 'Jane',
   employee 1 => last name => 'Doe',
   employee 1 => title => 'President',
   employee 2 => first name => 'John',
   employee 2 => last name => 'Smith',
   employee 3 => first name => 'Clarence',
   employee 3 => last name => 'Darrow',
  }
</pre>
    </blockquote><p>
      Here I think the intent is obvious -- to create an employee database in the form
      of a hash of hashes, allowing spaces in the keys.
      In Data::Dumper format, the result would look like:
    </p><blockquote>
      <pre>
{
              'employee 2' => {
                                'last name' => '\'Smith\'',
                                'first name' => '\'John\''
                              },
              'company name' => '\'Kamamaya Technology\'',
              'employee 3' => {
                                'last name' => '\'Darrow\'',
                                'first name' => '\'Clarence\''
                              },
              'employee 1' => {
                                'title' => '\'President\'',
                                'last name' => '\'Doe\'',
                                'first name' => '\'Jane\''
                              }
            }
</pre>
    </blockquote>
    <p>And in fact, that is the output of the script in
      <a href="https://gist.github.com/jeffreykegler/9478391">
    this Github gist</a>,
        which parses the previous "extended Perl 5" snippet using a Marpa
        grammar before passing it on to Perl.
      </p>
      <p>Perl 5 does not allow a syntax like this,
      and looking at its parsing code will tell you why -- it's already
      a maintenance nightmare.
      The extension I've described above could, in theory, be added to Perl
      5, but doing so would aggravate an already desperate maintenance situation.
    <p>
      Now, depending on taste,
      you may be just as happy that you'll never
      see the extensions I have just outlined in Perl 5.
      But I don't think it is as easy to
      be happy about a parsing technology that
      quickly paints the languages which use it into a corner.
    </p>
    <h3>How it works</h3>
    <p>
      The code is in
      <a href="https://gist.github.com/jeffreykegler/9478391">
        a Github gist</a>.
	For the purposes of the example, I've implemented
	a toy subset of Perl.
	But this approach has been shown to scale.
	There are full Marpa-powered parsers of
	<a href="https://metacpan.org/release/MarpaX-Languages-C-AST">C</a>,
	<a href="https://metacpan.org/release/MarpaX-Languages-ECMAScript-AST">ECMAScript</a>,
	<a href="https://metacpan.org/release/MarpaX-xPathLike">XPath</a>, and
	<a href="https://metacpan.org/pod/distribution/Marpa-R2/html/pod/HTML.pod">liberal HTML</a>.
    </p>
    <p>Marpa is a general BNF parser, which means that anything you can write in BNF, Marpa can parse.
    For practical parsing, what matters are those grammars that can be parsed in linear time,
    and with Marpa that class is vast, including all the classes of grammar currently in practical use.
    To describe the class of grammars that Marpa parses in linear time,
    assume that you have either a left or right parser,
    with infinite lookahead,
    that uses regular expressions.
    (A parser like this is called LR-regular.)
    Assume that this LR-regular parser parses your grammar.
    In that case,
    you can be sure that
    Marpa will parse that grammar in linear time, and without doing the lookahead.
    (Instead Marpa tracks possibilities in a highly-optimized table.)
    Marpa also parses many grammars that are not LR-regular in linear time,
    but just LR-regular is very likely to include any class of grammar that you will be
    interested in parsing.
    The LR-regular grammars easily include all those that can be
    parsed using yacc, recursive descent or regular expressions.
    </p>
    <p>
    Marpa excels at those special hacks so necessary in recursive descent and other techniques.
    Marpa allows you to define events that will stop it at symbols or rules, both before and after.
    While stopped,
    you can hand processing over to your own custom code.
    Your custom code can feed your own tokens to the parse for as long as you like.
    In doing so, it can
    consult Marpa to determine exactly what symbols and rules have been recognized and
    which ones are expected.
    Once finished with custom processing,
    you can then ask Marpa to pick up again at any point you wish.
    </p>
    <h3>The craps game is over</h3>
    <p>The bottom line is that if you can describe your language extension in BNF,
    or in BNF plus some hacks,
    you can rely on Marpa parsing it in reasonable time.
    Language design has been like shooting crap in a casino
    that sets you up to
    win a lot of the first rolls before
    the laws of probability grind you down.
    Marpa changes the game.
    </p>
    <h3>To learn more</h3>
    <p>
      <a href="https://metacpan.org/module/Marpa::R2">Marpa::R2
        is available on CPAN</a>.
      A list of my Marpa tutorials can be found
      <a href="http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL">
        here</a>.
      There are
      new tutorials by
      <a href="http://marpa-guide.github.io/chapter1.html">Peter Stuifzand</a>
      and
      <a href="http://longanswers.blogspot.de/2013/06/transforming-syntax.html">amon</a>.
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/">
        The Ocean of Awareness blog</a>
      focuses on Marpa,
      and it has
      <a href="http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html">an annotated guide</a>.
      Marpa has
      <a href="http://jeffreykegler.github.com/Marpa-web-site/">a web page that I maintain</a>
      and Ron Savage maintains
      <a href="http://savage.net.au/Perl-modules/html/marpa.papers/index.html">
        another</a>.
      For questions, support and discussion, there is
      <a href="http://groups.google.com/group/marpa-parser">
        the "marpa parser"
        Google Group.</a>
    </p>
    <h3>Comments</h3>
    <p>
      Comments on this post can be made in
      <a href="http://groups.google.com/group/marpa-parser">
      Marpa's Google group</a>.
      </p>
  </body>
</html>
<br />
<p>posted at: 19:48 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2014/03/kv.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Tue, 25 Feb 2014</h3>
<br />
<center><a name="semantic_ws"> <h2>Significant newlines?  Or semicolons?</h2> </a>
</center>
<html>
  <head>
  </head>
  <body><p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      Should statements have explicit terminators, like the semicolon of Perl and
      the C language?
      Or should they avoid the clutter, and separate statements by giving whitespace
      syntactic significance and a real effect on
      the semantics,
      as is done in Python and Javascript?
    </p>
    <p>
      Actually we don't have to go either way.
      As an example, let's look at some BNF-ish DSL.
      It defines a small calculator.
      At first glance, it looks as if this language has taken the
      significant-whitespace route -- there certainly are no explicit statement
      terminators.
    </p>
    <blockquote>
      <pre>
:default ::= action =&gt; ::first
:start ::= Expression
Expression ::= Term
Term ::=
      Factor
    | Term '+' Term action =&gt; do_add
Factor ::=
      Number
    | Factor '*' Factor action =&gt; do_multiply
Number ~ digits
digits ~ [\d]+
:discard ~ whitespace
whitespace ~ [\s]+
</pre>
    </blockquote>
    <h3>The rule is that there isn't one</h3>
    <p>
      If we don't happen to like the layout of the above DSL,
      and rearrange it in various ways,
      we'll find that everything we try works.
      If we become curious about what exactly what the rules for newlines are,
      and look at
      <a href="https://metacpan.org/pod/distribution/Marpa-R2/pod/Scanless/DSL.pod">
        the documentation</a>,
      we won't find any.
      That's because there aren't any.
    </p>
    <p>
      We can see this by thoroughly messing up the line structure:
    </p>
    <blockquote>
      <pre>
:default ::= action =&gt; ::first :start ::= Expression Expression ::= Term
Term ::= Factor | Term '+' Term action =&gt; do_add Factor ::= Number |
Factor '*' Factor action =&gt; do_multiply Number ~ digits digits ~
[\d]+ :discard ~ whitespace whitespace ~ [\s]+
</pre>
    </blockquote>
    <p>The <a href="https://gist.github.com/jeffreykegler/9220695">
      script</a> will continue to run just fine.
    </p>
    <h3>How does it work?</h3>
    <p>How does it work?
      Actually, pose the question this way:
      Can a human reader tell where the statements end?
      If the reader is not used to reading BNF,
      he might have trouble with this
      particular example but,
      for a language that he knows, the answer is simple:
      Yes, of course he can.
      So really the question is,
      why do we expect the parser to be so stupid that it cannot?
    </p>
    <p>
      The only trick is that this is done without trickery.
      Marpa's DSL is
      <a href="https://metacpan.org/source/JKEGL/Marpa-R2-2.080000/lib/Marpa/R2/meta/metag.bnf">
        written in itself</a>,
      and Marpa's self-grammar describes exactly what a statement is
      and what it is not.
      The Marpa parser is powerful enough to simply take this self-describing DSL
      and act on it, finding where statements begin and end,
      much as a human reader is able to.
    </p>
    <h3>To learn more</h3>
    <p>
      This example was produced with the Marpa parser.
      <a href="https://metacpan.org/module/Marpa::R2">Marpa::R2
        is available on CPAN</a>.
      The code for this example is based on that in
      the synopsis for its top-level document,
      but it is isolated conveniently in
      <a href="https://gist.github.com/jeffreykegler/9220695">
        a Github gist</a>.
    </p><p>
    </p><p>
      A list of my Marpa tutorials can be found
      <a href="http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL">
        here</a>.
      There are
      new tutorials by
      <a href="http://marpa-guide.github.io/chapter1.html">Peter Stuifzand</a>
      and
      <a href="http://longanswers.blogspot.de/2013/06/transforming-syntax.html">amon</a>.
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/">
        The Ocean of Awareness blog</a>
      focuses on Marpa,
      and it has
      <a href="http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html">an annotated guide</a>.
      Marpa has
      <a href="http://jeffreykegler.github.com/Marpa-web-site/">a web page that I maintain</a>
      and Ron Savage maintains
      <a href="http://savage.net.au/Perl-modules/html/marpa.papers/index.html">
        another</a>.
      For questions, support and discussion, there is
      <a href="http://groups.google.com/group/marpa-parser">
        the "marpa parser"
        Google Group.</a>
      Comments on this post can be made there.
    </p>
  </body>
</html>
<br />
<p>posted at: 15:30 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2014/02/semantic_ws.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
</div>
</div>
<div id="footer" style="border-top:thick solid #38B0C0;clear:left;padding:1em;">
<p>This is Ocean of Awareness's
  new home.  This blog has been hosted at
  <a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>
  but I have succumbed to the lure of static blogging.
</div>
	<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-33430331-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
</body></html>
