<html>
<head>
<link rel="alternate" title="Ocean of Awareness RSS" type="application/rss+xml" title="RSS" href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/index.rss" />
<title>Ocean of Awareness</title>
<style type="text/css">
   strong {font-weight: 700;}
</style>
</head>
<body>
<div
  style="color:white;background-color:#38B0C0;padding:1em;clear:left;text-align:center;">
<h1>Ocean of Awareness</h1>
</div>
  <div style="margin:0;padding:10px 30px 10px 10px;width:150px;float:left;border-right:2px solid #38B0C0">
  <p>
  <strong>Jeffrey Kegler's blog</strong>
  about Marpa, his new parsing algorithm,
    and other topics of interest</p>
  <p><a href="http://www.jeffreykegler.com/">Jeffrey's personal website</a></p>
      <p>
	<a href="https://twitter.com/jeffreykegler" class="twitter-follow-button" data-show-count="false">Follow @jeffreykegler</a>
      </p>
      <p style="text-align:center">
	<!-- Place this code where you want the badge to render. -->
	<a href="//plus.google.com/101567692867247957860?prsrc=3" rel="publisher" style="text-decoration:none;">
	<img src="//ssl.gstatic.com/images/icons/gplus-32.png" alt="Google+" style="border:0;width:32px;height:32px;"/></a>
      </p>
  <h3>Marpa resources</h3>
  <p><a href="http://jeffreykegler.github.com/Marpa-web-site/">The Marpa website</a></p>
  <p>The Ocean of Awareness blog: <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog">home page</a>,
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/chronological.html">chronological index</a>,
  and
  <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html">annotated index</a>.
  </p>
  </div>
  <div style="margin-left:190px;border-left:2px solid #38B0C0;padding:25px;">
<h3>Sat, 29 Dec 2012</h3>
<br />
<center><a name="self_lex"> <h2>A self-parsing and self-lexing grammar</h2> </a>
</center>
  <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      In a previous post, I showed a self-parsing grammar,
      written in Marpa's new BNF interface.
      This post does the same for Marpa's forthcoming
      Scanless interface.
      Many readers will no doubt
      prefer to be introduced to the Scanless interface
      via a simpler example,
      but from the response to the previous past I know
      there are others who see the fascination of
      self-description and self-exemplification.
    </p><p>
      The previous self-parsing grammar,
      following the tradition, cheated a bit.
      It required, but did not include, a lexer to make a prepass over
      its input.
      This self-parsing scannerless grammar is as completely self-contained
      as it can get.
      It is the complete and ultimate authority on its own syntax.
      It does not describe its own semantics,
      but even a self-describing Turing machine has to be written
      assuming the semantics of a Turing machine.
      So that's one limit that is probably going to stand.
    </p><p>
      In terms of being a practical example, this is as practical
      as they come.
      This grammar I will describe is the one actually used not
      only to parse itself and all other grammars written in the
      Scanless language,
      but also to parse the strings written
      in the BNF interface,
      it non-scannerless predecessor.
      So this grammar is an
      authority, if an over-liberal one,
      on the syntax
      of the BNF interface as well,
      with the exception that it is over-liberal.
      (Constructs allowed in the Scanless interface, but prohibited
      in the BNF interface are caught when the semantics are processed.)
    </p><p>
      The grammar in this blog post is abridged a bit,
      and rearranged for ease of explanation.
      The original that is actually used for self-parsing can be
      found here.
    </p><blockquote>
      <pre>
# Copyright 2012 Jeffrey Kegler
</pre></blockquote>
    <p>The file starts with legalese -- it goes on to say that it is LGPL 3.0.
      Note the hash comment -- since they is a self-describing self-lexer,
      it is eventually going to have to tell us how it deals with comments.
    </p>
    <blockquote>
      <pre>
:start ::= rules
rules ::= rule+
rule ::= &lt;start rule&gt; | &lt;empty rule&gt; | &lt;priority rule&gt; | &lt;quantified rule&gt; | &lt;discard rule&gt;
</pre></blockquote>
    <p>Next it tells us that the
      <tt>rules</tt>
      symbol is the start symbol,
      that file consists of a series of one or more rules,
      and that rules fall into one of five types.
      The last rule, with the LHS
      <tt>rule</tt>
      is self-describing -- among the
      options it lists, it is a
      <tt>&lt;priority rule&gt;</tt>.
      In the previous two lines are two of the other possibilities:
      a
      <tt>&lt;start rule&gt;</tt>
      and a
      <tt>&lt;quantified rule&gt;</tt>.
    </p><blockquote>
      <pre>
&lt;start rule&gt; ::= (':start' &lt;op declare bnf&gt;) symbol
&lt;op declare bnf&gt; ~ '::='
</pre></blockquote>
<p>
      The parentheses can be ignored -- they are to help out the semantics.
      (Symbols inside parentheses can be ignored by the semantics.)
      Here we see the description of a start rule:
      the
      <tt>:start</tt>
      pseudo-symbol,
      and an
      <tt>::=</tt>
      operator,
      followed by a
      <tt>symbol</tt>.
    </p>
    <blockquote>
      <pre>
&lt;quantified rule&gt; ::= lhs &lt;op declare&gt; &lt;single symbol&gt; quantifier &lt;adverb list&gt;
lhs ::= &lt;symbol name&gt;
&lt;op declare&gt; ::= &lt;op declare bnf&gt; | &lt;op declare match&gt;
&lt;op declare match&gt; ~ '~'
quantifier ::= '*' | '+'
</pre></blockquote>
    <p>Above we saw a quantified rule: "<tt>rules ::= rule+</tt>"
      It contains a left hand side (LHS) symbol name
      one of the two declaration operators,
      a
      <tt>single symbol</tt>,
      a plus or minus "quantifier",
      and an adverb list.
      The adverb list can be empty, which it was in that case.
    </p><p>
      Next come two rules we've yet to see:
    </p>
    <blockquote>
      <pre>
&lt;discard rule&gt; ::= (':discard' &lt;op declare match&gt;) &lt;single symbol&gt;
&lt;empty rule&gt; ::= lhs &lt;op declare&gt; &lt;adverb list&gt;
</pre></blockquote>
    <p>
      We'll explain what a "discard rule" is when we encounter one.
      An empty rule is what is sounds like.
      Note that an empty rule can have an adverb list.
    </p>
    <blockquote>
      <pre>
&lt;priority rule&gt; ::= lhs &lt;op declare&gt; priorities
priorities ::= alternatives+
    separator =&gt; &lt;op loosen&gt; proper =&gt; 1
&lt;op loosen&gt; ~ '||'
alternatives ::= alternative+
    separator =&gt; &lt;op equal priority&gt; proper =&gt; 1
alternative ::= rhs &lt;adverb list&gt;
&lt;op equal priority&gt; ~ '|'
</pre></blockquote>
    <p>
      Most rules, including most of the rules we've already seen,
      are priority rules,
      so-called because in their most complicated form they can express
      a precedence scheme.
      The typical rule in a grammar is a priority rule with only
      one priority -- we've yet to see anything else.
      Within priorities, there can be alternatives,
      and we have seen example of this.
      When
      <tt>rule</tt>
      was defined as being one of a set of possible
      rule types, priority rule being among those types,
      the different types of rule were alternatives within a single
      priority.
    </p>
    <p>We've used
      <tt>symbol</tt>,
      <tt>&lt;symbol name&gt;</tt>,
      and
      <tt>&lt;single symbol&gt;</tt>
      a few times.
      It's time to see how they are defined:
    </p>
    <blockquote>
      <pre>
&lt;single symbol&gt; ::=
    symbol
  | &lt;character class&gt;
symbol ::= &lt;symbol name&gt;
&lt;symbol name&gt; ::= &lt;bare name&gt;
&lt;symbol name&gt; ::= &lt;bracketed name&gt;
</pre></blockquote>
    <p>At this point,
      <tt>symbol</tt>
      and
      <tt>&lt;symbol name&gt;</tt>
      are
      essentially the same thing:
      someday there may be another way to specify symbols
      except by name.
      <tt>&lt;single symbol&gt;</tt>
      means any expression guaranteed
      to produce a single symbol.
      <tt>symbol</tt>
      is obviously one;
      a character class is the other.
    </p><p>Now that we know what a symbol can be,
      let's look at how right hand sides are built up:
    </p>
    <blockquote>
      <pre>
rhs ::= &lt;rhs primary&gt;+
&lt;rhs primary&gt; ::= &lt;single symbol&gt;
&lt;rhs primary&gt; ::= &lt;single quoted string&gt;
&lt;rhs primary&gt; ::= &lt;parenthesized rhs primary list&gt;
&lt;parenthesized rhs primary list&gt; ::= ('(') &lt;rhs primary list&gt; (')')
&lt;rhs primary list&gt; ::= &lt;rhs primary&gt;+
</pre></blockquote>
    <blockquote>
      <pre>
&lt;adverb list&gt; ::= &lt;adverb item&gt;*
&lt;adverb item&gt; ::=
      action
    | &lt;left association&gt; | &lt;right association&gt; | &lt;group association&gt;
    | &lt;separator specification&gt; | &lt;proper specification&gt;

action ::= ('action' '=&gt;') &lt;action name&gt;
&lt;left association&gt; ::= ('assoc' '=&gt;' 'left')
&lt;right association&gt; ::= ('assoc' '=&gt;' 'right')
&lt;group association&gt; ::= ('assoc' '=&gt;' 'group')
&lt;separator specification&gt; ::= ('separator' '=&gt;') &lt;single symbol&gt;
&lt;proper specification&gt; ::= ('proper' '=&gt;') boolean

&lt;action name&gt; ::= &lt;bare name&gt;

:discard ~ whitespace
whitespace ~ [\s]+

# allow comments
:discard ~ &lt;hash comment&gt;
&lt;hash comment&gt; ~ &lt;terminated hash comment&gt; | &lt;unterminated
   final hash comment&gt;
&lt;terminated hash comment&gt; ~ '#' &lt;hash comment body&gt; &lt;vertical space char&gt;
&lt;unterminated final hash comment&gt; ~ '#' &lt;hash comment body&gt;
&lt;hash comment body&gt; ~ &lt;hash comment char&gt;*
&lt;vertical space char&gt; ~ [\x{A}\x{B}\x{C}\x{D}\x{2028}\x{2029}]
&lt;hash comment char&gt; ~ [^\x{A}\x{B}\x{C}\x{D}\x{2028}\x{2029}]


boolean ~ [01]
&lt;bare name&gt; ~ [\w]+
&lt;bracketed name&gt; ~ '&lt;' &lt;bracketed name string&gt; '&gt;'
&lt;bracketed name string&gt; ~ [\s\w]+

# In single quotes strings and character classes
# no escaping or internal newlines, and disallow empty string

&lt;single quoted string&gt; ~ ['] &lt;string without single quote or vertical space&gt; [']
&lt;string without single quote or vertical space&gt; ~ [^'\x{0A}\x{0B}\x{0C}\x{0D}\x{0085}\x{2028}\x{2029}]+

&lt;character class&gt; ~ '[' &lt;cc string&gt; ']'
&lt;cc string&gt; ~ &lt;cc character&gt;+
&lt;cc character&gt; ~ &lt;escaped cc character&gt; | &lt;safe cc character&gt;
&lt;escaped cc character&gt; ~ '\' &lt;horizontal character&gt;
# hex 5d is right square bracket
&lt;safe cc character&gt; ~ [^\x{5d}\x{0A}\x{0B}\x{0C}\x{0D}\x{0085}\x{2028}\x{2029}]

# a horizontal character is any character that is not vertical space
&lt;horizontal character&gt; ~ [^\x{A}\x{B}\x{C}\x{D}\x{2028}\x{2029}]
</pre>
    </blockquote>
    <p>
    </p>
    <h3>Semantics</h3>
    <p>The Scanless interface's meta-grammar, is unusual in its semantics
      because it serves a dual purpose -- it is also the grammar for Marpa's
      BNF interface, which has a different semantics.
      In practice, a grammar is usually tied tightly to one semantics,
      but this is an exception.
    </p><p>
      For most grammars in either the Marpa's BNF or Scanless interface,
      the semantics would be specified using
      <tt>action</tt>
      adverbs.
      For this grammar, there are no
      <tt>action</tt>
      adverbs -- internally,
      Marpa waits until it knows which interface the grammar will be used for,
      then uses the symbol names to determine the actions on a "just in time"
      basis.
    </p><p>
      Standard applications will
      labeling rules and alternatives with
      <tt>action</tt>
      adverbs.
      Example of this are in the documentation for the BNF
      and Scanless interfaces.
    </p><h3>Comments</h3>
    <p>
      Comments on this post can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 19:03 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/12/self_lex.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 02 Dec 2012</h3>
<br />
<center><a name="whitespace"> <h2>Smart whitespace and the Ruby Slippers</h2> </a>
</center>
  <h3>Scannerless parsing</h3>
    <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      I've been working
      on a "scannerless" Marpa interface.
      "Scannerless" means that the user does not need to write
      a separate lexer --
      the lexer (scanner) is included in the parser.
      One of my working examples is
      the synopsis from
      <a href="https://metacpan.org/module/Marpa::R2">
        the main Marpa::R2 POD page</a>,
      rewritten to do its own lexing:
    </p>
    <blockquote>
      <pre>
    <tt>
:start ::= Expression
Expression ::=
       Number
    || Expression '*' Expression action => do_multiply
    || Expression '+' Expression action => do_add
Number ~ digits '.' digits action => do_literal
Number ~ digits action => do_literal
digits ~ [\d]+
    </tt>
      </pre>
    </blockquote>
    <p>Here the notation is that of
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/iterative.html">
        my last post</a>,
      as
      <a href="https://metacpan.org/module/Marpa::R2::BNF">
        documented here</a>.
      New for the scannerless parser are
    </p><ul>
      <li>
        the
        <tt>:start</tt>
        pseudo-symbol, which indicates the start rule;
      </li><li>
        rules with a tilde ("<tt>~</tt>") to separate
        LHS from RHS: these indicate rules whose
        whitespace is to be left as-is
      </li><li>single-quoted strings, to tell Marpa which
        character to look for; and
      </li><li>square-bracketed character classes, to
        tell Marpa to look for a class of characters.
        Their interpretation is done by Perl,
        and therefore the allowed classes are exactly those
        accepted by your version of Perl.
      </li></ul>
    <p>
      Valid strings in this language are "<tt>15329 + 42 * 290 * 711</tt>",
      "<tt>42*3+7</tt>",
      "<tt>3*3+4* 4</tt>",
      along with all their whitespace variants.
    </p>
    <p>My recent posts have been tutorial.
      My work on scannerless parsing is
      not quite ready for a tutorial presentation,
      so this post will be conceptual.
      It is about an interesting issue that arises in
      scannerless parsing,
      one which Perl 6 also had to solve,
      and which Marpa solves in a new and different way.
      That issue is whitespace.
    </p>
    <h3>Dealing with whitespace</h3>
    <p>For the statements with a declaration operator of
      <tt>::=</tt>,
      whitespace is handled automatically by Marpa.
      Valid strings in the above language are
      "<tt>42*3+7</tt>",
      "<tt>42 * 3 + 7</tt>" and
      "<tt>42 * 3+7</tt>",
      all of which yield 133 as the answer.
      The trick is to, on one hand, allow whitespace to be optional
      and, on the other hand, recognize that strings like "<tt>42</tt>"
      must be a single number.
      That is, the parser should not recognize optional whitespace
      between the two digits and decide that
      "<tt>42</tt>",
      is actually two numbers:
      "<tt>4</tt>" and
      "<tt>2</tt>".
    </p>
    <p>
      The Perl 6 project has already taken on scannerless parsing.
      My methods for dealing with whitespace are based on theirs.
      Central to
      their solution is "smart whitespace".
      ("Smart whitespace" is my term --
      the
      <a href="http://perlcabal.org/syn/S05.html">
        Perl 6 doc</a>
      is more matter-of-fact.)
      Smart whitespace is whitespace which is optional, except between
      word characters.
      Stated another way, smart whitespace is either explicit whitespace,
      or a word boundary.
      In the case of "<tt>42</tt>",
      "<tt>4</tt>" and
      "<tt>2</tt>" are both word characters, so there is no
      word boundary between them, and therefore no smart whitespace.
    </p>
    <h3>Implementing smart whitespace</h3>
    <p>
      Left parsers (like that which Perl 6 uses)
      often know very little about the context of the parse.
      But left parsers do know the current "character transition" --
      what the previous character was,
      and what the current character is.
      In a left parser, finding word boundaries for the
      purpose of detecting smart whitespace fits in
      nicely with the way it works in general.
    </p>
    <p>Marpa, of course,
      also knows the previous and current characters.
      It is certainly possible for
      Marpa to check every transition for a word boundary.
      But in Marpa's case, this check would
      be an additional overhead, handling just one special case.
      It'd be nice if we could look for word boundaries in a cool Marpa-ish way,
      preferably one with efficiency advantages.
    </p>
    <h3>Out come the Ruby Slippers</h3>
    <p>"Ruby Slippers" parsing, as a reminder, is new with Marpa,
      despite seeming a very obvious concept.
      It amounts to adjusting the input to the parser based on what
      the parser wants.
      This can be seen as assuring the parser that whatever it wishes
      for will happen, the same power that was conferred on Dorothy
      in
      <em>Wizard of Oz</em>
      by a happy choice of footware.
    </p>
    <p>
      To make the Ruby Slippers work in this case,
      we make a word boundary a special kind of virtual token,
      and we define smart whitespace to be one of two things:
    </p><ul>
      <li>
        A sequence of one or more characters of
        real, physical whitespace.
      </li><li>
        A virtual word-boundary token.
      </li></ul><p>
      We then proceed normally with the parse,
      until there's a problem.
      When the parser reports a problem,
      we ask it if it is looking for one
      of the virtual word boundary tokens.
      If so, we give it one and continue.
      Why does life have to be difficult?
    </p>
    <p>
      Comments on this post
      can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 08:51 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/12/whitespace.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 25 Nov 2012</h3>
<br />
<center><a name="announce_r2"> <h2>Announcing a full release of Marpa::R2</h2> </a>
</center>
  <h3>Announcing Marpa::R2</h3>
    <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
    <p>
      <a href="https://metacpan.org/release/Marpa-R2">
        Marpa::R2</a>
      is now in full, official release.
      For those new to this blog, Marpa::R2 is an efficient, practical general
      BNF parser, targeted at applications too complex for
      regular expressions.
      Marpa::R2 is based on
      <a href="http://jeffreykegler.github.com/Marpa-web-site/">
        the Marpa parsing algorithm</a>.
      New, but squarely based on the published literature,
      the Marpa algorithm
      parses every class of grammar in practical use today
      in linear time.
    </p>
    <p>Marpa::R2 is the successor to Marpa::XS and
    </p>
    <ul>
      <li>
        <p>installs and runs on Windows.
        </p>
      </li>
      <li>
        <p>has better error reporting.
        </p>
      </li>
      <li>
        <p>is faster.
        </p>
      </li>
      <li>
        <p>
          has a cleaner, simpler interface.
        </p>
      </li>
    </ul>
    <p>
    <a href="https://metacpan.org/module/Marpa::XS">Marpa::XS</a>
    remains available and,
      since changes to it are now on a "bug fix only" basis,
      should be quite stable.
      While Marpa::R2's interface will have a familiar look
      to users of Marpa::XS, it is not fully compatible:
      <a href="https://metacpan.org/module/Marpa::R2::Changes">
      changes are documented here</a>.
    </p>
    <p>
      Those who have been following this blog may have noticed
      that
      <a href="https://metacpan.org/module/Marpa::R2::BNF">
      a new BNF interface</a>
      has been added to Marpa::R2.
      This is growing --
      I am currently adding scannerless parsing to it,
      which means that applications will be able to run
      Marpa::R2 without a lexer.
      Because the BNF interface is new
      and still under very active development,
      it is being kept in beta status for the time being.
    </p>
    <h3>Comments</h3>
    <p>
      The Windows port of Marpa was the work of Jean-Damien Durand,
      who utilized Alberto Sim&otilde;es'
      <a href="http://search.cpan.org/dist/Config-AutoConf/">
        Config::AutoConf</a>.
      Comments on this post
      can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 16:38 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/announce_r2.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 18 Nov 2012</h3>
<br />
<center><a name="iterative"> <h2>A Marpa tutorial: iterative parser development</h2> </a>
</center>
  <h3>Developing a parser iteratively</h3>
    <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      This post describes a manageable way
      to write a complex parser,
      a little bit at a time, testing as you go.
      This tutorial will "iterate" a parser
      through one development step.
      As the first iteration step,
      we will use the example parser from
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html">
        the previous tutorial in this series</a>,
      which parsed a Perl subset.
    </p>
    <p>
      You may recall that the topic of that previous tutorial was pattern search.
      Pattern search and iterative parser development are
      essentially the same thing,
      and the same approach can be used for both.
      Each development stage of our Perl parser will do a pattern search
      for the Perl subset it parses.
      We can use the accuracy of this pattern search
      to check our progress.
      The subset we are attempting to parse is our "search target".
      When our "searches" succeed in finding all instances
      of the target,
      we have successfully written a parser for that subset,
      and can move on to the next step of the iteration.
    </p>
    <h3>What we need to do</h3>
    <p>
      This tutorial is the latest of
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL">
        a series</a>,
      each of which describes one self-contained example of a Marpa-based parser.
      In this tutorial we use the example from
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html">
        the previous tutorial</a>
      as the first iteration step
      in the iterative development of a Perl parser.
      For the iteration step in this example, we will add two features.
    </p><ul>
      <li><p>The previous iteration step was more of a recognizer than a parser.
          In particular, its grammar was too simplified to support a semantics,
          even for the Perl subset it recognized.
          We will fix that.
        </p></li><li>Having amplified the grammar, we will add a semantics,
        simple, but quite powerful enough to use in checking our progress
        in developing the parser.
      </li></ul>
    <h3>The grammar</h3>
    <p>
    Here is our grammar from the previous post:
    </p><blockquote>
      <pre>
    <tt>
start ::= prefix target
prefix ::= any_token*
target ::= expression
expression ::=
       number | scalar | scalar postfix_op
    || op_lparen expression op_rparen assoc =&gt; group
    || unop expression
    || expression binop expression
    </tt>
    </pre>
    </blockquote><p>
    <a href="https://metacpan.org/module/Marpa::R2::BNF">
      The format is documented here</a>.
      These eight lines were enough to descibe arithmetic expressions sufficiently well
      for a recognizer, as well as to provide the "scaffolding" for the unanchored search.
      Nice compression, but now that we are talking about supporting a Perl semantics,
      we will need more.
    </p><p>Adding the appropriate grammar is a matter of turning to the
      <a href="http://perldoc.perl.org/perlop.html#Operator-Precedence-and-Associativity">
        appropriate section of the
        <tt>perlop</tt>
        man page</a>
      and copying it.
      I needed to change the format and name the operators,
      but the process was pretty much rote, as you can see:
    </p><blockquote>
      <pre>
    <tt>
my $perl_grammar = Marpa::R2::Grammar-&gt;new(
    {   start          =&gt; 'start',
        actions        =&gt; 'main',
        default_action =&gt; 'do_what_I_mean',
        rules          =&gt; [ &lt;&lt;'END_OF_RULES' ]
start ::= prefix target action =&gt; do_arg1
prefix ::= any_token* action =&gt; do_undef
target ::= expression action =&gt; do_target
expression ::=
     number
   | scalar
   | op_lparen expression op_rparen assoc =&gt; group
  || op_predecrement expression
   | op_preincrement expression
   | expression op_postincrement
   | expression op_postdecrement
  || expression op_starstar expression assoc =&gt; right
  || op_uminus expression
   | op_uplus expression
   | op_bang expression
   | op_tilde expression
  || expression op_star expression
   | expression op_slash expression
   | expression op_percent expression
   | expression kw_x expression
  || expression op_plus expression
   | expression op_minus expression
  || expression op_ltlt expression
   | expression op_gtgt expression
  || expression op_ampersand expression
  || expression op_vbar expression
   | expression op_caret expression
  || expression op_equal expression assoc =&gt; right
  || expression op_comma expression
END_OF_RULES
    }
);
    </tt>
    </pre>
    </blockquote>
    <h3>The lexer</h3>
    <p>
      The lexer is table-driven.
      I've used this same approach to lexing in every post
      in this tutorial series.
      Those interested in
      an explanation of how the lexer works can
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html">
        find one in the first tutorial</a>.
      Having broken out the operators, I had to rewrite
      the lexing table,
      but that was even more rote than rewriting
      the grammar.
      I won't repeat the
      lexer table here --
      it can be found in
      <a href="https://gist.github.com/4093504">the Github gist</a>.
    </p>
    <h3>Adding the semantics</h3>
    <p>Our semantics will create a syntax tree.
      Here is that logic.
      (Note that the first argument to these semantic closures
      is a per-parse "object",
      which we don't use here.)
    </p><blockquote>
      <pre>
    <tt>
sub do_undef       { undef; }
sub do_arg1        { $_[2]; }
sub do_what_I_mean { shift; return $_[0] if scalar @_ == 1; return \@_ }

sub do_target {
    my $origin = ( Marpa::R2::Context::location() )[0];
    return if $origin != $ORIGIN;
    return $_[1];
} ## end sub do_target
    </tt>
    </pre>
    </blockquote>
    <p>
      There is some special logic in the
      <tt>do_target()</tt>
      method,
      involving the "origin", or starting location of the target.
      Perl arithmetic expressions,
      when they are the target of an unanchored search,
      are ambiguous.
      For example, in the string "<tt>abc 1 + 2 + 3 xyz</tt>",
      there are two targets ending at the same position:
      "<tt>2 + 3</tt>" and "<tt>1 + 2 + 3</tt>".
      We are interested only in longest of these,
      whose start location is indicated by the
      <tt>$ORIGIN</tt>
      variable.
    </p><p>The next logic will be familiar from our
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html">
        pattern search tutorial</a>.
      It repeatedly looks for non-overlapping occurrences of
      <tt>target</tt>,
      starting from the end and going back to the beginning of the input.
    </p><blockquote>
      <pre>
    <tt>
my $end_of_search;
my @results = ();
RESULTS: while (1) {
    my ( $origin, $end ) =
        $self-&gt;last_completed_range( 'target', $end_of_search );
    last RESULTS if not defined $origin;
    push @results, [ $origin, $end ];
    $end_of_search = $origin;
} ## end RESULTS: while (1)
    </tt>
    </pre>
    </blockquote>
    <p>This final code sample is the logic
      that unites pattern search with incremental
      parsing.
      It is a loop through
      <tt>@results</tt>
      that prints the original text
      and, depending on a flag,
      its syntax tree.
    </p>
    <p>
      Near the top of the loop,
      the "<tt>$recce-&gt;set( { end =&gt; $end } )</tt>"
      call sets the end of parse location to the current
      result.
      At the bottom of the loop,
      we call
      "<tt>$recce-&gt;reset_evaluation()</tt>".
      This is necessary to allow us to evaluate the
      input stream again, but with a new
      <tt>$end</tt>
      location.
    </p>
    <blockquote>
      <pre>
    <tt>
RESULT: for my $result ( reverse @results ) {
    my ( $origin, $end ) = @{$result};

    <big><b>... Print out the original text ...</b></big>

    $recce-&gt;set( { end =&gt; $end } );
    my $value;
    VALUE: while ( not defined $value ) {
        local $main::ORIGIN = $origin;
        my $value_ref = $recce-&gt;value();
        last VALUE if not defined $value_ref;
        $value = ${$value_ref};
    } ## end VALUE: while ( not defined $value )
    if ( not defined $value ) {
        say 'No parse'
            or die "say() failed: $ERRNO";
        next RESULT;
    }
    say Data::Dumper::Dumper($value)
        or die "say() failed: $ERRNO"
        if not $quiet_flag;
    $recce-&gt;reset_evaluation();
} ## end RESULT: for my $result ( reverse @results )
    </tt>
    </pre>
    </blockquote>
    <p>The
      <tt>VALUE</tt>
      sub-loop is
      where the
      <tt>$ORIGIN</tt>
      variable
      was set.
      In the semantics,
      <tt>do_target()</tt>
      checks this.
      In the case of an ambiguous parse,
      <tt>do_target()</tt>
      turns any target which does not
      cover the full span from
      <tt>$origin</tt>
      to
      <tt>$end</tt>
      into a Perl
      <tt>undef</tt>,
      which will
      eventually become
      the value of its parse.
      The logic in the
      <tt>VALUE</tt>
      loop
      ignores parses whose value is a Perl <tt>undef</tt>,
      so that only the longest target for each
      <tt>$end</tt>
      location is printed.
    </p>
    <h3>Code and comments</h3>
    <p>The example in this post is available as
      <a href="https://gist.github.com/4093504">a Github gist</a>.
      It was run with
      <a href="https://metacpan.org/release/JKEGL/Marpa-R2-2.024000/">
        Marpa::R2 2.024000</a>,
      as of this writing the latest full release.
      Its main test, which is included in the gist,
      used displays from the
      <a href="http://perldoc.perl.org/perlop.html">perlop man page</a>.
    </p>
    <p>
      Comments on this post
      can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 08:56 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/iterative.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
<h3>Sun, 11 Nov 2012</h3>
<br />
<center><a name="pattern_search"> <h2>A Marpa tutorial: pattern searches</h2> </a>
</center>
  <h3>Pattern searches</h3>
    <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      We use regular expressions for pattern searching these days.
      But what if your search target is not a regular expression?
      In this post I will show how to use Marpa to search text files for
      arbitrary context-free expressions.
    </p>
    <p>
      This tutorial builds on earlier tutorials.
      It is possible to simply dive into it,
      but it may be easier
      to start with two of my earlier posts,
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html">here</a>
      and
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">here</a>.
    </p>
    <h3>The grammar</h3>
    <p>
      I will use arithmetic expressions as
      the example of a search target.
      Even the arithmetic subset of Perl expressions is quite complex,
      but in this case we can get the job done
      with eight lines of grammar and a lexer driven
      by a table of just over a dozen lines.
      Here is the grammar:
    </p>
    <blockquote>
      <pre>
    <tt>
start ::= prefix target
prefix ::= any_token*
target ::= expression
expression ::=
       number | scalar | scalar postfix_op
    || op_lparen expression op_rparen assoc =&gt; group
    || unop expression
    || expression binop expression`
    </tt>
    </pre>
    </blockquote>
    <p>
      This grammar uses
      <a href="https://metacpan.org/module/Marpa::R2::BNF">
        Marpa::R2's BNF interface</a>.
      It takes considerable advantage of the fact that we are not
      <b>parsing</b>
      these expressions, but
      <b>recognizing</b>
      them.
      Because of this, we don't have to specify whether expressions left- or right-associate.
      We can also ignore what operators mean and group them according to syntax only
      -- binary, prefix unary and postfix unary.
      Similarly, we can ignore the precedence within these large groups.
      This leaves us with numbers, scalars,
      parentheses,
      and binary, prefix unary and postfix unary operators.
      (To keep this example simple, we restrict the primaries
      to numeric constants and Perl scalars.)
    </p>
    <p>
      What we are searching for is defined by the
      <tt>target</tt>
      symbol.
      For
      <tt>target</tt>
      you could substitute
      the start symbol of
      any context-free grammar,
      and the structure of this example will still work.
      To turn a parser for
      <tt>target</tt>
      into a pattern searcher, we add a new start
      symbol (unimaginatively named "<tt>start</tt>")
      and two rules that
      allow the target to have a
      <tt>prefix</tt>.
    </p>
    <h3>Ambiguous parsing</h3>
    <p>To do an anchorless pattern search,
      this example will use ambiguous parsing.
      This grammar always has at least one parse going,
      representing the prefix for
      the zero or more targets
      that our parser
      expects to find in the future.
      The prefix will never end, because
      any token (as indicated by a token
      named, literally,
      <tt>any_token</tt>)
      extends it.
    </p>
    <p>
      If we are in the process of recognizing a
      <tt>target</tt>,
      we will have one or more other parses going.
      I say "one or more" because the search method
      described in this post
      allows <tt>target</tt> to be ambiguous.
      But arithmetic expressions,
      the target pattern used in this example,
      are not ambiguous.
      So our example will have
      at most two parses active at any point:
      one for the prefix and another for the target.
    </p>
    <p>
      Ambiguous parsing has a serious potential downside --
      it is not necessarily linear
      and therefore not necessarily efficient.
      But Marpa can parse many classes of ambiguous grammar in linear time.
      Grammars like the one in this post --
      a prefix and an unambiguous search target --
      fall into one of the linearly parseable classes.
      Keeping the prefix going requires a tiny constant overhead per token.
    </p>
    <h3>The lexer table</h3>
    <p>
      The lexer is driven by a table of pairs: token name and regex.
    </p><blockquote>
      <pre>
<tt>
my @lexer_table = (
    [ number     =&gt; qr/(?:\d+(?:\.\d*)?|\.\d+)/xms ],
    [ scalar     =&gt; qr/ [\$] \w+ \b/xms ],
    [ postfix_op =&gt; qr/ [-][-] | [+][+] /xms ],
    [ unop       =&gt; qr/ [-][-] | [+][+] /xms ],
    [   binop =&gt; qr/
          [*][*] | [&gt;][&gt;] | [&lt;][&lt;]
        | [*] | [\/] | [%] | [x] \b
        | [+] | [-] | [&amp;] | [|] | [=] | [,]
    /xms
    ],
    [   unop =&gt; qr/ [-] | [+] | [!] | [~] /xms
    ],
    [ op_lparen =&gt; qr/[(]/xms ],
    [ op_rparen =&gt; qr/[)]/xms ],
);
</tt>
</pre>
    </blockquote>
    <p>
      Order is significant here.
      In particular
      two-character operators are checked for first.
      This guarantees that
      two consecutive minus signs
      will be seen as an
      decrement operator, and not as a double negation.
    </p>
    <h3>Ambiguous lexing</h3>
    <p>The very careful reader may have noticed that
      <tt>any_token</tt>
      is not in the lexing table.
      The main loop is written so that every token is read as an
      <tt>any_token</tt>.
      If no token from the lexing table is accepted,
      the next character in the input stream
      is read as an
      <tt>any_token</tt>.
      If a token from the lexing table
      <b>is</b>
      accepted,
      then it gets read twice,
      once as an
      <tt>any_token</tt>,
      and once as the token type taken from the lexing table
      entry.
    </p>
    <p>Ambiguous lexing is a familiar technique to
      the Natural Language Processing community.
      Engish, in particular, is a language that abounds
      in lexemes that can play multiple roles.
      The word "sort", for example, can easily be
      an noun, a verb or an adjective.
    </p>
    <h3>The Ruby Slippers</h3>
    <p>The main loop will also be a simple case of the use
      of the Ruby Slippers.
      For those unfamiliar,
      the "Ruby Slippers" parsing technique handles difficult lexing
      and parsing problems by asking the parser, at the problem point,
      what it is looking for,
      and providing it.
      This seems a fairly obvious approach,
      but the Ruby Slippers are new with Marpa --
      traditional parsers could not easily
      determine where they were in a parse.
    </p>
    <p>
      One way to use the Ruby Slippers is to ask the parser in
      advance what it is looking for.
      The code that follows uses another method.
      Instead of determining in advance what tokens to read,
      it simply feeds tokens to the parser.
    </p>
    <p>
      Token rejection is a "soft" error -- it costs
      little to try, and little to retry.
      The following code can
      efficiently determine which entry in the lexing table is appropriate,
      simply by trying each of them in order.
      If the
      <tt>alternative()</tt>
      method returns a Perl
      <tt>undef</tt>,
      indicating that a token was rejected,
      then the main loop will try later entries in the lexing table.
    </p>
    <p>
      When a token is accepted,
      the main loop can safely assume that it is on the right track.
      Marpa is 100% accurate about
      which tokens can and cannot result in a successful parse.
    </p>
    <h3>The main loop</h3>
    <p>
      The main loop iterates through input looking for tokens.
      Whitespace is skipped.
      Comments are not skipped.
      Finding arithmetic expressions in
      strings and/or comments can be useful.
      We will assume that is the case here.
    </p>
    <blockquote>
      <pre>
<tt>
my $length = length $string;
pos $string = $positions[-1];
TOKEN: while ( pos $string &lt; $length ) {
    next TOKEN if $string =~ m/\G\s+/gcxms;    # skip whitespace
    my $position = pos $string;
    FIND_ALTERNATIVE: {
        TOKEN_TYPE: for my $t (@lexer_table) {
            my ( $token_name, $regex ) = @{$t};
            next TOKEN_TYPE if not $string =~ m/\G($regex)/gcxms;
            if ( not defined $recce-&gt;alternative($token_name) ) {
                pos $string = $position;       # reset position for matching
                next TOKEN_TYPE;
            }
            $recce-&gt;alternative('any_token');
            last FIND_ALTERNATIVE;
        } ## end TOKEN_TYPE: for my $t (@lexer_table)
        ## Nothing in the lexer table matched
        ## Just read the currrent character as an 'any_token'
        pos $string = $position + 1;
        $recce-&gt;alternative('any_token');
    } ## end FIND_ALTERNATIVE:
    $recce-&gt;earleme_complete();
    my $latest_earley_set_ID = $recce-&gt;latest_earley_set();
    $positions[$latest_earley_set_ID] = pos $string;
} ## end TOKEN: while ( pos $string &lt; $length )
</tt>
</pre>
    </blockquote>
    <p>
      The
      <tt>earleme_complete()</tt>
      method tells Marpa that all the alternatives
      at one location have been entered,
      and that the parse should now move on to the next location.
      (Marpa's idea of location is called an "earleme", in honor of the great
      parsing theorist, Jay Earley.)
    </p>
    <h3>How to parse without really trying</h3>
    <p>
    At this point, I want to draw the reader's attention to the code
    that deals with special cases for the minus sign.
    Specifically, to the fact that there is no such code.
    The more familiar you are with PPI and/or
      <tt>perly.y</tt>,
      the more remarkable this will seem.
      </p>
      <p>
      To take one example, PPI correctly realizes that the minus
      sign in
      "<tt>1+2-3</tt>" is a binary operator.
      However PPI fails on "<tt>(1+2)-3</tt>" --
      it thinks the minus sign is part of the number "-3".
      Why don't the authors of PPI just look at the Perl
      interpreter and copy the logic there?
      Take a glance at <tt>perly.y</tt>
      and <tt>toke.c</tt> 
      and you will know the answer to that question.
      </p>
      <p>What is PPI's problem here?
      The problem is that,
      without knowing where you are in the expression,
      you cannot tell whether a minus sign is a unary
      operator or a binary operator.
      And the parse engines for PPI and for Perl itself,
      while quite different in many respects,
      share a property common to traditional parsers --
      in determining context
      they offer the lexer, respectively,
      little and no help.
      </p>
      <p>
      In the code in this example,
      Marpa's <tt>alternative()</tt> method is, by accepting
      and rejecting tokens, guiding the lexer to the right choice.
      Because of Perl's grammar, a minus sign at a given position
      cannot be both a unary operator and a binary operator.
      And Marpa is 100% accurate in its knowledge of which
      tokens are possible.
      So Marpa's
      <tt>alternative()</tt> method
      always knows whether a minus sign can be
      a unary or binary operator and accepts
      or rejects the token accordingly.
    </p>
    <p>
      This is the Ruby Slippers in action --
      a very simple solution to what for the Perl
      interpreter and PPI
      is a very complicated problem.
      When I developed the Ruby Slippers technique,
      my most serious problem 
      was convincing myself that something
      so simple could really work.
    </p>
    <h3>Finding the targets</h3>
    <p>
      Once the parse is complete, it remains to find
      and print the "targets" found
      by the search.
      In
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">
      a previous post</a>,
      I showed how, 
      given a symbol name,
      to find the last occurrence of the symbol in a Marpa parse.
      That routine needed to be modified to allow repeated searches,
      but the change was straightforward.
      The code is in the
      <a href="https://gist.github.com/4057239">
      gist</a>,
      and the ideas behind it were explained
      in
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">
      the previous post</a>,
      so I won't repeat them here.
    </p>
    <h3>Code and comments</h3>
    <p>The example in this post is available as
    <a href="https://gist.github.com/4057239">
      a Github gist</a>.
      It was run with
      <a href="https://metacpan.org/release/JKEGL/Marpa-R2-2.024000/">
      Marpa::R2 2.024000</a>,
      as of this writing the latest full release.
      My main test, which is included in the gist,
      used displays from the
      <a href="http://perldoc.perl.org/perlop.html">perlop man page</a>.
    </p>
    <p>
      Comments on this post
      can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
<br />
<p>posted at: 20:15 |
<a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html">direct link to this entry</a>
</p>
<div style="color:#38B0C0;padding:1px;text-align:center;">
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&sect;
</div>
</div>
</div>
<div id="footer" style="border-top:thick solid #38B0C0;clear:left;padding:1em;">
<p>This is Ocean of Awareness's
  new home.  This blog has been hosted at
  <a href="http://blogs.perl.org/users/jeffrey_kegler/">blogs.perl.org</a>
  but I have succumbed to the lure of static blogging.
  I have not yet decided how to deal with comments at this new blog location.
If the post is Marpa-related,
<a href="https://groups.google.com/forum/?hl=en&fromgroups#%21forum/marpa-parser">
the Marpa mailing list</a>
is a good place to comment.
</div>
	<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-33430331-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
</body></html>
