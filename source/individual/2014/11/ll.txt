Parsing: Top-down versus bottom-up
<html>
  <head>
  </head>
  <body><p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
    </p>
    <p>Why did the invention of bottom-up parsing bring
    with it such hope?
    Indeed, despite bottom-up parsing's
     near-total abandonment by practitioners,
     among theoreticians bottom-up still has not lost its hold.
     Even today,
    in parsing texts and courses,
    bottom-up parsing frequently gets as much or more
    attention than
    the more widely used top-down parsing.
    Why?
    <p>Many treatments of these two approaches
    are either too high-level or two low-level.
    Overly high-level treatments reduce the two approaches to buzzwords,
    and the comparision to a recitation of received wisdom.
    Overly low-level treatments get immersed in the minutiae of implementation,
    so that the comparison ends up no more helpful than placing
    two unrelated code listings placed side by side.
    In this post I hope to clarify why the two advocates of each
    parsing approach took that positions
    they did,
    and to suggest a way forward.
    </p>
    <h3>Top-down parsing</h3>
    <p>The basic idea of top-down parsing is
      as brutally simple as anything in programming:
      you look at the next token and decide then and there
      where it fits into the parse tree.
      Starting at the top, you add pieces and once
      you've looked at every token,
      you have your parse tree.
      <p>
      Since this idea, in its purest form,
      is too simple to get anything done,
      top-down parsing is almost
      always combined with with lookahead.
      Lookahead of one token helps a lot.
      But longer lookaheads
      are very sparsely used.
      They just aren't that helpful,
      and since
      the number of possible lookaheads grows exponentially,
      they get very expensive very fast.
    </p><p>Top-down parsing has an issue with left recursion.
      It's straightforward to see why.
      Take
      an open-ended expression like
    </p><blockquote><pre>
    a + b + c + d + e + f + [....]</pre></blockquote>
    <p>
      Here the plus signs continue off to the right,
      and all of them should go above the first one in the parse tree.
      So we put the first plus sign into a top-down parse
      tree without having dealt with all those plus signs that follow it.
      Even in the simplest expression,
      there is no way of even counting the plus signs
      without looking to the right,
      quite possibly a very long way to the right.
      And for anything but the simplest expressions,
      this rightward-looking needs to get
      rather sophisticated
      There are ways dealing with this difficulty,
      but all of them share one thing in common --
      they are trying to make top-down parsing into
      something that it is not.
    </p><h3>Advantages of top-down parsing</h3>
    <p>Top-down parsing does not look at the right context in any systematic way,
    and in the 1970's it was hard to believe that
      that as as good as we can do.
      (It's not all that easy to believe today.)
      But before looking at alternatives,
      I want to emphasize that its extreme simplicity
      is also top-down parsing's great strength.
      Because a top-down parsing is extremely simple,
      it is very easy to figure out what it is doing.
      And easy to figure out means easy to customize.
    </p><p>
      Take another of the many constructs incomprehensible to
      a top-down parser:
    </p><blockquote><pre>
    2 * 3 * 4 + 5 * 6
    </pre></blockquote><p>
      How do top-down parsers typically handle this?
      Simple: as soon as they realize they are faced
      with an expression, they give up on top-down
      parsing and switch to a special-purpose algorithm.
    </p><p>These two properties -- easy to understand
      and easy to customize --
      have catapulted top-down parsing
      to the top of the heap.
      Behind their different presentations,
      combinator parsing, PEG, and recursive descent are
      all top-down parsers.
    </p><h3>Bottom-up parsing</h3>
    <p>Few theoreticians of the 1970's imagined that top-down parsing would
      be the end of the story.
      It seemed almost paradoxical that, while looking to the right in
      ad hoc ways
      migh help, there was no systematic way to
      to exploit the right context.
      Certainly,
      when reading sentences like these, you'd think
      a human must be making more than casual use of right context.
    </p><p>Don Knuth in 19xx found an algorithm to exploit
      right context.
      Knuth's LR algorithm was,
      like top-down parsing as I have described it,
      deterministic.
      Determinism was thought to be essential because determinism
      allowing more than one choice easily leads to an explosion in the
      number possibilities being considered at once.
      Preventing an explosion in the number of possibilities
      guaranteed that the parse can be done in linear time.
    </p><p>Simplistically, Knuth's suggestion was to,
      instead of fully deciding the
      parse at every location, to make what I will call "subpieces" --
      pieces that embody partial decisions about the
      parse, which are intended
      to be assembled later into a larger subpieces,
      and eventually into a full parse tree.
      In Knuth's algorithm, the subpieces were bottom-up subparses.
      Knuth proposed a stack of subparses -- while a subparse
      but is waiting for its context, we push it onto a stack.
      When we encounter the context, we pop one or more subpieces off the stack
      and assemble a larger subpiece.
      <p>This approach is called shift/reduce parsing,
      My descriptions below will skip over details of shift/reduction --
      including some details crucial to successful implementation.
      These details are well-covered in many of places.
      <a href=http://en.wikipedia.org/wiki/Shift-reduce_parser:>The Wikipedia article</a>,
      for example, is excellent.
    </p><p>Like top-down parsing, bottom-up parsing is usually combined with lookahead.
      For the same lookahead, a bottom-up parser parses everything that a
      top-down parser can handle,
      and more.
    </p><p>
      To preserve determinism,
      you have to know,
      at every location,
      whether to push the subpiece onto the LIFO,
      and or to build it into a larger subpiece.
      And if we do decide to build the larger subpiece,
      we also need to know which rule to use to make the subpieces.
      <p>
      Bottom-up parsing solved
      the problem of left recursion.
      In the example from above,
    </p><blockquote><pre>
    a + b + c + d + e + f + [....]</pre></blockquote>
    <p>
      you never need to use LIFO -- you just simply build one subpiece after another
      until you run out of plus signs.
      The top-down parser had a problem because it needed to build top-down,
      so that it needed to know about the plus signs to come -- plus signs
      that will go into nodes of the parse tree above the subparse we are
      building.
      But if we are building a bottom-up subparse, we don't need to know anything about
      the plus signs to the right.
      We can easily wait until when and if we encounter them.
      When we run out of tokens, we also have hit the top of the parse tree
      and we are done.
    </p>
    <p>But if working bottom-up solves the left recursion problem,
    doesn't it create a new right recursion problem?
    In fact,
    for a bottom-up parser, right recursion is harder, but not much.
    Because unlike the top-down parsers,
    shift-reduce parsers have a LIFO.
    For a right recursion like this:
    </p><blockquote><pre>
    a = b = c = d = e = f = [....]</pre></blockquote>
  <p>
      we simply push every token onto the LIFO.
      Once your LIFO contains the entire input,
       we pop the assignments off the stack
      one by one, building the tree bottom-up,
      and pushing the result back onto the LIFO.
      Since every time we pop three items (the equal sign and its two operands),
      we only push one result back one,
      eventually the stack will empty.
      When the stack is empty, we are done.
      Essentially, what we do the exactly same thing we did for left recursion,
      except that we use the LIFO to reverse the order.
      <p>
      Arithmetic expressions like
    </p><blockquote><pre>
    2 * 3 * 4 + 5 * 6</pre></blockquote>
    <p>
      are handled by mixing the methods just described.
      For the expression above,
      <ul>
      <li>We immediately build all the multiplications in the first set
      into a subparse as soon as possible,
      treating it the same as we did a left recursion,
      until we reach the plus sign.
      <li>When we reach the plus sign, we push that sign onto the LIFO.
      <li>After the plus sign
      we build all the multiplications in the next set into a subparse,
      much as we did with the first set.
      <li>A this point the LIFO will contain three items: a subparse,
      the addition sign,
      and a subparse.
      The two subparses are the operands of the addition.
      We build these three elements into a new subparse.
      <li>
      This subparse is, in fact, our parse tree.
      We are done.
      </ul>
    </p><p>
      As mentioned, I omitted a lot of details,
      and most of them will stay omitted.
      But one omission requires attention:
      to preserve determinism,
      we have to know,
      at every location,
      whether to push the next symbol onto the stack,
      or to build a new subparse immediately
      from whatever is at the top of the LIFO.
      And if we do decide to build a new subparse,
      so we also need to decide what rule to use.
      (There may be a choice.)
      Above, we assumed that we had a way to figure this out.
      In fact,
      finding what a practical way to make the necessary
      shift/reduce and reduce/reduce decisions was a very far from trivial
      task.
      By the 197-, it was thought a practical way had been found,
      and around 19-- a parser generator based on it was released as yacc.
      (Readers today may be more familiar with yacc's successor, bison.)
    </p>
    <h3>The advantages and disadvantages of bottom-up parsing</h3>
    <p>
      With yacc, it looked as if all the most failures of top-down parsing were solved.
      We now had a parsing algorithm that could readily and directly
      parse left recursions and arithmetic expressions.
      Theoreticians thought they'd found the Holy Grail.
      When the textbooks focused on bottom-up parsing came out,
      they were not always able to restrain the urge
      to portray parser writers as knights in armor.
    </p><p>But not every medieval romance has a happy ending.
      As I've
      <a href="http://jeffreykegler.github.io/Ocean-of-Awareness-blog/individual/2014/09/chron.html">described
      elsewhere</a>,
      this story ended badly.
      Bottom-up parsing was driven by tables which made the algorithm fast
      for correct inputs, but unable to accurately diagnose faulty ones.
      The subset of grammars parsed was still not quite large enough,
      even for conservative language designers.
      And bottom-up parsing was very unfriendly to custom hacks,
      which made its shortcomings loom large.
      It is much harder to work around a problem in a bottom-up
      parser than than it was to deal with a similar problem
      in a top-down parser.
      After years of experience,
      top-down parsing has re-emerged as the
      algorithm of choice.
    </p><h3>Table parsing</h3>
    <p>For many, the return to top-down parsing
      answers the question that we posed earlier:
      "Is there any systematic way to exploit right context when parsing?"
      This answer turns out to be a rather startling "No".
      But is this really the end of the story?
    </p><p>Assumed in all of this was that,
      for an algorithm to be linear,
      in practice it would also have to be deterministic.
      But is this actually the case?
    </p><p>It's not, in fact.
      To keep bottom-up parsing deterministic, we restricted ourselves to a stack.
      But what if we keep all possible subpieces linked and in tables,
      and make the final decisions in another pass,
      once the tables are complete.
      (The second pass replaces the stack based
      see-sawing back and forth of the deterministic algorithm,
      so it's not an inefficiency.)
      Jay Earley in 19-- came up with an algorithm to do this,
      and in 1991 Joop Leo added a memoization to Earley's
      algorithm which makes it linear for all deterministic grammars.
    </p><p>The "deterministic grammars"
      are exactly the bottom-up parseable grammars
      with lookahead.
      So that means the Earley/Leo algorithm parses,
      in linear time,
      everything that a deterministic bottom-up parser can parse,
      and therefore every grammar that
      a deterministic top-down parser can parse.
      (In fact, the Earley/Leo algorithm is linear for a lot of
      ambiguous grammars as well.)
    </p><p>Top-down parsing had the advantage that it was easy to know where
      you are.  But the Earley/Leo algorithm has an equivalent advantage -- its
      tables know where it is, and it is easy to query them programmatically.
      In 2010, this blogger added to the Earley/Leo algorithm
      the other big advantage of top-down parsing:
      The Marpa algorithm rearranges the Earley/Leo parse engine so that you can
      stop it, perform your own logic, and restart where you left off.
      <a href=http://savage.net.au/Marpa.html">A quite useable parser based on the Marpa algorithm</a>
      is available as open source.
    </p><h3>Comments</h3>
    <p>Comments on this post can be made in
      <a href="http://groups.google.com/group/marpa-parser">
        Marpa's Google group</a>,
      or on our IRC channel: #marpa at freenode.net.
      To learn more about Marpa,
      there's
      <a href=http://savage.net.au/Marpa.html">the
        official web site maintained by Ron Savage</a>.
      I also have
      <a href="http://jeffreykegler.github.io/Marpa-web-site/">a Marpa web site</a>.
    </p>
  </body>
</html>
