The Interpreter Design Pattern
  <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
    </p>
    <p>The influential
      <a href="http://en.wikipedia.org/wiki/Design_Patterns">
        <em>Design Patterns</em>
        book</a>
      lays out 23 patterns for programming.
      One of them, the Interpreter Pattern, is rarely used.
      Steve Yegge puts it a bit more strikingly -- he says
      that the book contains
      <a href="https://sites.google.com/site/steveyegge2/ten-great-books">22
        patterns and a practical joke</a>.
    </p>
    <p>That sounds (and in fact is) negative, but
      <a href="http://steve-yegge.blogspot.com/2007/12/codes-worst-enemy.html">
        elsewhere</a>
      Yegge says that
      "[t]ragically, the only [Go4] pattern that can help code get smaller
      (Interpreter) is utterly ignored by programmers".
      (The
      <i>Design Patterns</i>
      book has four authors,
      and is often called the Gang of Four book, or Go4.)
    </p>
    <p>
      In fact, under various names and definitions, the
      Interpreter Pattern and its close relatives and/or identical twins
      are widely cited,
      much argued and highly praised<a href="#NOTE1">[1]<a>.
          As they should be.
          Languages are the most powerful and flexible design pattern of all.
          A language can include all, and only, the concepts relevent
          to your domain.
          A language can allow you to relate them in all, and only, the appropriate ways.
          A language can identify errors with pinpoint precision,
          hide implementation details,
          allow invisible "drop-in" enhancements, etc., etc., etc.
        </a></a></p>
    <p>
      In fact languages are so powerful and flexible,
      that their use is pretty much universal.
      The choice is not whether or not to use a language to solve
      the problem,
      but whether to use
      a general-purpose language,
      or a domain-specific language.
      Put another way,
      if you decide not to use a language targeted
      to your domain,
      it almost always means that you
      are choosing to use another language that is not specifically
      fitted to your domain.
    </p>
    <p>
      Why then, is the Interpreter Pattern so little used?
      Why does Yegge call it a practical joke?
    </p>
    <h3>There's a problem</h3>
    <p>The problem with the Interpreter Pattern is that you must
      turn your language into an AST -- you must parse it somehow.
      Simplifying the language can help here,
      but if the point is to be simple at the expense of power
      and flexibility,
      you usually might as well
      stick with the other 22 design patterns.
    </p>
    <p>
      On the other hand,
      creating a parser for anything but the simplest languages
      has been a time-consuming effort,
      and one of a kind known for disappointing results.
      In fact,
      language development efforts run
      a real risk of total failure.
    </p>
    <p>How did the Go4 deal with this?
      They defined the problem away.
      They stated that the parsing issue was separate from the
      Interpreter Pattern, which was limited to what you did with the AST
      once you'd somehow come up with one.
    </p>
    <p>
      But AST's don't (so to speak) grow on trees.
      You have to get one from somewhere.
      In their example, the Go4 simply built one in their code,
      node by node.
      In doing this, they bypassed the BNF, and the problem of parsing,
      but also their language and therefore the whole point
      of the Interpreter Pattern.
    </p>
    <p>
      Which is why Yegge characterized the chapter as a practical joke.
      And why other programming techniques and patterns are almost
      always preferred to the Interpreter Pattern.
    </p>
    <h3>Finding that one missing piece</h3>
    <p>So that's how the Go4 left things.
      A potentially great programming technique made almost useless because
      of a missing piece.
      There was no easy, general and practical way to generate AST's.
    </p>
    <p>
      Few expected that to change.
      I was more optimistic than most.
      In 2007 I embarked on a full-time project:
      to create an Earley-based
      parser that I was sure would fulfill two of the criteria --
      it would be easy to use, and it would be general.
      As for practical -- well, a lot of parsing problems
      are small, and a lot of applications don't require a lot
      of speed, and for these I expected the result to be good enough.
    </p>
    <p>What I didn't realize was that
      all of the problems preventing
      Earley's from seeing real, practical use
      has already been solved in the academic literature.
      I was not alone in not having put the picture together.
      The people who had solved the problems
      had focused on two disjoint sets of issues,
      and were unaware of each other's
      work.
      In 1991, in the Netherlands,
      the mathematican Joop Leo had
      arrived at an astounding result --
      he showed how to make Earley's run in linear time for a vast class of grammars
      including, as a subset, LR(k) for all
      <i>k</i>.
      Ten years later in Canada,
      Aycock and Horspool focused on some nagging practical issues,
      including the size of Earley's parse tables
      and the handling of nullable rules and symbols.
      But the Aycock-Horspool speeds were essentially that of
      Earley's original algorithm --
      they seem to have been unaware of Leo's earlier result.
    </p>
    <p>
      Because of Leo's work, Marpa is fast.
      For any grammar in any class currently in practical use, Marpa parses in linear time.
      That includes regular expressions,
      the LL(k) grammars on which recursive descent and PEG
      are based for all
      <i>k</i>, and the LR(k) grammars on which yacc and bison are based,
      again for all
      <i>k</i>.
      I realized that,
      if only it could be combined with the approach
      of Aycock and Horspool, Leo's speed could be harnessed in practice.
    </p><p>
    </p><p>
      But the Aycock-Horspool and Leo algorithms had branched off in different directions --
      it was not obvious that their approaches could be combined, much less how.
      In fact, the solution was not simple.
      In the course of combining the two, I reordered the Earley parse engine
      in a way that has some very nice properties for,
      among other things, error reporting.
    </p>
    <h3>Eureka and all that</h3>
    <p>The result is an algorithm which parses anything
      you can write in BNF and
      does it in times considered optimal in practice.
      Unlike recursive descent, you don't have to write out the parser --
      Marpa generates a parser for you, from the BNF.
      It's the easy, "drop-in" solution that the Go4 needed and did not have.
    </p>
    <p>
      I've redone the Go4 example, adding the missing parser.
      I described the fully worked out version in
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/03/bnf_to_ast.html">a
        previous blog post</a>.
      The full code is in
      <a href="https://gist.github.com/jeffreykegler/5121769">
        a Github gist</a>.
    </p>
    <h3>More about Marpa</h3>
    <p>
      Marpa's latest version is
      <a href="https://metacpan.org/module/Marpa::R2">Marpa::R2,
        which is available on CPAN</a>.
      Recently, it has gained immensely in "whipitupitude" with
      <a href="https://metacpan.org/module/JKEGL/Marpa-R2-2.048000/pod/Scanless/DSL.pod">
        a new interface</a>,
      which has tutorials
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/dsl_simpler2.html">here
      </a>
      and
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/announce_scanless.html">
        here</a>.
      Marpa has
      <a href="http://jeffreykegler.github.com/Marpa-web-site/">a web page</a>,
      and of course it is the focus of
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/">
        my "Ocean of Awareness" blog</a>.
    </p>
    <p>
      Comments on this post
      can be sent to the Marpa's Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
    <h3>Notes</h3>
    <p><a name="NOTE1">Note 1</a>:
      For example,
      <a href="http://en.wikipedia.org/wiki/Domain-specific_language">the Wikipedia article on DSL's</a>;
      <a href="http://www.faqs.org/docs/artu/minilanguageschapter.html">Eric Raymond discussing mini-languages</a>;
      <a href="http://www.dmst.aueb.gr/dds/pubs/jrnl/2000-JSS-DSLPatterns/html/dslpat.html">
        "Notable Design Patterns for Domain-Specific Languages"</a>, Diomidis Spinellis; and
      <a href="http://www.c2.com/cgi/wiki?DomainSpecificLanguage">the c2.com wiki</a>.
    </p>
