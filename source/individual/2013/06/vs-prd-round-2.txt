Marpa v. Parse::RecDescent: a rematch
<h2>The application</h2>
<p>
In my last post, I looked at an unusual language which defines arrays and strings,
mixing counts and parentheses.  Here's an example if it:
<code class="prettyprint">
<pre>
A2(A2(S3(Hey)S13(Hello, World!))S5(Ciao!))
</pre>
</code>
<p>
The language is of special interest to me because, while simple, it requires procedural
parsing -- a purely declarative BNF approach will not work.
So it's a chance to find out if Marpa can play the game that is recursive descent's
specialty.
The last post focused on how to write the solution
in a nice mix of procedural and declarative.
It hinted at another aspect: speed.
<p>Over the last year, Marpa has also improved its speed.
Parse::RecDescent is pure Perl, while Marpa is based on a parse
engine in a library written in
hand-optimized C.
You'd expect Marpa to win this race and, as represented by Marpa::XS
a year it did, by a factor of up to 10.
In the past year, Marpa::R2 has come out, with a new interface
and an internal lexer.
Marpa::R2 beats Marpa::XS by a factor of up to 10,
making it 100 times faster for long inputs.
</p>
I call it a Dyck-Hollerith language because it
combines
<a href="http://en.wikipedia.org/wiki/Hollerith_constant">
Hollerith constants</a>

(strings preceded by a count),
with balanced parentheses
(what is called
<a href="http://en.wikipedia.org/wiki/Dyck_language">
a Dyck language</a>
by mathematicians).
Here's Flavio's example:
When I did
<a href="http://blogs.perl.org/users/jeffrey_kegler/2011/11/marpa-v-perl-regexes-some-numbers.html">
a Marpa versus Perl regexes comparison</a>,
I was very careful to choose an application which showed Marpa in
a good light.
Here I did not pick the application,
and it is almost as if it was designed
to show recursive descent in a good light.
</p>
<p>

Recursive descent tries to parse by treating each rule
as a subroutine call.
This is a very natural way for a programmer
to look at a grammar.
But, alas, it only works in certain cases,
and most of those are already handled by regular expressions.
However, Dyck languages, including balanced parentheses,
are one of the boundary cases:
languages beyond the abilities of regular expressions,
but within the capabilities of recursive descent.
</p>
<p>
Hollerith constants highlight the other strength of
recursive descent.
Since recursive descent's basic idea is so intuitive, it is easy
to add custom hacks to it.
And Hollerith constants are beyond the capabilities of even
general BNF parsing.
Earley's, Marpa, CYK, GLR, you name it,
none of them can handle Hollerith constants without
some kind of custom hack.
You might say that Hollerith constants force a parser
to wrestle in the mud.
And when it comes to wrestling in the mud,
recursive descent is hard to beat.
</p>
<h2>The benchmark</h2>
<table align="center" cellpadding="5" border="1" width="100%">
<tr><th rowspan="2">Length<th colspan="3">Seconds</tr>
<tr>
<th>Marpa::R2
<th>Marpa::XS
<th>Parse::RecDescent
</tr>
<tr><td>1000
<td align="center">1.569
<td align="center">2.938
<td align="center">13.616
</tr>
<tr><td>2000
<td align="center">2.746
<td align="center">7.067
<td align="center">62.083
</tr>
<tr><td>3000
<td align="center">3.935
<td align="center">13.953
<td align="center">132.549
</tr>
<tr>
<td>10000
<td align="center">12.270
<td align="center">121.654
<td align="center">1373.171
</tr>
</table>
</p>

<p>
The benchmark emphasizes long inputs, though these days a 500K source,
longer than the longest tested, would not exactly set a new record.
Marpa optimizes by doing a lot of grammar precomputation,
and is written long inputs in mind.
in the benchmark is Flavio's,
</p>
<p>
The reader who wants an exact description should
look at
<a href="http://blogs.perl.org/users/polettix/2012/04/parserecdescent-and-number-of-elements-read-on-the-fly.html">
Flavio's post and code</a>.
