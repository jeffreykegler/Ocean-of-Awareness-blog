A Marpa tutorial: pattern searches
  <h3>Pattern searches</h3>
    <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      We use regular expression engines for pattern searching these days.
      And this works beautifully --
      as long as the target pattern is a regular expression.
      But what if what you are searching for is not a regular expression?
    </p>
    <p>
      In this post I will show how to use Marpa to search text files for
      arbitrary context-free expressions.
      I will use arithmetic expressions as
      the example of a search target.
    </p>
    <p>
      This tutorial builds on earlier tutorials.
      It may be possible to simply dive into it,
      but it may be easier
      to start with two of my earlier posts,
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html">here</a>
      and
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">here</a>.
    </p>
    <h3>The grammar</h3>
    <p>
      Even the arithmetic subset of Perl expressions is quite complex,
      but in this case we can get the job done
      with eight lines of grammar and a lexer driven
      by a table of just over a dozen lines.
      Here is the grammar:
    </p>
    <blockquote>
      <pre>
    <tt>
start ::= prefix target
prefix ::= any_token*
target ::= expression
expression ::=
       number | scalar | scalar postfix_op
    || op_lparen expression op_rparen assoc =&gt; group
    || unop expression
    || expression binop expression`
    </tt>
    </pre>
    </blockquote>
    <p>
      This grammar uses
      <a href="https://metacpan.org/module/Marpa::R2::BNF">
        Marpa::R2's BNF interface</a>.
      It takes considerable advantage of the fact that we are not
      <b>parsing</b>
      these expressions, but
      <b>recognizing</b>
      them.
      Because of this, we don't have to specify whether expressions left- or right-associate.
      We can also ignore what operators mean and group them according to syntax only
      -- binary, prefix unary and postfix unary.
      Similarly, we can ignore the precedence within these large groups.
      This leaves us with numbers, scalars,
      parentheses,
      and binary, prefix unary and postfix unary operators.
      (To keep this example simple, we restrict the primaries
      to numeric constants and Perl scalars.)
    </p>
    <p>
      What we are searching for is defined by the
      <tt>target</tt>
      symbol.
      For
      <tt>target</tt>
      you could substitute
      the start symbol of
      any context-free grammar,
      and the structure of this example will still work.
      To turn a parser for
      <tt>target</tt>
      into a pattern searcher, we add a new start
      symbol (unimaginatively named "<tt>start</tt>")
      and two rules that
      allow the target to have a
      <tt>prefix</tt>.
    </p>
    <h3>Ambiguous parsing</h3>
    <p>To do an anchorless pattern search,
      this example will use ambiguous parsing.
      This grammar always has at least one parse going,
      representing the prefix for zero or more targets
      that our parser
      expects to find in the future.
      The prefix will never end, because
      any token (as indicated by a token
      named, literally,
      <tt>any_token</tt>)
      extends it.
    </p>
    <p>
      If we are in the process of recognizing a
      <tt>target</tt>,
      we will have one or more other parses going.
      I say "one or more" because the search method
      described in this post
      allows <tt>target</tt> to be ambiguous.
      But arithmetic expressions,
      the target pattern used in this example,
      are not ambiguous.
      So our example will have
      at most two parses active at any point:
      one for the prefix and another for the target.
    </p>
    <p>
      Ambiguous parsing has a serious potential downside --
      it is not necessarily linear
      and therefore not necessarily efficient.
      But Marpa can parse many classes of ambiguous grammar in linear time.
      Grammars like the one in this post --
      a prefix and an unambiguous search target --
      fall into one of the linearly parseable classes.
      Keeping the prefix going requires a tiny constant overhead per token.
    </p>
    <h3>The lexer table</h3>
    <p>
      The lexer is driven by a table of pairs: token name and regex.
    </p><blockquote>
      <pre>
<tt>
my @lexer_table = (
    [ number     =&gt; qr/(?:\d+(?:\.\d*)?|\.\d+)/xms ],
    [ scalar     =&gt; qr/ [\$] \w+ \b/xms ],
    [ postfix_op =&gt; qr/ [-][-] | [+][+] /xms ],
    [ unop       =&gt; qr/ [-][-] | [+][+] /xms ],
    [   binop =&gt; qr/
          [*][*] | [&gt;][&gt;] | [&lt;][&lt;]
        | [*] | [\/] | [%] | [x] \b
        | [+] | [-] | [&amp;] | [|] | [=] | [,]
    /xms
    ],
    [   unop =&gt; qr/ [-] | [+] | [!] | [~] /xms
    ],
    [ op_lparen =&gt; qr/[(]/xms ],
    [ op_rparen =&gt; qr/[)]/xms ],
);
</tt>
</pre>
    </blockquote>
    <p>
      Order is significant here.
      In particular
      two-character operators are checked for first.
      This guarantees that
      two consecutive minus signs
      will be seen as an
      increment operator, and not as a double negation.
    </p>
    <h3>Ambiguous lexing</h3>
    <p>The very careful reader may have noticed that
      <tt>any_token</tt>
      is not in the lexing table.
      The main loop is written so that every token is read as an
      <tt>any_token</tt>.
      If no token from the lexing table is accepted,
      the next character in the input stream
      is read as an
      <tt>any_token</tt>.
      If a token from the lexing table
      <b>is</b>
      accepted,
      then it gets read twice,
      once as an
      <tt>any_token</tt>,
      and once as the token type taken from the lexing table
      entry.
    </p>
    <p>Ambiguous lexing is a familiar technique to
      the Natural Language Processing community.
      Engish, in particular, is a language that abounds
      in lexemes that can play multiple roles.
      The word "sort", for example, can easily be
      an noun, a verb or an adjective.
    </p>
    <h3>The Ruby Slippers</h3>
    <p>The main loop will also be a simple case of the use
      of the Ruby Slippers.
      For those unfamiliar,
      the "Ruby Slippers" parsing technique handles difficult lexing
      and parsing problems by asking the parser, at the problem point,
      what it is looking for,
      and providing it.
      This seems a fairly obvious approach,
      but the Ruby Slippers are new with Marpa --
      traditional parsers could not easily
      determine where they were in a parse.
    </p>
    <p>
      One way to use the Ruby Slippers is to ask the parser in
      advance what it is looking for.
      The code that follows uses another method.
      Instead of determining in advance what tokens to read,
      it simply feeds its candidate tokens to the parser.
    </p>
    <p>
      Token rejection is a "soft" error -- it costs
      little to try, and little to retry.
      The following code can
      efficiently determine which entry in the lexing table is appropriate,
      simply by trying each of them in order.
      If the
      <tt>alternative()</tt>
      method returns a Perl
      <tt>undef</tt>,
      indicating that a token was rejected,
      then the main loop will try later entries in the lexing table.
    </p>
    <p>
      When a token is accepted,
      the main loop can safely assume that it is on the right track.
      Marpa is 100% accurate about
      what tokens can and cannot result in a successful parse.
    </p>
    <h3>The main loop</h3>
    <p>
      The main loop iterates through input looking for tokens.
      Whitespace is skipped.
      Comments are not skipped.
      Finding arithmetic expressions in
      strings and/or comments can be useful.
      We will assume that is the case here.
    </p>
    <blockquote>
      <pre>
<tt>
my $length = length $string;
pos $string = $positions[-1];
TOKEN: while ( pos $string &lt; $length ) {
    next TOKEN if $string =~ m/\G\s+/gcxms;    # skip whitespace
    my $position = pos $string;
    FIND_ALTERNATIVE: {
        TOKEN_TYPE: for my $t (@lexer_table) {
            my ( $token_name, $regex ) = @{$t};
            next TOKEN_TYPE if not $string =~ m/\G($regex)/gcxms;
            if ( not defined $recce-&gt;alternative($token_name) ) {
                pos $string = $position;       # reset position for matching
                next TOKEN_TYPE;
            }
            $recce-&gt;alternative('any_token');
            last FIND_ALTERNATIVE;
        } ## end TOKEN_TYPE: for my $t (@lexer_table)
        ## Nothing in the lexer table matched
        ## Just read the currrent character as an 'any_token'
        pos $string = $position + 1;
        $recce-&gt;alternative('any_token');
    } ## end FIND_ALTERNATIVE:
    $recce-&gt;earleme_complete();
    my $latest_earley_set_ID = $recce-&gt;latest_earley_set();
    $positions[$latest_earley_set_ID] = pos $string;
} ## end TOKEN: while ( pos $string &lt; $length )
</tt>
</pre>
    </blockquote>
    <p>
      The
      <tt>earleme_complete()</tt>
      method tells Marpa that all the alternatives
      at one location have been entered,
      and that the parse should now move on to the next location.
      (Marpa's idea of location is called an "earleme", in honor of the great
      parsing theorist, Jay Earley.)
    </p>
    <h3>How to parse without really trying</h3>
    <p>
    At this point, I would draw your attention to the code
    that deals with special cases for the minus sign.
    Specifically, to the fact that there isn't any.
    The more familiar you are with PPI and/or
      <tt>perly.y</tt>,
      the more remarkable this will be seem.
      </p>
      <p>
      To take one example, PPI correctly realizes that the minus
      sign in
      "<tt>1+2-3</tt>" is a binary operator.
      However PPI fails on "<tt>(1+2)-3</tt>" --
      it thinks the minus sign is part of the number "-3".
      Why don't the authors of PPI just look at the Perl
      interpreter and copy the logic there?
      Take a glance at <tt>perly.y</tt>
      and <tt>toke.c</tt> 
      and you will know the answer to that question.
      </p>
      <p>What is PPI's problem here?
      The problem is that,
      without knowing where you are in the expression,
      you cannot tell whether a minus sign is a unary
      operator or a binary operator.
      And the parse engines for PPI and for Perl itself,
      while quite different in many respects,
      share a property common to traditional parsers --
      in determining context
      they offer the lexer, respectively,
      little and no help.
      </p>
      <p>
      In the code in this example,
      Marpa's <tt>alternative()</tt> method is, by accepting
      and rejecting tokens, guiding the lexer to the right choice.
      Because of Perl's grammar, a minus sign at a given position
      cannot be both a unary operator and a binary operator.
      And Marpa is 100% accurate in its knowledge of which
      tokens are possible.
      So Marpa's
      <tt>alternative()</tt> method
      always knows whether a minus sign can be
      a unary or binary operator and accepts
      or rejects the token accordingly.
    </p>
    <p>
      This is the Ruby Slippers in action --
      a very simple solution to what for the Perl
      interpreter and PPI
      is a very complicated problem.
      When I developed the Ruby Slippers technique,
      my most serious problem 
      was believing that something
      so simple could really work.
      If the reader is having the same issue,
      I understand.
    </p>
    <h3>Finding the targets</h3>
    <p>
      Once the parse is complete, it remains to find
      and print the "targets" found
      by the search.
      In
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">
      a previous post</a>,
      I showed how, 
      given a symbol name,
      to find the last occurence of the symbol in a Marpa parse.
      That routine needed to be modified to allow repeated searches,
      but change was straightforward.
      The code is in the
      <a href="https://gist.github.com/4057239">
      gist</a>,
      and the ideas behind it were explained
      in
      <a href="http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html">
      the previous post</a>,
      so I won't repeat them here.
    </p>
    <h3>Code and comments</h3>
    <p>The example in this post is available as
    <a href="https://gist.github.com/4057239">
      a Github gist</a>.
      It was run with Marpa::R2 2.024000,
      as of this writing the latest full release,
      and tested with the displays from the
      <a href="http://perldoc.perl.org/perlop.html">perlop man page</a>.
    </p>
    <p>
      Comments can be sent to the Marpa Google Group:
      <code>marpa-parser@googlegroups.com</code>
    </p>
