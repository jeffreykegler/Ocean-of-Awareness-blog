Domain-Specific Languages made simple
<h2>Writing your own language</h2>
<p>Creating your own languages has been A Big Deal (tm).
What if you could create a simple language in hours or minutes?
There's been a serious obstacle up to now.
No practical parser "just parsed" BNF.
With Marpa, that restriction is lifted.
<p>
In this post, I will describe
a small, sample Marpa domain-specific language (DSL).
In designing it I am inspired by
<a href="http://blog.plover.com/oops/blosxom-sux.html">
Mark Dominus's description</a>
of the
<a href="http://en.wikipedia.org/wiki/Worse_is_better">
"Worse is Better" philosophy</a>,
and its implementation in the form of
<a href="http://en.wikipedia.org/wiki/Blosxom">
Blosxom</a>.
This DSL is feature-poor,
but short, simple and extensible.
<h2>A calculator</h2>
<p>
This DSL is a calculator.
Calculators are familiar and,
after all, whatever tool you build this
DSL into, it will probably be useful
to have a calculator as part of it.
What follows contains only the parts of the code
relevant to the discussion,
not necessarily in lexical order.
If you find the following interesting,
you'll almost certainly want the full code,
which is available as
a Github gist.
<!-- TODO: Make hot -->
<p>
<h2>The grammar</h2>
<p>Marpa allows you to build your DSL as a clean modular
structure,
with a separate grammar, tokenizer and semantics.
If you're used to doing parsing with regexes or recursive descent,
you expect to see things mixed together,
and much as you might like modularity in other contexts,
this cleaner approach may make you uneasy.
And not without reason, since in the past the tools that
took this approach
were painful to use and,
for cleanly written practical grammars,
often rewarded the extra effort
they required by failing to work.
<p>Here's the grammar for our calculator.

<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">
my $rules = Marpa::Demo::OP2::parse_rules(
    <<'END_OF_GRAMMAR'
reduce_op ::=
    '+'                   => do_arg0
  | '-'                   => do_arg0
  | '/'                   => do_arg0
  | '*'                   => do_arg0
script ::= e              => do_arg0
script ::= script ';' e   => do_arg2
e ::=
     NUM                  => do_arg0
   | VAR                  => do_is_var
   | :group '(' e ')'     => do_arg1
  || '-' e                => do_negate
  || :right e '^' e       => do_binop
  || e '*' e              => do_binop
   | e '/' e              => do_binop
  || e '+' e              => do_binop
   | e '-' e              => do_binop
  || e ',' e              => do_array
  || reduce_op 'reduce' e => do_reduce
  || VAR '=' e            => do_set_var
END_OF_GRAMMAR
);
</div>

<p>This is a simple language, but it's already a big advance over,
<a href="http://blog.plover.com/prog/bash-expr.html">
say, shell arithmetic</a>.
And the <tt>reduce</tt> operator is even a bit
of fanciness.
It's a second-order binary operator,
whose left operand is another operator.
<p>The grammar is written in another DSL, <tt>Marpa::Demo::OP2</tt>,
which is bundled into the same file.
Together, these two quite useable DSL's require 600 lines,
self-testing included.
The calculator grammar is written in OP2,
and OP2's grammar is defined directly in Marpa::R2.
<p>
I'm using OP2 in this post, as it presents the <strong>idea</strong>
of a grammar more clearly.
Marpa::R2's lower level syntax, while more stable, flexible and efficient,
is more cluttered.
OP2 itself is interesting as an extension and generalization of
precedence parsing,
as I described in
<a href="http://blogs.perl.org/users/jeffrey_kegler/2012/08/precedence-parsing-made-simpler.html">
a previous post</a>.
Here's its syntax:
<dl>
<dt><strong><tt>::=</tt></strong><dd>A BNF rule in LHS <tt>::=</tt> RHS form
<dt><strong><tt>'abc'</tt></strong><dd>A literal token.
<dt><strong><tt>|</tt></strong><dd>Separates alternative RHS's at the <strong>same</strong> precedence level
<dt><strong><tt>||</tt></strong><dd>Separates alternative RHS's at the <strong>different</strong> precedence levels.
  The tighter ("higher") precedence alternative is first, the
  tighter ("lower") precedence alternative is second.
<dt><strong><tt>=&gt;</tt></strong><dd><tt>rule =&gt; semantics</tt>, where <tt>semantics</tt>
is a Perl closure.
<dt><strong><tt>:left</tt></strong><dd>The alternative is left-associative (the default)
<dt><strong><tt>:right</tt></strong><dd>The alternative is right-associative
<dt><strong><tt>:group</tt></strong><dd>The alternative is grouping-associative -- that is, its
operator(s), regardless of their own precedence,
group expressions of the loosest precedence
</dl>

<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">
my $grammar = Marpa::R2::Grammar->new(
    {   start          => 'script',
        actions        => __PACKAGE__,
        rules          => $rules,
    }
);
$grammar->precompute;
</div>

<p>The code just above creates a new grammar from the OP2-generated rules.
The only other information needed to fully define
the grammar is the name of the start symbol
("<tt>script</tt>") and the name of the package where
the semantics can be found
(the current one, <tt>__PACKAGE__</tt>).
<p>Marpa does a lot of precomputation to its grammars.
Once a grammar is fully defined,
and before it a recognizer can be created from it,
the <tt>precompute()</tt> method must be called.
<h2>The Semantics</h2>
<p>The semantics for this calculator are somewhat interesting,
but this post is about how to get <strong>your</strong> interesting
semantics out easily and quickly in the of form a powerful
language specifically designed for it.
This interested in the semantics of my little caculator
can look at
the Github git.
</p>
<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">
</div>

<h2>The lexer</h2>
<h3>The token table</h3>
<p>The calculator's lexer is table-driven.
The table is quite simple -- it's an array
of two element arrays.
In the inner arrays, the first element is the symbol name,
as specified in the grammar,
and the second is a regex which matches it.
<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">

my @terminals = (
    [ q{'reduce'}, qr/reduce\b/xms ],
    [ 'NUM',       qr/\d+/xms ],
    [ 'VAR',       qr/\w+/xms ],
    [ q{'='},      qr/[=]/xms ],
    [ q{';'},      qr/[;]/xms ],
    [ q{'*'},      qr/[*]/xms ],
    [ q{'/'},      qr/[\/]/xms ],
    [ q{'+'},      qr/[+]/xms ],
    [ q{'-'},      qr/[-]/xms ],
    [ q{'^'},      qr/[\^]/xms ],
    [ q{'('},      qr/[(]/xms ],
    [ q{')'},      qr/[)]/xms ],
    [ q{','},      qr/[,]/xms ],
);

</div>
<p>
The reader will note that I am one of those who specify <tt>xms</tt> for every
regex.
It is not important in this application, but order matters if you have
terminals where one can be the prefix of another, for example,
<tt>==</tt> and <tt>=</tt>.
Note that the symbol names preserve the surrounding single quotes.
This is convenient for processing,
and it also makes diagnostic messages involving
those symbols more comprehensible.
Finally, note that the <tt>reduce</tt> operator is required to end on a word boundary.
<h3>The tokenizing engine</h3>

<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">
    my $rec = Marpa::R2::Recognizer->new( { grammar => $grammar } );

    my $length = length $string;
    pos $string = 0;
    TOKEN: while ( pos $string < $length ) {

        # skip whitespace
        next TOKEN if $string =~ m/\G\s+/gcxms;

        # read other tokens
        TOKEN_TYPE: for my $t (@terminals) {
            next TOKEN_TYPE if not $string =~ m/\G($t->[1])/gcxms;
            if ( not defined $rec->read( $t->[0], $1 ) ) {
                die_on_read_problem( $rec, $t, $1, $string, pos $string );
            }
            next TOKEN;
        } ## end TOKEN_TYPE: for my $t (@terminals)

        die q{No token at "}, ( substr $string, pos $string, 40 ),
            q{", position }, pos $string;
    } ## end TOKEN: while ( pos $string < $length )
</div>
<p>The calculator's token engine creates a Marpa recognizer
with the <tt>new()</tt> constructor,
and feeds it tokens with the <tt>read()</tt> method.
In it, I use Perl's progressive matching capabilities:
the
<tt>g</tt> and
<tt>c</tt> modifiers, the
<tt>\G</tt> assertion and the
<tt>pos</tt> function.
When writing a token engine,
there is, as the expression goes, more than one way to it,
many of them somewhat easier than this approach.
But progressive matching is powerful, efficient
very flexible
and has the advantage that
it leaves the original string intact.
<p>
Those who go on to look at the code in the gist
may find
<tt>die_on_read_problem()</tt>,
the DSL's function for handline <tt>read()</tt> errors,
helpful.
It produces a very specific and comprehensive error message.
One of Marpa's greatest improvements over previous
parsers is that, when a parse fails,
Marpa can explain why in considerable detail.
It makes sense to take full advantage of that ability.

<h2>Evaluating the parse</h2>
<p>
<div style="white-space:pre;overflow:auto;font-family:monospace;margin:0;padding:1em 0 1em 2.8em;">

    my $value_ref = $rec->value;

    if ( !defined $value_ref ) {
        say $rec->show_progress() or die "say failed: $ERRNO";
        die 'Parse failed';
    }
    return ${$value_ref};

</div>
<p>Evaluation of the parse is done with calling the <tt>value()</tt> method.
This can return all the parse results of an ambiguous parse.
We want only one parse here,
so we call <tt>value()</tt> only once.
<tt>value()</tt> returns a reference to the value of the parse,
and a Perl <tt>undef</tt> if the parse failed.
The error handling is worth noticing.
One of Marpa's strengths is that it is fully aware of which rules
are being tried at any point,
and of how far into those rules recognition has progressed.
The <tt>show_progress()</tt> method reports that information.

<h2>OP2</h2>
<p>
This ends our description of the calculator code.
In
the Github gist
a second DSL immediately follows the
calculator DSL.
This second DSL is OP2,
which is used to define the grammar for the calculator.
OP2 is more complicated than the calculator,
but its design is similar,
and it can be used as a second DSL example.
<h2>Alernatives</h2>
<h3>Marpa::R2 verus Marpa::XS</h3>
<p>This calculator uses
Marpa::R2.
Marpa::R2 is beta,
while Marpa::XS is in a stable, bug-fix only release.
On the other hand Marpa::R2 is somewhat faster here,
and its reporting of parse-time problems is cleaner.
<h3>Specifying the grammar</h3>
The grammar of the calculator is specified in OP2,
which is a clear and elegant way to do it.
But OP2 is an experimental DSL created just for this
one use.
<p>
A much more robust way to 
specify grammars is to do it directly in Marpa::R2.
OP2's grammar is specified directly in Marpa::R2.
A compromise between elegance and stability would be
to use OP2 (or a derivative)
to generate the rules (or some of them).
The OP2-generated rules can be used
as is, or edited to taste.
When you are happy with them,
Data::Dumper can turn the OP2-generated rules
into code,
which you can
then incorporate into your DSL program.
<h3>Error messages</h3>
It is hard to compare
messages from these DSL's,
unfamiliar programs whose design breaks new ground,
against, for example,
the comprehensibility of a C compiler's
error messages.
With the C compiler, I have the advantage of
over 40 years of Pavlovian training in guessing what
they really mean.
I believe that this DSL's error messages
are already, on average, up to the level of a production languages.
My main reason for this bold assertion is that
production parsers has set the bar,
frankly, extremely low.
I hasten to add, that this is often not because of lack of care or effort
by the implementers.
The traditional parsing technologies simply
do not provide enough information to support
accurate and helpful error reporting.
<p>
Much more could be done in error message handling
than is done by this DSL.
I find better error messages are often worth a high priority,
even in programs intended for personal use.
Marpa's situational awareness
makes much easier to write usefully
accurate error messages than has been the case.
