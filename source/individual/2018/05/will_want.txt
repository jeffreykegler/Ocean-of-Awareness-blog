The Five Virtues of Parsers
<html>
  <head>
  </head>
  <body>
    <p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
      In a previous post, I did a careful examination of the
      history of attempts to produce the ideal parser.
      In this one, I will look at the question in reverse --
      what makes the users of a parser
      happy or unhappy with it?
      That is, once a parser is discovered,
      makes it successful?
    </p>
    <h1>The first virtue: fast</h1>
    <p>
      By one accounting,
      the first systematic attempt at parsing
      was via regular expressions.
      Regular expressions are still very much with us,
      so they obviously must demonstrate at least <b>some</b>
      of the virtues that make a parser popular.
    </p>
    <p>
      The most superficial of these is that
      a parser must be "fast enough"
      to please its users.
      A rigorous understanding of what "fast enough" means
      was slow to emerge,
      but it is now clear that, except in restricted uses,
      a parser must be linear or quasi-linear,
    </p>
    <h1>The second virtue: predictable</h1>
    <p>
    Less obvious is what I will call "predictability":
    It must be possible for a programmer,
    with reasonable effort,
    to know if her grammar
    will be parsed by the parser.
    In this respect, regular expressions can be called
    perfect --
    there's a handy notation for them.
    Anything in that notation is a regular expression,
    and will be parsed in linear time by your regular
    expression engine --
    you never need to desk-check.
    </p>
    <h1>The third virtue: power</h1>
    <p>Regular expressions, however,
    were not the end of the parsing story --
    from a strictly Chomskyan point of view,
    in fact, they are note even the beginning.
    If a programmer has a grammar she considers practical,
    she wants her parser to parse it.
    Here regular expressions often fail -- a lot of practical
    grammar are regular expressions, but many others are not.
    For regular expressions,
    one of the fails is ironic --
    the notation for regular expressions is recursive,
    but regular expressions cannot deal with recursion.
    </p>
    <p>
    Grabs for power predate the parsing literature,
    which begins with Irons 1961.
    In terms of power,
    Irons parser is "general",
    meaning that it can parse what are called
    the "context-free grammars".
    </p>
    <p>
    The context-free grammars are exactly those which can
    be written in BNF.
    This means that Irons parser had the same kind of predictability
    that regular expressions had -- it could parse every grammar
    written in its grammar notation.
    Again, there was no need to desk check,
    but this time the class of grammars that could be parsed was
    much, much larger.
    </p>
    <h1>The Fourth Virtue: reliability</h1>
    <p>
    The Irons 1961 algorithm was perfectly predictable,
    it was predictably powerful,
    and it could be fast.
    But it could not be relied on to be fast.
    In the general case,
    Irons 1961 used backtracking
    to achieve its power,
    so it would go exponential for many useful grammars.
    Iron 1961 was fast but not predictably fast.
    <p>
    </p>
    This would go without saying,
    except that solutions to the parsing problem are often advanced
    which trade power for reliability.
    An algorithm which can go quadratic or worse is often used to supplement
    an algorithm which lacks power.
    It's a kind of cross-breeding of algorithms.
    The hope is that the hybrid, in your use case,
    had the power of the slow algorithm and the
    speed of the fast one.
    This works a lot better in botany than it does in parsing.
    Once you have a successful cross in a plant,
    you can breed from that and expect good things.
    But if even once you've lucked out with a parse,
    your next parse is a just another new toss of the dice.
    </p>
    <p>
    [ TO HERE ] <br>
    Which brings us to why, despite all of its very nice properties,
    people try, and often need to, do better than regular expressions:
    power.
    How wide a variety of grammars can the algorithm parse?
    In the case of regular expressions, it flunks an obvious test --
    no notation for regular expressions can be parsed by a regular expression.
    That is because, while regular expressions are
    recursive, they cannot parse recursions.
    </p>
    <p>In 19XX it was thought the next step up in power,
    consistent with the Three Basic Virtues,
    might have been found:
    A parser called yacc parsed a class of grammars called LALR.
    LALR clearly had two of the Basic Virtues (fast and reliable)
    and it could be said to have the third if you were willing to stretch a point.
    Technically,
    it took a mathematician to tell if a grammar is LALR.
    But what was probably the most sophisticated LALR grammar was
    created by Larry Wall, a non-mathematician --
    so one could get sense of it after a few hard knocks.
    </p>
    <h2>References, comments, etc.</h2>
    <p>
      For more about
      Marpa, my own parsing project,
      there is the
      <a href="http://savage.net.au/Marpa.html">semi-official web site, maintained by Ron Savage</a>.
      The official, but more limited, Marpa website
      <a href="http://jeffreykegler.github.io/Marpa-web-site/">is my personal one</a>.
      Comments on this post can be made in
      <a href="http://groups.google.com/group/marpa-parser">
        Marpa's Google group</a>,
      or on our IRC channel: #marpa at freenode.net.
    </p>
  </body>
</html>
