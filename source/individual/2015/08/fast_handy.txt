Fast handy languages
<html>
  <head>
  </head>
  <body><p>
      <!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      -->
    </p>
    <p>Back around 19--, I had a language I wanted to parse
      and access to UNIX,
      a system which I knew had all the latest CS tools.
      So I expected type in my BNF and "Presto, Language!".
    </p><p>Not so easy, I was told.
      Languages were difficult things created by complex tools
      written by experts who understood the difficulties.
      I recall thinking that English had a syntax that is
      as hard as they come, yet toddlers manage to parse it
      just fine.
      But experts can be hard to convince,
      and second-hand experts even more so.
    </p><p>I was steered to an LALR-based parser called yacc.
      (Readers may be more familiar bison, a yacc successor.)
      LALR had extended the class of quickly parseable grammars a bit
      over recursive descent,
      but where recursive descent was easy to understand and hack,
      debugging LALR challenges the experts.
      To make an unpleasant story a short one,
      I eventually gave up on yacc
      and solved my problem another way.
    </p><p>Few people complained about yacc on the Internet.
      If you noise it about that you are unable
      to get the state-of-the-art tools to work for you,
      and conclusions are drawn,
      they may not be the ones you want.
      But my experience must have been more than common.
    </p><p>LALR's claim to fame was that it was the basis of the
      new industry-standard C compiler.
      Over 4 decades,
      its maintainers suffered in silence,
      but by 19--, they'd had enough.
      GCC (the new industry standard)
      ripped its LALR engine out.
      The trend ever since, has been back to recursive descent.
    </p><h3>A surprise discovery</h3>
    <p>Even back in the 1970's,
      there had been more powerful alternatives
      to LALR and recursive descent.
      But they were reputed to be slow.
    </p><p>But there are some applications where slow is OK,
      and in 2007 I decided a parsing tool that parsed
      all context-free languages at state-of-the-art speeds,
      slow or fast as the case may be,
      would be a useful addition to programmer toolkits.
      And I ran into a surprise.
    </p><p>Hidden in the literature was an amazing discovery --
      an 1991 article by Joop Leo described how to modify Earley's
      algorithm to be fast for every language class in practical use.
      (When I say "fast" in this article, I will mean "linear".)
      Leo's article had been almost completely ignored --
      my project (Marpa) would be its first
      practical implementation.
    </p><h3>Second-order languages</h3>
    <p>The implications of Leo's discovery go well beyond speed.
      <b>If</b>
      you can rely on the BNF that you write always producing
      a practical parser, you can auto-generate your language.
      In fact,
      you can write languages which write languages.
    </p><h3>Which are the fast languages></h3>
    <p>The Leo/Earley algorithm is not fast
      for every BNF-expressible language.
      BNF is powerful, and you can write exponentially
      ambiguous languages in it.
      But programmers these days only care about unambiguous languages --
      they are accustomed to tools which parse only a subset of these.
    </p>
    <p>
      As I've said, Marpa is fast for every language in
      a class in practical use today.
      Since the modern tools for parsing impose severe limits,
      Marpa is almost certainly fast for any language,
      that a modern programmer has in mind.
      But for more ambitious uses of Marpa,
      such as second-order languages,
      it is useful to be more exact.
      You can guarantee that Marpa is fast for your BNF language,
      if you follow three rules:
    </p><ul>
      <li>Rule 1: Your BNF must be unambiguous.
      </li><li>Rule 2: Your BNF must have no "unmarked" middle recursions.
      </li><li>Rule 3: All of the right-recursive symbols
        in your BNF must be dedicated
        to that right recursion.
      </li></ul>
    <p>Rule 3 is easy to obey.
      A right recursive symbol is "dedicated" if it appears only
      as part of a right recursion.
      If for some reason your BNF does not happen obey rule 3,
      you can easily rewrite it to do so.
      Just take your "undedicated" symbol and create two symbols
      with the same semantics
    </p><p>
      [ to here ]
    </p><p>For those not yet in the know on this,
      I'll illustrate with a pair of examples from
      <a href="http://www.romanredz.se/papers/FI2008.pdf">
        an excellent 2008 paper by Redziejowski</a>.
      Let's start with these two PEG specifications.
    </p><blockquote><pre>
    ("a"|"aa")"a"
    ("aa"|"a")"a"
    </pre></blockquote><p>
      One of these two PEG grammars accepts
      the string "<tt>aaa</tt>" but not the string "<tt>aa</tt>".
      The other does the opposite -- it accepts the string
      the string "<tt>aa</tt>" but not the string "<tt>aaa</tt>".
      Can you tell which one?
      (For the answer,
      see page 4 of
      <a href="http://www.romanredz.se/papers/FI2008.pdf">
        Redziejowski 2008</a>.)
    </p>
    <h3>Comments</h3>
    <p>Comments on this post can be made in
      <a href="http://groups.google.com/group/marpa-parser">
        Marpa's Google group</a>,
      or on our IRC channel: #marpa at freenode.net.
      To learn more about Marpa,
      there's
      <a href="http://savage.net.au/Marpa.html">the
        official web site maintained by Ron Savage</a>.
      I also have
      <a href="http://jeffreykegler.github.io/Marpa-web-site/">a Marpa web site</a>.
    </p>
  </body>
</html>
