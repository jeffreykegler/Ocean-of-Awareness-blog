<?xml version="1.0"?>
<!-- name="generator" content="blosxom/2.0" -->
<!DOCTYPE rss PUBLIC "-//Netscape Communications//DTD RSS 0.91//EN" "http://my.netscape.com/publish/formats/rss-0.91.dtd">

<rss version="0.91">
  <channel>
    <title>Ocean of Awareness   </title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog</link>
    <description>Ocean of Awareness.</description>
    <language>en</language>

  <item>
    <title>A Marpa tutorial: Pattern searches</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html</link>
    <description>  &lt;h3&gt;Pattern searches&lt;/h3&gt;
    &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      These days we use regular expression engines for pattern searching.
      And this works beautifully --
      as long as the target pattern is a regular expression.
    &lt;/p&gt;
    &lt;p&gt;
      But if what you are searching for is not a regular expression?
      You could approximate with an over-liberal regular expression,
      and sort out any false positives by other means.
      Or you could be out of luck.
    &lt;/p&gt;
    &lt;p&gt;
      In this post I will show how to use Marpa to search text files for
      arbitrary context-free expressions.
      As a search target,
      The example I will use will be arithmetic expressions.
    &lt;/p&gt;
    &lt;p&gt;
      This tutorial builds on earlier tutorials.
      It is possible to simply dive into it,
      but it may be easier
      to start with earlier posts
&lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html&quot;&gt;here&lt;/a&gt;
and
&lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html&quot;&gt;here&lt;/a&gt;.
    &lt;/p&gt;
    &lt;h3&gt;The grammar&lt;/h3&gt;
    &lt;p&gt;
      Even the arithmetic subset of Perl expressions is quite complex,
      but in this case we can get the job done
      with a dozen or so lines of grammar and a table-driven lexer.
      Here is the grammar:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
    &lt;tt&gt;
start ::= prefix target
prefix ::= any_token*
target ::= expression
expression ::=
       number | scalar | scalar postfix_op
    || op_lparen expression op_rparen assoc =&amp;gt; group
    || unop expression
    || expression binop expression`
    &lt;/tt&gt;
    &lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      This grammar uses &lt;a href=&quot;https://metacpan.org/module/Marpa::R2::BNF&quot;&gt;
      Marpa::R2's BNF interface&lt;/a&gt;.
      It takes considerable advantage of the fact that we are not
      &lt;b&gt;parsing&lt;/b&gt;
      these expressions, but
      &lt;b&gt;recognizing&lt;/b&gt;
      them.
      Because of this, we don't have to specify whether expressions left- or right-associate.
      We can also ignore what operators mean and group them according to syntax only
      -- binary, prefix unary and postfix unary.
      Similarly, we can ignore the precedence within these large groups.
      This leaves us with numbers, scalars,
      binary, prefix unary and postfix unary operators
      and parentheses.
      (To keep this example simple, this code only deals with Perl scalars.)
    &lt;/p&gt;
    &lt;p&gt;
      What we are searching for is defined by the
      &lt;tt&gt;target&lt;/tt&gt;
      symbol.
      For &lt;tt&gt;target&lt;/tt&gt;
      you could substitute any context-free grammar,
      and the technique of this example would still work.
      To turn a parser for &lt;tt&gt;target&lt;/tt&gt;
      into a pattern searcher, we add a new start
      symbol (unimaginatively named &quot;&lt;tt&gt;start&lt;/tt&gt;&quot;)
      and two rules that
      allow the target to have a
      &lt;tt&gt;prefix&lt;/tt&gt;.
    &lt;/p&gt;
&lt;h3&gt;Ambiguous parsing&lt;/h3&gt;
&lt;p&gt;To do an anchorless pattern search,
this example will make use of Marpa'a facility with
ambiguous parsing.
This grammar always has at least one parse going,
representing the prefix of zero or more target that it
will find in the future.
The prefix will never end, because
      any token (literally
      &lt;tt&gt;any_token&lt;/tt&gt;)
      extends it.
&lt;/p&gt;
&lt;p&gt;
If we are recognizing a
      &lt;tt&gt;target&lt;/tt&gt;,
      we will have one or more other parses going.
I say &quot;one or more&quot; because using this method a target can be ambiguous.
In this specific example, the target is not ambiguous,
so at most two parses will be active:
one for the prefix and another for the target.
    &lt;/p&gt;
    &lt;p&gt;
Ambiguous parsing has a serious potential downside --
      it is not necessarily efficient.
      But Marpa can parse many types of ambiguous grammar in linear time and,
      grammars in this
      this class of &quot;prefix and unambiguous pattern&quot; are one of them.
Keeping the prefix going requires a tiny constant overhead per token.
    &lt;/p&gt;
    &lt;h3&gt;The lexer table&lt;/h3&gt;
    &lt;p&gt;
      The lexer is driven by a table of pairs: token name and regex.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
&lt;tt&gt;
my @lexer_table = (
    [ number     =&amp;gt; qr/(?:\d+(?:\.\d*)?|\.\d+)/xms ],
    [ scalar     =&amp;gt; qr/ [\$] \w+ \b/xms ],
    [ postfix_op =&amp;gt; qr/ [-][-] | [+][+] /xms ],
    [ unop       =&amp;gt; qr/ [-][-] | [+][+] /xms ],
    [   binop =&amp;gt; qr/
          [*][*] | [&amp;gt;][&amp;gt;] | [&amp;lt;][&amp;lt;]
        | [*] | [\/] | [%] | [x] \b
        | [+] | [-] | [&amp;amp;] | [|] | [=] | [,]
    /xms
    ],
    [   unop =&amp;gt; qr/ [-] | [+] | [!] | [~] /xms
    ],
    [ op_lparen =&amp;gt; qr/[(]/xms ],
    [ op_rparen =&amp;gt; qr/[)]/xms ],
);
&lt;/tt&gt;
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      Order is significant here.
      In particular
      two-character operators are checked for first.
      This guarantees that
      two consecutive minus signs
      will be seen as an
      increment operator, and not as a double negation.
    &lt;/p&gt;
    &lt;h3&gt;The main loop&lt;/h3&gt;
    &lt;p&gt;
      The main loop iterates through input looking for tokens.
      Whitespace is skipped.
      Note that comments are not skipped.
      Finding arithmetic expressions in
      strings and/or comments can be highly useful,
      and we will assume that in this case that it is.
    &lt;/p&gt;
    &lt;p&gt;
      The most interesting action is inside the
      &lt;tt&gt;FIND_ALTERNATIVE&lt;/tt&gt;
      block, where the order of the lexing table is combined with
      &quot;Ruby Slippers&quot; parsing.
      The &quot;Ruby Slippers&quot; parsing technique solves difficult lexing
      and parsing problems by asking the parser, at the problem point,
      what it is looking for.
      This seems a fairly obvious approach,
      but the Ruby Slippers is new with Marpa --
      previous parsers could not provide this information conveniently
      or efficiently.
    &lt;/p&gt;
    &lt;p&gt;
      As an example,
      a real problem here is minus signs,
      which can negate a number,
      be a subtraction operation,
      or be part of a decrement operation (postfix or prefix).
      Some of this issue is dealt with by the lexer.
      The order of lexer table puts two-character operators,
      like decrement,
      (&quot;&lt;tt&gt;--&lt;/tt&gt;&quot;)
      before one-character operators,
      such as negation
      (&quot;&lt;tt&gt;-&lt;/tt&gt;&quot;).
    &lt;/p&gt;&lt;p&gt;In this lexer, an initial minus sign is never part of a number.
      A number constant is always positive, though it may have
      a unary negation operator in front of it.
      PPI sometimes includes initial minus signs in numeric
      constants. Unfortunately, lacking the Ruby Slippers,
      it will do this in cases where the minus
      sign is actually a binary operator.
    &lt;/p&gt;
    &lt;p&gt;
      The
      &lt;tt&gt;FIND_ALTERNATIVE&lt;/tt&gt;
      loop is short,
      but worth a careful look.
      It tries every lexeme, in lexer table order.
      If the
      &lt;tt&gt;alternative()&lt;/tt&gt;
      method
      returns a Perl
      &lt;tt&gt;undef&lt;/tt&gt;,
      it means the token was &quot;rejected&quot;.
      This means the parser was not expecting it.
      Unlike most parsers in use today, Marpa is 100% accurate about
      what tokens can and cannot result in a successful parse.
    &lt;/p&gt;
    &lt;p&gt;
      This means that Marpa knows whether a minus sign can be
      a unary or binary operator.
      (Because of Perl's grammar, it can be one or the other,
      but never both in the same position.)
      This is the Ruby Slippers in action --
      a very simple solution to what for
      &lt;tt&gt;perly.y&lt;/tt&gt;
      and PPI is a very complicated problem.
    &lt;/p&gt;
    &lt;p&gt;
      Once the right token has been determined, the
      &lt;tt&gt;alternative()&lt;/tt&gt;
      method is called again to
      ready in an
      &lt;tt&gt;any_token&lt;/tt&gt;.
      (Marpa allows ambiguous lexing --
      the same character can be read as two different
      tokens.)
      If the entire lexer table is tried, and no acceptable
      lexeme is found,
      a single character is read as an
      &lt;tt&gt;any_token&lt;/tt&gt;.
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
&lt;tt&gt;
my $length = length $string;
pos $string = $positions[-1];
TOKEN: while ( pos $string &amp;lt; $length ) {
    next TOKEN if $string =~ m/\G\s+/gcxms;    # skip whitespace
    my $position = pos $string;
    FIND_ALTERNATIVE: {
        TOKEN_TYPE: for my $t (@lexer_table) {
            my ( $token_name, $regex ) = @{$t};
            next TOKEN_TYPE if not $string =~ m/\G($regex)/gcxms;
            if ( not defined $recce-&amp;gt;alternative($token_name) ) {
                pos $string = $position;       # reset position for matching
                next TOKEN_TYPE;
            }
            $recce-&amp;gt;alternative('any_token');
            last FIND_ALTERNATIVE;
        } ## end TOKEN_TYPE: for my $t (@lexer_table)
        ## Nothing in the lexer table matched
        ## Just read the currrent character as an 'any_token'
        pos $string = $position + 1;
        $recce-&amp;gt;alternative('any_token');
    } ## end FIND_ALTERNATIVE:
    $recce-&amp;gt;earleme_complete();
    my $latest_earley_set_ID = $recce-&amp;gt;latest_earley_set();
    $positions[$latest_earley_set_ID] = pos $string;
} ## end TOKEN: while ( pos $string &amp;lt; $length )
&lt;/tt&gt;
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      The
      &lt;tt&gt;earleme_complete()&lt;/tt&gt;
      method tells Marpa that all the alternatives
      for that location have been entered.
      (Marpa's idea of location is called an &quot;earleme&quot;, in honor of the great
      parsing theorist, Jay Earley.)
    &lt;/p&gt;
    &lt;h3&gt;Finding the targets&lt;/h3&gt;
    &lt;p&gt;
      Once the parse is complete, it remains to find
      and print the &quot;targets&quot; found
      by the search.
      In a previous post,
      I showed how, for error reporting, to find the last symbol found,
      given a symbol name.
      That routine needs to be modified to allow repeated searches.
      The code is in the gist,
      and was explained in the previous post,
      so I won't repeat here.
    &lt;/p&gt;
    &lt;h3&gt;Pattern searching and incremental development&lt;/h3&gt;
    &lt;p&gt;
    You may notice that this pattern searcher is also
    a start on a Perl parser.
    The first priority would have to be restoring proper associativity
    and precedence to the expressions.
    This can be done by copying the
    table at the beginning of the perlop man page
    into the precedence statement in the grammar.
    &lt;/p&gt;
    &lt;p&gt;
    From this start, you would adding more and more syntax to the grammar,
    and more and more recognition to the lexer.
    As you expanded the pattern searcher, the target would gradually become
    closer and closer to the entire language.
    &lt;/p&gt;
    &lt;p&gt;
    When, for all valid input files, your pattern searcher always finds
    a single match that spans the input file, you can remove rules which
    parse the prefix, and make &lt;tt&gt;target&lt;/tt&gt; the new start symbol.
    Or you may wish to keep them, as an aid to error reporting.
    Either way, your parser is finished.
    My own experience is that parsers are far easier
    to write
    if you can build them incrementally,
    taking advantage of the kind of feedback that Marpa allows.
    &lt;/p&gt;
    &lt;h3&gt;Comments&lt;/h3&gt;
    &lt;p&gt;The example in this post was run with Marpa::R2 2.024000,
      as of this writing the latest full release.
      Comments can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>A grammar that exemplifies, describes and parses itself</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/self_parse.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      I've written a grammar in Marpa's new BNF interface,
      to parse Marpa's new BNF interface.
      In the 70's, when I learned parsing theory,
      this was a very fashionable thing to do, perhaps because
      yacc had done it,
      in Appendix B of
      &lt;a href=&quot;http://dinosaur.compilertools.net/yacc/&quot;&gt;
        the original 1975 paper&lt;/a&gt;.
      By 1979, Hoftstadter's book Godel-Escher-Bach (GEB) was out,
      and the next year it took the Pulitzer for
      General Nonfiction.
      Self-description, recursion, self-reference, self-embedding,
      you
      (preferably
      &lt;a href=&quot;http://en.wikipedia.org/wiki/Autological_word&quot;&gt;autologically&lt;/a&gt;)
      name it,
      these things were all the rage.
    &lt;/p&gt;
    &lt;p&gt;Reading code
    that is at once both self-example and self-description
    still holds a certain magic for me.
      Regular expressions cannot describe themselves.
      Recursive descent parsers are hand-written
      in another general-purpose language,
      so there can be no concise self-description.
      Ironically, yacc actually cannot parse its own description language.
      (&quot;Ironically&quot; is the word used in the paper.)
      Like almost all useful grammars, yacc's description language
      goes beyond the capabilities of yacc's LALR parser,
      and a lexer hack is needed to make the code in Appendix B work.
    &lt;/p&gt;
    &lt;p&gt;Marpa is a general BNF parser and requires no special hacks
    to parse the following efficiently:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
rules ::= rule+ action =&gt; do_rules
rule ::= empty_rule | priority_rule | quantified_rule
priority_rule ::= lhs op_declare priorities
  action =&gt; do_priority_rule
empty_rule ::= lhs op_declare adverb_list
  action =&gt; do_empty_rule
quantified_rule ::= lhs op_declare name quantifier adverb_list
    action =&gt; do_quantified_rule
priorities ::= alternatives+
    separator =&gt; op_tighter proper =&gt; 1
    action =&gt; do_discard_separators
alternatives ::= alternative+
    separator =&gt; op_eq_pri proper =&gt; 1
    action =&gt; do_discard_separators
alternative ::= rhs adverb_list action =&gt; do_alternative
adverb_list ::= adverb_item* action =&gt; do_adverb_list
adverb_item ::=
      action
    | left_association | right_association | group_association
    | separator_specification | proper_specification

action ::= kw_action op_arrow name action =&gt; do_action
left_association ::= kw_assoc op_arrow kw_left
  action =&gt; do_left_association
right_association ::= kw_assoc op_arrow kw_right
  action =&gt; do_right_association
group_association ::= kw_assoc op_arrow kw_group
  action =&gt; do_group_association
separator_specification ::= kw_separator op_arrow name
  action =&gt; do_separator_specification
proper_specification ::= kw_proper op_arrow boolean
action =&gt; do_proper_specification

lhs ::= name action =&gt; do_lhs
rhs ::= names
quantifier ::= op_star | op_plus
names ::= name+ action =&gt; do_array
name ::= bare_name | reserved_word | quoted_name
name ::= bracketed_name action =&gt; do_bracketed_name

reserved_word ::= kw_action | kw_assoc | kw_separator | kw_proper
  | kw_left | kw_right | kw_group
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
    The conventions are standard or transparent.
    The &quot;&lt;tt&gt;::=&lt;/tt&gt;&quot; symbol separates the left and right hand sides of rules.
    The &quot;&lt;tt&gt;|&lt;/tt&gt;&quot; symbol separates alternative right hand sides.
    The &quot;&lt;tt&gt;*&lt;/tt&gt;&quot; and
    &quot;&lt;tt&gt;+&lt;/tt&gt;&quot; are quantifiers, similar to those in regular expressions,
    and indicate, respectively, zero or more repetitions and one or more repetitions
    of the preceding symbol.
    Adverbs take the form &quot;&lt;tt&gt;keyword =&gt; value&lt;/tt&gt;&quot;,
    and indicate semantics or the style of sequence separation.
    Full documentation can be found
    &lt;a href=&quot;https://metacpan.org/module/JKEGL/Marpa-R2-2.023_010/pod/BNF.pod&quot;&gt;
    here&lt;/a&gt;.
    &lt;p&gt;
      Self-parsing compiler compilers ruled the earth
      in the age of bellbottoms.
      Self-parsing has lasted better, but not by much.
      When some years I wrote a self-describing language as an interface to
      Marpa, it seemed to confuse people.
      They wondered what Marpa did --
      parsing your own description did not seem to be
      about &lt;b&gt;doing&lt;/b&gt; anything.
      These days my examples feature a lot of calculators.
      (&quot;Ironically&quot;, Hofstadter seems to have had the same problem with
      GEB -- he felt that
      people did not understand what his book was saying --
      even those who liked it.)
    &lt;/p&gt;
    &lt;p&gt;
      But ideas from Larry Wall and Peter Stuifzand
      have re-ignited my interest in self-parsing.
      And this time the self-parsing parser was written
      with a specific purpose.
      I plan to enhance this language.
      I have found that the convenience of this interface
      more than compensates for the circular
      dependency issues.
      The BNF source in this post is
      &lt;a href=&quot;https://metacpan.org/source/JKEGL/Marpa-R2-2.023_010/lib/Marpa/R2/meta/Stuifzand.bnf&quot;&gt;
      the source&lt;/a&gt;
      for its own parser,
      and I plan to use it
      to produce improved versions
      of itself.
    &lt;/p&gt;
    &lt;h3&gt;Comments&lt;/h3&gt;
    &lt;p&gt;
      Comments on this post can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>A Marpa DSL tutorial: Error reporting made easy</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      Using
      Marpa's facilities for error reporting,
      a quickly written domain-specific language can,
      as of its first draft,
      have error reporting whose helpfulness and precision exceeds
      that of carefully hand-crafted production compilers.
      This post will show how, with an example.
    &lt;/p&gt;&lt;p&gt;
      Two techniques will be used.
      First and most basic,
      Marpa's knowledge of the point
      at which the parse
      can no longer proceed is 100% accurate and immediate.
      This is not the case with yacc-derived parsers,
      and is not the case with most recursive descent parsers.
    &lt;/p&gt;
    &lt;p&gt;
      However, even Marpa's 100% accuracy in pinpointing
      the problem location is only accuracy
      in the technical sense -- it cannot take into account what the
      programmer intended.
      A second technique allows the programmer to double-check his
      intentions against what the parser has actually seen.
      Marpa can tell the programmer exactly how it thinks
      the input parsed, up to the point at which it could no
      longer proceed.
      The Marpa parser can report the answer to questions like
    &lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;
        &quot;What was the last statement you successfully parsed?&quot;&lt;br&gt;
        &quot;What was the last expression you successfully parsed?&quot;&lt;br&gt;
        &quot;What was the last arithmetic expression you successfully parsed?&quot;&lt;br&gt;
        &quot;Where did the last successfully parsed block start?  End?&quot;&lt;br&gt;
      &lt;/p&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;The language&lt;/h3&gt;
    &lt;p&gt;
      To focus on the logic of the error reporting,
      I looked for a language that was error-prone,
      but extremely simple.
      For this purpose,
      prefix arithmetic is like a gift from the dakinis.
      It is almost trivial in concept,
      and almost impossible to get right when it is more than a few
      characters long.
      Two valid strings in this language are
      &lt;q&gt;say + 1 2&lt;/q&gt;
      and
      &lt;q&gt;+++ 1 2 3 + + 1 2 4&lt;/q&gt;.
      Their results are, in order, 3 and 13.
    &lt;/p&gt;&lt;p&gt;
      I restricted the calculator to addition, because even with one
      operator, prefix notation is more than confusing enough to serve our purposes.
      I have included an optional
      &lt;tt&gt;say&lt;/tt&gt;
      keyword, in order
      to illustrate rejection of a token by type.
      In pure prefix arithmetic, either all tokens are valid or none are.
      The
      &lt;tt&gt;say&lt;/tt&gt;
      keyword is only valid as the first token.
    &lt;/p&gt;&lt;h3&gt;The grammar&lt;/h3&gt;&lt;p&gt;
      The full code for this post is in
      &lt;a href=&quot;https://gist.github.com/3974816&quot;&gt;
        a Github gist&lt;/a&gt;.
      It was run using
      &lt;a href=&quot;https://metacpan.org/release/JKEGL/Marpa-R2-2.023_008&quot;&gt;
        a release candidate for the full release of Marpa::R2&lt;/a&gt;.
      Here is the grammar.
    &lt;/p&gt;&lt;blockquote&gt;&lt;pre&gt;&lt;tt&gt;
my $prefix_grammar = Marpa::R2::Grammar-&amp;gt;new(
    {   start          =&amp;gt; 'Script',
        actions        =&amp;gt; 'My_Actions',
        default_action =&amp;gt; 'do_arg0',
        rules          =&amp;gt; [ &amp;lt;&amp;lt;'END_OF_RULES' ]
Script ::=
     Expression
   | kw_say Expression action =&amp;gt; do_arg1
Expression ::=
     Number
   | op_add Expression Expression action =&amp;gt; do_add
END_OF_RULES
    }
);
&lt;/tt&gt;&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;The rules are specified in another DSL,
      of the kind I've used
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html&quot;&gt;
        in previous posts&lt;/a&gt;.
      This one is incorporated in Marpa::R2 itself,
      and is
      &lt;a href=&quot;https://metacpan.org/module/JKEGL/Marpa-R2-2.023_008/pod/BNF.pod&quot;&gt;
        documented here&lt;/a&gt;.
      Here are its features relevant to this example:
    &lt;/p&gt;&lt;dl&gt;
      &lt;dt&gt;&lt;strong&gt;&lt;tt&gt;::=&lt;/tt&gt;&lt;/strong&gt;&lt;/dt&gt;
      &lt;dd&gt;A BNF rule in LHS
        &lt;tt&gt;::=&lt;/tt&gt;
        RHS form&lt;/dd&gt;
      &lt;dt&gt;&lt;strong&gt;&lt;tt&gt;|&lt;/tt&gt;&lt;/strong&gt;&lt;/dt&gt;
      &lt;dd&gt;Separates alternative RHS's at the
        &lt;strong&gt;same&lt;/strong&gt;
        precedence level&lt;/dd&gt;
      &lt;dt&gt;&lt;strong&gt;&lt;tt&gt;=&amp;gt;&lt;/tt&gt;&lt;/strong&gt;&lt;/dt&gt;
      &lt;dd&gt;&lt;tt&gt;keyword =&amp;gt; value&lt;/tt&gt;, where
        &lt;tt&gt;keyword&lt;/tt&gt;
        is the name of an adverb.&lt;/dd&gt;
    &lt;/dl&gt;
    &lt;p&gt;The
      &quot;&lt;tt&gt;action =&amp;gt; do_add&lt;/tt&gt;&quot;
      adverb indicates that the semantics for the alternative
      are in the Perl closure named
      &lt;tt&gt;do_add&lt;/tt&gt;.
    &lt;/p&gt;&lt;p&gt;The rest of the grammar's definition will be familiar to Marpa users.
      &lt;tt&gt;Script&lt;/tt&gt;
      is the start symbol,
      the Perl closures implementing semantics are to be found in the
      &lt;tt&gt;My_Actions&lt;/tt&gt;
      package,
      and where no semantics are explicitly specified,
      the Perl closure
      &lt;tt&gt;do_arg0&lt;/tt&gt;
      is the default.
    &lt;/p&gt;&lt;h3&gt;The semantics&lt;/h3&gt;
    &lt;p&gt;The semantics for this example are easy.
    &lt;/p&gt;&lt;blockquote&gt;&lt;pre&gt;&lt;tt&gt;
sub My_Actions::do_add  { shift; return $_[1] + $_[2] }
sub My_Actions::do_arg0 { shift; return shift; }
sub My_Actions::do_arg1 { shift; return $_[1]; }
&lt;/tt&gt;&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;
      The first argument to a Marpa semantic closure is a &quot;per-parse variable&quot;,
      which is not used in this application.
      The other arguments are the values of the child nodes,
      as determined recursively and in lexical order.
    &lt;/p&gt;&lt;h3&gt;The lexing table&lt;/h3&gt;
    &lt;p&gt;
      In this post,
      I am skipping around in the code --
      &lt;a href=&quot;https://gist.github.com/3974816&quot;&gt;
        the full code is in the gist&lt;/a&gt;.
      But lexical analysis is of particular interest to new
      Marpa users.
      The lexer I use for this example is overkill --
      table-driven and using Perl's progressive matching
      capabilities, it is capable of serving a much more
      complex language.
      (I talked about lexing more
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html&quot;&gt;
        in a previous example&lt;/a&gt;.)
      Here is the lexing table:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
my @terminals = (
    [ Number =&amp;gt; qr/\d+/xms,   'Number' ],
    [ op_add =&amp;gt; qr/[+]/xms,   'Addition operator' ],
    [ kw_say =&amp;gt; qr/say\b/xms, qq{&quot;say&quot; keyword} ],
);
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;The lexing table is an array of 3-element arrays.
      Each sub-array contains the symbol name, a regular expression
      that is used to recognize it, and a &quot;long name&quot;,
      a human-readable name more appropriate for error messages
      than the symbol name.
      For some languages,
      the order of our lexing tables may be significant,
      although in the case of this language it makes no difference.
    &lt;/p&gt;
    &lt;h3&gt;Types of parsing error&lt;/h3&gt;
    &lt;p&gt;Before plunging into the error-handling code,
      I will describe the forms parsing errors take,
      and show the messages that the code this example
      DSL's error handling produces.
    &lt;/p&gt;
    &lt;h4&gt;No valid token&lt;/h4&gt;
    &lt;p&gt;The lexer may reach a point in the input
      where it does not find one of the allowed tokens.
      An example in this language would be an input with an
      an exclamation point.
      This is no need to talk much about this kind of error,
      which has always been relatively easy to diagnose,
      pinpoint and, usually, to fix.
    &lt;/p&gt;
    &lt;h4&gt;The parser rejects a token&lt;/h4&gt;
    &lt;p&gt;
      In some cases the lexer finds a token,
      but it is not one
      that the parser will accept at that point,
      so the parser rejects the token.
      An example for this language would be the input
      &quot;&lt;tt&gt;+ 1 say 2&lt;/tt&gt;&quot;, which causes the following diagnostic:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
Last expression successfully parsed was:  1
A problem occurred here:  say 2
Parser rejected token &quot;&quot;say&quot; keyword&quot;
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;Marpa successfully determined that
      &quot;&lt;tt&gt;1&lt;/tt&gt;&quot; is a valid expression of the language, but
      &quot;&lt;tt&gt;+ 1&lt;/tt&gt;&quot; is not.
    &lt;/p&gt;
    &lt;h4&gt;The parser becomes exhausted&lt;/h4&gt;
    &lt;p&gt;
      In other cases, the parser may &quot;dead end&quot; -- reach a point
      where no more input can be accepted.
      One example is with the input
      &quot;&lt;tt&gt;+ 1 2 3 + + 1 2 4&lt;/tt&gt;&quot;.
      This causes the following diagnostic:
    &lt;/p&gt;&lt;blockquote&gt;&lt;pre&gt;
Last expression successfully parsed was: + 1 2
The parse became exhausted here: &quot; 3 + + 1 2 4&quot;
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;The parser has completed a prefix expression.
      Unlike infix and postfix expressions, once a prefix
      expression has been
      allowed to end
      there is no way to &quot;extend&quot; or &quot;restart&quot; it.
      The parse is &quot;exhausted&quot;.
    &lt;/p&gt;&lt;p&gt;A second example of an exhausted parse
      occurs with the the input
      &quot;&lt;tt&gt;1 + 2 +3  4 + 5 + 6 + 7&lt;/tt&gt;&quot;.
      Here is the diagnostic:
    &lt;/p&gt;&lt;blockquote&gt;&lt;pre&gt;
Last expression successfully parsed was: 1
The parse became exhausted here: &quot; + 2 +3  4 + 5 + 6 + 7&quot;
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;h4&gt;The input is fully accepted, but there is no parse&lt;/h4&gt;&lt;p&gt;
      Finally, it may happen that lexer and parser read and accept
      the entire input, but do not find a valid parse in it.
      For example, if the input is
      &quot;&lt;tt&gt;+++&lt;/tt&gt;&quot;, the diagnostic will be:
    &lt;/p&gt;&lt;blockquote&gt;&lt;pre&gt;
No expression was successfully parsed
No parse was found, after reading the entire input
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;The input was a good start for a prefix expression,
      but no numbers were ever found,
      and our DSL reports that it never recognized any
      prefix expressions.
    &lt;/p&gt;&lt;p&gt;A more complicated case is this input:
      &quot;&lt;tt&gt;++1 2++&lt;/tt&gt;&quot;.
      Here is what our DSL tells us:
    &lt;/p&gt;&lt;blockquote&gt;&lt;pre&gt;
Last expression successfully parsed was: +1 2
No parse was found, after reading the entire input
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;
      Our DSL did find a good expression, and tells us where it was.
      If there is more than one good expression, our DSL tells us
      the most recent.
      With input &quot;&lt;tt&gt;++1 2++3 4++&lt;/tt&gt;&quot;,
      the diagnostic becomes
    &lt;/p&gt;&lt;blockquote&gt;&lt;pre&gt;
Last expression successfully parsed was: +3 4
No parse was found, after reading the entire input
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;In fact, if we thought it would be helpful
      our DSL could show all the expressions found,
      or the last
      &lt;i&gt;N&lt;/i&gt;
      expressions for some
      &lt;i&gt;N&lt;/i&gt;.
      This is a simple language with nothing but expressions
      involving a single operator.
      More interesting languages will have statements and blocks,
      and layers of subexpressions.
      The logic below can be straightforwardly modified to show us
      as much about these as we think will be helpful.
    &lt;/p&gt;&lt;h3&gt;Parsing the DSL&lt;/h3&gt;
    &lt;blockquote&gt;&lt;pre&gt;
sub my_parser {
    my ( $grammar, $string ) = @_;
    my @positions = (0);
    my $recce = Marpa::R2::Recognizer-&amp;gt;new( { grammar =&amp;gt; $grammar } );

    my $self = bless {
        grammar   =&amp;gt; $grammar,
        input     =&amp;gt; \$string,
        recce     =&amp;gt; $recce,
        positions =&amp;gt; \@positions
        },
        'My_Error';

    my $length = length $string;
    pos $string = $positions[-1];

    &lt;big&gt;&lt;b&gt;... &quot;Reading the tokens&quot; goes here ...&lt;/b&gt;&lt;/big&gt;

    my $value_ref = $recce-&amp;gt;value;
    if ( not defined $value_ref ) {
        die $self-&amp;gt;show_last_expression(), &quot;\n&quot;,
            &quot;No parse was found, after reading the entire input\n&quot;;
    }
    return ${$value_ref};
} ## end sub my_parser
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;The above closure takes a grammar and an input string, and either produces a parse
      value,
      or a diagnostic telling us exactly why it could not.
      For truly helpful diagnostics, I find it necessary to be able to quote
      the input exactly.
      The
      &lt;tt&gt;@positions&lt;/tt&gt;
      array will be used to map the locations that the Marpa
      parser uses back to positions in the original input string.
      Marpa location 0 is always before any input symbol, so it is initialized
      to string position 0.
    &lt;/p&gt;
    &lt;p&gt;
      The
      &lt;tt&gt;$self&lt;/tt&gt;
      object is a convenience.
      It collects the information the error handler needs,
      and allows an elegant syntax for the error-handling calls.
    &lt;/p&gt;
    &lt;p&gt;The loop for reading tokens will be described below.
      After it, but before the
      &lt;tt&gt;return&lt;/tt&gt;,
      is our first error check.
      &quot;No parse&quot; errors show up after all the tokens have been read,
      when the
      &lt;tt&gt;$recce-&amp;gt;value()&lt;/tt&gt;
      call returns a Perl
      &lt;tt&gt;undef&lt;/tt&gt;.
      In that case,
      we produce the message we showed above.
      The tricky details are hidden in the
      &lt;tt&gt;show_last_expression()&lt;/tt&gt;
      method,
      which we will come to.
    &lt;/p&gt;&lt;h3&gt;Reading the tokens&lt;/h3&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
TOKEN: while ( pos $string &amp;lt; $length ) {
    next TOKEN if $string =~ m/\G\s+/gcxms;    # skip whitespace
    if ( $recce-&amp;gt;exhausted() ) {
	die $self-&amp;gt;show_last_expression(), &quot;\n&quot;,
	    q{The parse became exhausted here: &quot;},
	    $self-&amp;gt;show_position( $positions[-1] ), qq{&quot;\n},
	    ;
    } ## end if ( $recce-&amp;gt;exhausted() )

    &lt;big&gt;&lt;b&gt;...  &quot;Looping through the lexing table&quot; goes here ...&lt;/b&gt;&lt;/big&gt;

    die 'A problem occurred here: ',
	$self-&amp;gt;show_position( $positions[-1] ), &quot;\n&quot;,
	q{No valid token was found};
} ## end TOKEN: while ( pos $string &amp;lt; $length )
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;This loop implements part of our progressive matching
      within
      &lt;tt&gt;$string&lt;/tt&gt;,
      and contains two of our four error checks.
      The
      &lt;tt&gt;exhausted()&lt;/tt&gt;
      method check if the parse is
      exhausted,
      and again the hard work is done by the
      &lt;tt&gt;show_last_expression()&lt;/tt&gt;
      method.
    &lt;/p&gt;&lt;p&gt;If we get through the lexing table without finding a token,
      we produce an invalid token message
      and report the position using the
      &lt;tt&gt;show_position()&lt;/tt&gt;
      method.
      For invalid tokens, position should be all that
      the user needs to know.
      Position is also reported in the case of an exhausted parse.
      Implementation of the
      &lt;tt&gt;show_position()&lt;/tt&gt;
      method presents
      no difficulties -- the code can be found in the gist.
    &lt;/p&gt;&lt;h3&gt;Looping through the lexing table&lt;/h3&gt;
    &lt;blockquote&gt;&lt;pre&gt;
TOKEN_TYPE: for my $t (@terminals) {
    my ( $token_name, $regex, $long_name ) = @{$t};
    next TOKEN_TYPE if not $string =~ m/\G($regex)/gcxms;
    if ( defined $recce-&amp;gt;read( $token_name, $1 ) ) {
	my $latest_earley_set_ID = $recce-&amp;gt;latest_earley_set();
	$positions[$latest_earley_set_ID] = pos $string;
	next TOKEN;
    }
    die $self-&amp;gt;show_last_expression(), &quot;\n&quot;,
	'A problem occurred here: ',
	$self-&amp;gt;show_position( $positions[-1] ), &quot;\n&quot;,
	qq{Parser rejected token &quot;$long_name&quot;\n};
} ## end TOKEN_TYPE: for my $t (@terminals)
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;
      Our innermost loop is through the lexing table,
      checking each table entry against the input string.
      If a match is found, the Marpa recognizer's
      &lt;tt&gt;read()&lt;/tt&gt;
      method is called.
      This may fail due to our fourth and last type of error:
      a rejected token.
      Again,
      &lt;tt&gt;show_position()&lt;/tt&gt;
      reports position
      and
      &lt;tt&gt;show_last_expression()&lt;/tt&gt;
      does the interesting stuff.
    &lt;/p&gt;&lt;h3&gt;Showing the last expression&lt;/h3&gt;
    &lt;blockquote&gt;&lt;pre&gt;&lt;tt&gt;
sub My_Error::show_last_expression {
    my ($self) = @_;
    my $last_expression =
        $self-&amp;gt;input_slice( $self-&amp;gt;last_completed_range('Expression') );
    return
        defined $last_expression
        ? &quot;Last expression successfully parsed was: $last_expression&quot;
        : 'No expression was successfully parsed';
} ## end sub My_Error::show_last_expression
&lt;/tt&gt;&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;At its top level,
      &lt;tt&gt;show_last_expression()&lt;/tt&gt;
      finds the parse locations of the last completed
      &lt;tt&gt;Expression&lt;/tt&gt;
      symbol,
      using the
      &lt;tt&gt;last_completed_range()&lt;/tt&gt;
      method.
      (In Marpa,
      as in other Earley parsers, a symbol or rule that has been recognized
      from start to finish is said to be &quot;completed&quot;.)
      The parse locations are passed to the
      &lt;tt&gt;input_slice()&lt;/tt&gt;
      method,
      which translates them into the corresponding substring of the input
      string.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
sub My_Error::input_slice {
    my ( $self, $start, $end ) = @_;
    my $positions = $self-&amp;gt;{positions};
    return if not defined $start;
    my $start_position = $positions-&amp;gt;[$start];
    my $length         = $positions-&amp;gt;[$end] - $start_position;
    return substr ${ $self-&amp;gt;{input} }, $start_position, $length;
} ## end sub My_Error::input_slice
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;Finding the last successful parse of a symbol&lt;/h3&gt;
    &lt;p&gt;The
      &lt;tt&gt;last_completed_range()&lt;/tt&gt;
      method does the
      complicated part of the error handling -- finding the last
      successfully recognized (&quot;completed&quot;)
      occurrence of a symbol.
      The
      &lt;tt&gt;last_completed_range()&lt;/tt&gt;
      method does not use
      any internals, but it certainly gets technical
      in its use of the external methods.
      It or something like it
      is a prime candidate to be folded into the Marpa
      interface someday.
    &lt;/p&gt;&lt;p&gt;
      Successful recognitions of a symbol are called,
      again following standard Earley parsing terminology,
      &quot;completions&quot;.
      Completions are recorded by rule,
      so the first thing that must be done is to turn the
      symbol name into a list of those rules which have
      that symbol on their left hand side.
      These are called the
      &lt;tt&gt;@sought_rules&lt;/tt&gt;.
      We also need to initialize the loop by
      recording the last parse location (&quot;latest Earley set&quot;).
      &lt;tt&gt;$earley_set&lt;/tt&gt;
      will be our loop variable.
    &lt;/p&gt;
    &lt;blockquote&gt;&lt;pre&gt;
sub My_Error::last_completed_range {
    my ( $self, $symbol_name ) = @_;
    my $grammar      = $self-&amp;gt;{grammar};
    my $recce        = $self-&amp;gt;{recce};
    my @sought_rules = ();
    for my $rule_id ( $grammar-&amp;gt;rule_ids() ) {
        my ($lhs) = $grammar-&amp;gt;rule($rule_id);
        push @sought_rules, $rule_id if $lhs eq $symbol_name;
    }
    die &quot;Looking for completion of non-existent rule lhs: $symbol_name&quot;
        if not scalar @sought_rules;
    my $latest_earley_set = $recce-&amp;gt;latest_earley_set();
    my $earley_set        = $latest_earley_set;

    &lt;big&gt;&lt;b&gt;... &quot;Traversing the Earley sets&quot; goes here ...&lt;/b&gt;&lt;/big&gt;

    return if $earley_set &amp;lt; 0;
    return ( $first_origin, $earley_set );
} ## end sub My_Error::last_completed_range
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;
      Once we have traversed the Earley sets, we need only return
      the appropriate value.
      If the Earley set number fell below 0, we never found any completions
      of the &quot;sought rules&quot;,
      a circumstance which we report with a bare
      &lt;tt&gt;return&lt;/tt&gt;
      statement.
      Otherwise,
      &lt;tt&gt;$first_origin&lt;/tt&gt;
      and
      &lt;tt&gt;$earley_set&lt;/tt&gt;
      will be set to the first and last parse locations of the completion,
      and we return them.
    &lt;/p&gt;
    &lt;h3&gt;Traversing the Earley sets&lt;/h3&gt;
    &lt;p&gt;This is our final code sample, and the buck stops here.
      Marpa::R2 introduced more detailed user access to the progress reporting
      information, and
      &lt;a href=&quot;https://metacpan.org/module/JKEGL/Marpa-R2-2.023_008/pod/Progress.pod&quot;&gt;
        that interface&lt;/a&gt;
      is used here.
    &lt;/p&gt;
    &lt;p&gt;We traverse the Earley sets in reverse order,
      beginning with the latest and going back, if necessary to Earley set 0.
      For each Earley sets, there are &quot;progress items&quot;, reports of the progress
      as of that Earley set.
      Of these, we are only interested in completions,
      which have a &quot;dot position&quot; of -1.
      (Those interested in a fuller explanation of &quot;dot positions&quot;,
      progress items, and
      progress reports, can look in
      &lt;a href=&quot;https://metacpan.org/module/JKEGL/Marpa-R2-2.023_008/pod/Progress.pod&quot;&gt;
        the documentation for progress reports&lt;/a&gt;.)
      Of the completions, we are interested only in those for one of
      the
      &lt;tt&gt;@sought_rules&lt;/tt&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      For any given set of sought rules, more than one might end at
      an given Earley set.
      Usually we are most interested in the longest of these,
      and this logic assumes that we are only interested in the
      longest completion.
      We check if the start of the completion (its &quot;origin&quot;) is prior to
      our current match, and if so its becomes our new
      &lt;tt&gt;$first_origin&lt;/tt&gt;.
    &lt;/p&gt;
    &lt;p&gt;&lt;tt&gt;$first_origin&lt;/tt&gt;
      was initialized to an non-existent Earley set,
      higher in number than any actual one.
      Once out of the loop through the progress items, we check if
      &lt;tt&gt;$first_origin&lt;/tt&gt;
      is still at its initialized value.
      If so, we need to iterate backward one more Earley set.
      If not, we are done, and
      &lt;tt&gt;$first_origin&lt;/tt&gt;
      and
      &lt;tt&gt;$earley_set&lt;/tt&gt;
      contain the information that we were looking for -- the start and end
      locations of the most recent longest completion of one of the
      &lt;tt&gt;@sought_rules&lt;/tt&gt;.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
my $first_origin = $latest_earley_set + 1;
EARLEY_SET: while ( $earley_set &amp;gt;= 0 ) {
    my $report_items = $recce-&amp;gt;progress($earley_set);
    ITEM: for my $report_item ( @{$report_items} ) {
	my ( $rule_id, $dot_position, $origin ) = @{$report_item};
	next ITEM if $dot_position != -1;
	next ITEM if not scalar grep { $_ == $rule_id } @sought_rules;
	next ITEM if $origin &amp;gt;= $first_origin;
	$first_origin = $origin;
    } ## end ITEM: for my $report_item ( @{$report_items} )
    last EARLEY_SET if $first_origin &amp;lt;= $latest_earley_set;
    $earley_set--;
} ## end EARLEY_SET: while ( $earley_set &amp;gt;= 0 )
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;Comments&lt;/h3&gt;
    &lt;p&gt;
      Comments on this post can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>Configuring the Ruby Slippers for HTML</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/config_html3.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      perl ./marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      This post is part of
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html#PARSE_HTML&quot;&gt;
        a series&lt;/a&gt;
      describing Marpa::R2::HTML,
      a configurable HTML parser.
      The last two posts described how to change
      the context and contents of the HTML
      elements, both new and existing.
      This post describes how to configure
      optional start tags: how to change 
      which start tags
      are optional,
      and how to specify the circumstances
      in which they will be supplied.
    &lt;/p&gt;
    &lt;h3&gt;How the parser works&lt;/h3&gt;
    &lt;p&gt;
      In the first posts in this series I went into some detail describing
      my Marpa-based approach to HTML parsing.
      Briefly, it combines a parse engine using a &quot;wishful thinking&quot; grammar
      with a Ruby Slippers lexer.
      The &quot;wishful thinking&quot; grammar expects all elements,
      without exception,
      to have both start and end tags.
      This overstrict grammar demands tags even in cases
      where the
      &lt;a href=&quot;http://www.w3.org/TR/1999/PR-html40-19990824/sgml/dtd.html#inline&quot;&gt;
        HTML 4.01 Strict DTD&lt;/a&gt;
      mandates that they be treated as optional.
    &lt;/p&gt;
    &lt;p&gt;
      The overstrict grammar is liberalized by the Ruby Slippers.
      Marpa has an unusual property among parsers -- it is fully
      informed about the state of the parse at all points,
      and can conveniently and efficiently share that information
      with the application.
      In Marpa::R2::HTML, when the parse engine, with its
      overstrict grammar, grinds to a halt for lack
      of a tag that does not exist
      in the physical input,
      the lexer can ask the parse engine which tag it is looking for.
      It can then dummy one up, feed it to the parse engine,
      and start things back up.
      It's as simple as that.
    &lt;/p&gt;
    &lt;p&gt;
      For HTML end tags,
      the Ruby Slippers work stunningly well.
      Only one end tag will be expected at any point.
      In cases where a stack of elements must be properly terminated,
      the parse engine will request the end tags, one at a time,
      in proper order.
      The grammar can simplify life for itself by demanding a perfect
      world, and on the lexer's side, things are no harder -- it just
      has to do what it is told.
    &lt;/p&gt;
    &lt;p&gt;
      For the very few start tags
      that are optional according to the Strict HTML 4.01 DTD,
      things are just as simple -- they occur in places where only one
      at a time will be demanded, and the Ruby Slippers lexer need
      only do what it is told to.
      However, if you want to further liberalize HTML, there will be
      cases where there is a choice between start tags;
      or between
      starting one element and ending another.
    &lt;/p&gt;
    &lt;h3&gt;Configuring the Ruby Slippers&lt;/h3&gt;
    &lt;p&gt;
      In the last post,
      I showed how to configure Marpa::R2::HTML to allow or disallow
      text directly in the
      &lt;tt&gt;&amp;lt;body&amp;gt;&lt;/tt&gt;
      element.
      If Marpa::R2::HTML
      was configured to disallow 
      text directly in the
      &lt;tt&gt;&amp;lt;body&amp;gt;&lt;/tt&gt;
      element,
      and it encountered such text,
      Marpa::R2::HTML would start a block.
      The block was started
      by supplying a
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
      start tag in front of the text.
      In other words, Marpa::R2::HTML treated
      the
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
      start tag as optional.
    &lt;/p&gt;
      Let me give an example.
      Suppose the HTML document consisted of the string
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;Hello, world&lt;/tt&gt;&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      and that, using the default configuration,
      we ran &lt;tt&gt;html_fmt&lt;/tt&gt; as  follows:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;echo 'Hello, world' |
/Users/jeffreykegler/perl5/bin/marpa_r2_html_fmt --no-added-tag-comment&lt;/tt&gt;&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      This would be our result:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;p&amp;gt;
      Hello, world
    &amp;lt;/p&amp;gt;&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/tt&gt;&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      This was produced using the default configuration,
      which resides in
      &lt;a href=&quot;http://api.metacpan.org/source/JKEGL/Marpa-R2-2.022000/g/config/default.txt&quot;&gt;
        the
        &lt;tt&gt;g/config/default.txt&lt;/tt&gt;
        file&lt;/a&gt;.
      (All the examples is this post use version 2.022000 of Marpa::R2.)
    &lt;/p&gt;
    &lt;h3&gt;First, the results&lt;/h3&gt;
    &lt;p&gt;
      Let's change the behavior of 
      Marpa::R2::HTML so that,
      instead of starting a new
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
      element,
      it will reject the text as cruft.
      We create a new configuration,
      putting it into a file named
      &lt;tt&gt;g/config/reject_text.txt&lt;/tt&gt;.
    &lt;p&gt;
      Creating the
      configuration will not be difficult,
      but it will perhaps be easiest to understand
      if we first see the result
      that we are aiming at.
      Again we run &lt;tt&gt;html_fmt&lt;/tt&gt;:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;echo 'Hello, world' |
/Users/jeffreykegler/perl5/bin/marpa_r2_html_fmt \
  --compile reject_pcdata.txt  --no-added-tag-comment&lt;/tt&gt;&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      And this is our new result:
    &lt;/p&gt;&lt;blockquote&gt;&lt;pre&gt;&lt;tt&gt;&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;!-- html_fmt: Next line is cruft --&amp;gt;
    Hello, world
&amp;lt;/body&amp;gt;
&lt;/tt&gt;&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;Note that in this second example, there are no tags
      for the
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
      element,
      and that the text is now labeled as &quot;cruft&quot;, as desired.
    &lt;/p&gt;
    &lt;h3&gt;How it was done&lt;/h3&gt;
    &lt;p&gt;
      How would we change the default configuration file to refuse to start a new
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
      element in front of text?
      The three relevant lines are:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;@block_rubies  = &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;body&amp;gt;
@inline_rubies = @block_rubies &amp;lt;tbody&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td&amp;gt; &amp;lt;p&amp;gt;
PCDATA -&amp;gt; @inline_rubies
&lt;/tt&gt;&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;The symbols with an &quot;&lt;tt&gt;@&lt;/tt&gt;&quot; sigil are lists,
      which the configuration file uses as a convenient shorthand for groups
      of symbols which occur frequently.
      For convenience in this discussion,
      let's expand them, so that relevant extract looks like this
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;PCDATA -&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;tbody&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td&amp;gt; &amp;lt;p&amp;gt;&lt;/tt&gt;&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      In the configuration file,
      &lt;tt&gt;PCDATA&lt;/tt&gt;
      can be thought of as non-whitespace text,
      occurring in a context which is parsed
      for markup and entities.
      (Precisely, it is whatever
      HTML::Parser returns as text that is not whitespace
      and does not turn on the
      &lt;tt&gt;is_cdata&lt;/tt&gt;
      flag.)
      What this line says is that, whenever
      a &lt;tt&gt;PCDATA&lt;/tt&gt; token
      is rejected,
      Marpa::R2::HTML should try to fix the problem as follows:
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;1. If possible, start an
        &lt;tt&gt;&amp;lt;html&amp;gt;&lt;/tt&gt;
        element.
      &lt;/li&gt;
      &lt;li&gt;2. Otherwise, if possible, start a
        &lt;tt&gt;&amp;lt;head&amp;gt;&lt;/tt&gt;
        element.
      &lt;/li&gt;
      &lt;li&gt;3. Otherwise, if possible, start a
        &lt;tt&gt;&amp;lt;body&amp;gt;&lt;/tt&gt;
        element.
      &lt;/li&gt;
      &lt;li&gt;4. Otherwise, if possible, start a
        &lt;tt&gt;&amp;lt;tbody&amp;gt;&lt;/tt&gt;
        element.
      &lt;/li&gt;
      &lt;li&gt;5. Otherwise, if possible, start a
        &lt;tt&gt;&amp;lt;tr&amp;gt;&lt;/tt&gt;
        element.
      &lt;/li&gt;
      &lt;li&gt;6. Otherwise, if possible, start a
        &lt;tt&gt;&amp;lt;td&amp;gt;&lt;/tt&gt;
        element.
      &lt;/li&gt;
      &lt;li&gt;7. Otherwise, if possible, start a
        &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
        element.
      &lt;/li&gt;
      &lt;li&gt;8. Otherwise, if it is possible to end
        a non-structural or a 
        &lt;tt&gt;&amp;lt;head&amp;gt;&lt;/tt&gt;
	element at this point, do so.
	(At any point, it will be possible to end
	at most one element.)
      &lt;/li&gt;
      &lt;li&gt;9. Finally, if nothing else works, mark the &quot;PCDATA&quot; as cruft.
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;p&gt;
      Of these alternatives, the first three allow Marpa::R2::HTML to supply missing
      structural start tags, as required by the standards.
      Alternatives 4, 5 and 6 allow Marpa::R2::HTML to continue building a table
      if table-building is in progress.
      (But note that the line does not allow Marpa::R2::HTML
      to deal with rejected
      PCDATA by starting a new table.)
      Alternative 7 allows Marpa::R2::HTML to start a new
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
      element if PCDATA is rejected.
      &lt;p&gt;
      Alternatives 8 and 9 are implicit.
      By default, after all the explicit Ruby Slippers
      alternatives have been tried,
      Marpa::R2::HTML will create a Ruby Slippers tags
      for any end tag that is allowed,
      with two exceptions:
      Marpa::R2::HTML will not create
      &lt;tt&gt;&amp;lt;/body&amp;gt;&lt;/tt&gt; and
      &lt;tt&gt;&amp;lt;/html&amp;gt;&lt;/tt&gt; end tags except at the end of file.
      And Marpa::R2::HTML always reserves the possibility of,
      as a last resort,
      labeling a token as &quot;cruft&quot; and moving on.
    &lt;/p&gt;
    &lt;p&gt;
      Once you understand how the Ruby Slippers configuration lines work,
      the fix in this case becomes obvious:
      In the expanded line,
      elminate the
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
      as one of the alternatives considered for the Ruby Slippers.
      In terms of the expanded line,
      this means changing it to
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;PCDATA -&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;tbody&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td&amp;gt;&lt;/tt&gt;&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      In terms of the original set of lines,
      this means changing the one for the
      &lt;tt&gt;@inline_rubies&lt;/tt&gt;
      list:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;@inline_rubies = @block_rubies &amp;lt;tbody&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td&amp;gt;&lt;/tt&gt;&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      In the Ruby Slippers configuration lines of
      the default configuration file,
      the &lt;tt&gt;@inline_rubies&lt;/tt&gt; list is the only place that
      the
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt; tag is mentioned.
      So changing
      &lt;tt&gt;@inline_rubies&lt;/tt&gt;
      has effect
      of eliminating
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
      as an optional start tag.
      Only &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt; tags actually in the physical
      input will be recognized.
      This is what was actually done
      in
      &lt;a href=&quot;https://gist.github.com/3925571&quot;&gt;
        &lt;tt&gt;g/config/reject_text.txt&lt;/tt&gt;,
        the configuration file used in our example&lt;/a&gt;.
    &lt;/p&gt;
    &lt;h3&gt;Code and comments&lt;/h3&gt;
    &lt;p&gt;
      Comments on this post can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>A configurable HTML parser, part 2</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/config_html2.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/config_html.html&quot;&gt;
        My last post&lt;/a&gt;
      introduced Marpa::R2::HTML,
      a configurable HTML parser.
      By editing
      &lt;a href=&quot;https://gist.github.com/3901637&quot;&gt;
        a configuration file&lt;/a&gt;,
      the user can change
      the variant of HTML
      being parsed.
      The changes allowed are very wide ranging.
      The previous post started with simple changes --
      the ability to specify the contents of new tags,
      and the context in which they can appear.
    &lt;/p&gt;
    &lt;p&gt;
      In this post the changes get more aggressive.
      I change the contents of an existing HTML element --
      and not just any element, but
      one of the HTML's three &quot;structural&quot; elements.
      Marpa::R2::HTML allows the configuration file to change
      the contents of all pre-existing
      elements, with the exception of the highest level of the three
      structural elements:
      the
      &lt;tt&gt;&amp;lt;html&amp;gt;&lt;/tt&gt;
      element itself.
    &lt;/p&gt;
    &lt;h3&gt;Can text appear directly in an HTML body?&lt;/h3&gt;
    &lt;p&gt;
      This post will discuss changing the contents of the
      &lt;tt&gt;&amp;lt;body&amp;gt;&lt;/tt&gt;
      element.
      Fundamental to the HTML document as this element is,
      the definition of its contents has been very much in play.
    &lt;/p&gt;
    &lt;p&gt;
      Let's start with the question posed in the title of this section:
      Can text appear directly in an HTML
      &lt;tt&gt;
        &amp;lt;body&amp;gt;&lt;/tt&gt;
      element?
      That is, must text inside an HTML
      &lt;tt&gt;
        &amp;lt;body&amp;gt;&lt;/tt&gt;
      be part of one of its child elements,
      or can it be directly part of the contents
      of the
      &lt;tt&gt;
        &amp;lt;body&amp;gt;&lt;/tt&gt;
      element?
    &lt;/p&gt;&lt;p&gt;
      If you want an
      answer strictly according to the standards,
      then you get your choice in the matter.
      According to the
      &lt;a href=&quot;http://www.w3.org/TR/1999/PR-html40-19990824/sgml/dtd.html#inline&quot;&gt;
        HTML 4.01 Strict DTD&lt;/a&gt;,
      the
      &lt;tt&gt;&amp;lt;body&amp;gt;&lt;/tt&gt;
      contains a &quot;block flow&quot;,
      which means that
      the answer is &quot;No, text must be in the contents of a child element&quot;.
      Implementations of HTML were encouraged to be liberal, however,
      and in practice a lot of the HTML &quot;out there&quot;
      has text directly
      in
      &lt;tt&gt;&amp;lt;body&amp;gt;&lt;/tt&gt;
      elements.
      Users expect their browsers to render these pages
      in the way that the writer intended them to look.
    &lt;/p&gt;
    &lt;p&gt;
      Recognizing existing practice,
      HTML 5 changed to require conforming implementations to
      allow text to be interspersed with the block flow,
      in what I call a &quot;mixed flow&quot;.
      A mixed flow can directly contain blocks and text,
      as well as inline elements.
      (The inline vs. block element distinction is basic to HTML parsing.
      See my earlier post or
      &lt;a href=&quot;http://en.wikipedia.org/wiki/HTML_element&quot;&gt;
        the well-organized Wikipedia page on HTML elements&lt;/a&gt;.)
    &lt;/p&gt;
    &lt;h3&gt;Block or mixed flow?&lt;/h3&gt;
    &lt;p&gt;
      When parsing HTML, do you want to the treat contents of the body
      as a block flow or a mixed flow?
      Here are some of the factors.
    &lt;/p&gt;&lt;ul&gt;
      &lt;li&gt;
        Common practice requires accepting a mixed flow.
      &lt;/li&gt;&lt;li&gt;
        Cautious practice suggests writing a block flow.
      &lt;/li&gt;&lt;li&gt;
        HTML 4.01 requires block, but suggests being liberal.
      &lt;/li&gt;&lt;li&gt;
        HTML 5 requires that a mixed flow be accepted.
      &lt;/li&gt;&lt;li&gt;
        But HTML 5 also requires that the mixed flow be displayed as if it was written
        in blocks and
        suggests that explicit blocking be used to eliminate
        ambiguities.
      &lt;/li&gt;&lt;/ul&gt;
    &lt;h3&gt;Examples&lt;/h3&gt;
    &lt;h4&gt;Body contains block flow&lt;/h4&gt;
    &lt;p&gt;
      In this first example,
      the
      &lt;tt&gt;&amp;lt;body&amp;gt;&lt;/tt&gt;
      contains a block flow.
      This is what is specified in
      &lt;a href=&quot;https://gist.github.com/3901637&quot;&gt;
        the default configuration file&lt;/a&gt;.
      Here is the pertinent line:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;
&amp;lt;body&amp;gt; is *block
&lt;/tt&gt;&lt;/pre&gt;&lt;/blockquote&gt;&lt;p&gt;
      This line says
      that the
      &lt;tt&gt;
        &amp;lt;body&amp;gt;&lt;/tt&gt;
      element contains a block flow (&lt;tt&gt;*block&lt;/tt&gt;).
      Here the star is a sigil which suggests the repetition operator
      of DTD's and regular expressions.
      (Readers of my last post will notice I've changed the configuration
      file syntax and will,
      I hope,
      find the new format an improvement.)
    &lt;/p&gt;&lt;p&gt;
      For the examples in this post,
      the HTML will be
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;
I cannot wait for a start tag&amp;lt;p&amp;gt;I can
&lt;/tt&gt;&lt;/pre&gt;&lt;/blockquote&gt;&lt;p&gt;
      We run this through the
      &lt;tt&gt;marpa_r2_html_fmt --no-added-tag-comment&lt;/tt&gt;.
      Here is the output:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;p&amp;gt;
      I cannot wait for a start tag&amp;lt;/p&amp;gt;&amp;lt;p&gt;
      I can&amp;lt;/p&amp;gt;&amp;lt;/body&gt;
&amp;lt;/html&amp;gt;
&lt;/tt&gt;&lt;/pre&gt;&lt;/blockquote&gt;&lt;p&gt;
      The first thing the parser encounters is text,
      which in this example is not allowed
      to occur directly in the body.
      As part of being a highly liberal HTML parser,
      however, Marpa::R2::HTML will supply a start tag
      in these situations.
      (This behavior, by the way, is also configurable --
      a change to the configuration file can
      tell Marpa::R2::HTML not to do this.)
      With its two
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
      start tags,
      one of them conjured up by the Ruby Slippers,
      Marpa::R2::HTML breezes through its input.
    &lt;/p&gt;
    &lt;h4&gt;Body contains mixed flow&lt;/h4&gt;
    &lt;p&gt;
      In the second example, we liberalize the contents of
      the
      &lt;tt&gt;&amp;lt;body&amp;gt;&lt;/tt&gt;
      to allow a mixed flow:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;
&amp;lt;body&amp;gt; is *mixed
&lt;/tt&gt;&lt;/pre&gt;&lt;/blockquote&gt;&lt;p&gt;
      Here is the result:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;&lt;tt&gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    I cannot wait for a start tag&amp;lt;p&amp;gt;
      I can&amp;lt;/p&amp;gt;&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/tt&gt;&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;
      In a mixed flow, no
      second
      &lt;tt&gt;&amp;lt;p&amp;gt;&lt;/tt&gt;
      start tag
      is needed, and none is created.
      Its matching end tag
      (&lt;tt&gt;&amp;lt;/p&amp;gt;&lt;/tt&gt;) also does not
      have to be created.
      Otherwise, all is as before.
    &lt;/p&gt;
    &lt;h3&gt;What I decided&lt;/h3&gt;
    &lt;p&gt;
      Before I made my HTML parser configurable,
      I was forced to decide the issue of
      &lt;tt&gt;&amp;lt;body&amp;gt;&lt;/tt&gt;
      contents one way or the other.
      My first
      implementation of the
      &lt;tt&gt;html_fmt&lt;/tt&gt;
      utility was based on Marpa::XS
      and
      its grammar specified a mixed flow.
    &lt;/p&gt;&lt;p&gt;
      When I started a new version
      of the utility
      based on Marpa::R2,
      I reopened the issue.
      I decided that a stricter grammar produced a more precise parse,
      and that it was best to leave it up
      to the Ruby Slippers to &quot;loosen things up&quot;
      when the grammar was too strict.
      This was close, I hoped, to the best of both worlds,
      So I changed the grammar to specify a block
      flow for the contents of
      &lt;tt&gt;&amp;lt;body&amp;gt;&lt;/tt&gt;
      element.
      This second choice -- strict block-flow-body grammar and liberal Ruby Slippers --
      remains the default in the configurable version.
    &lt;/p&gt;
    &lt;p&gt;
      In current developer's releases of Marpa::R2,
      and in its next indexed release,
      both the grammar and the Ruby Slippers are configurable.
      The true best of both worlds happens when
      the user gets to decide.
    &lt;/p&gt;
    &lt;h3&gt;Code and comments&lt;/h3&gt;
    &lt;p&gt;
      The examples here were run using Marpa::R2 release 2.021_010.
      They are part of its test suite and can be found in the
      &lt;tt&gt;html/t/cfg_fmt.t&lt;/tt&gt;
      file.
    &lt;/p&gt;
    &lt;p&gt;
      The configurable Marpa::R2::HTML does considerably more than
      can be comfortably described in a single post.
      This post is the second of a series.
      Comments on this post can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;</description>
  </item>
  </channel>
</rss>
