<?xml version="1.0"?>
<!-- name="generator" content="blosxom/2.0" -->
<!DOCTYPE rss PUBLIC "-//Netscape Communications//DTD RSS 0.91//EN" "http://my.netscape.com/publish/formats/rss-0.91.dtd">

<rss version="0.91">
  <channel>
    <title>Ocean of Awareness   </title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog</link>
    <description>Ocean of Awareness.</description>
    <language>en</language>

  <item>
    <title>Significant whitespace?  Or semicolons?</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2014/02/semantic_ws.html</link>
    <description>&lt;html&gt;
  &lt;head&gt;
  &lt;/head&gt;
  &lt;body&gt;&lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      Should statements have explicit terminators, like Perl and C's semicolon?
      Or should they avoid the clutter, and separate statements by giving whitespace
      syntactic signifance and a real effect on
      the semantics?
      Actually you don't have to go either way,
      and you can avoid both sets of problems.
    &lt;/p&gt;
    &lt;p&gt;
      As an example, let's look at some BNF-ish DSL.
      It defines a small calculator.
      At first glance, it looks as if this language has taken the
      significant-whitespace route -- there certainly are no explicit statement
      terminators.
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
:default ::= action =&amp;gt; ::first
:start ::= Expression
Expression ::= Term
Term ::=
      Factor
    | Term '+' Term action =&amp;gt; do_add
Factor ::=
      Number
    | Factor '*' Factor action =&amp;gt; do_multiply
Number ~ digits
digits ~ [\d]+
:discard ~ whitespace
whitespace ~ [\s]+
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;The rule is that there isn't one&lt;/h3&gt;
    &lt;p&gt;
      If you use this DSL, and try natural rearrangements of the whitespace, you'll they
      just work.
      You might become curious about what exactly what the rules for newlines are,
      but if you look at
      &lt;a href=&quot;https://metacpan.org/pod/distribution/Marpa-R2/pod/Scanless/DSL.pod&quot;&gt;
      the documentation&lt;/a&gt;,
      you won't find any.
      That's because there aren't any.
    &lt;/p&gt;
    &lt;p&gt;
      You can see this for yourself.
      GNU's fmt command will thoroughly mess it up the line structure:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
:default ::= action =&amp;gt; ::first :start ::= Expression Expression ::= Term
Term ::= Factor | Term '+' Term action =&amp;gt; do_add Factor ::= Number |
Factor '*' Factor action =&amp;gt; do_multiply Number ~ digits digits ~
[\d]+ :discard ~ whitespace whitespace ~ [\s]+
&lt;/pre&gt;
&lt;/blockquote&gt;
      &lt;p&gt;But
      &lt;a href=&quot;https://gist.github.com/jeffreykegler/9220695&quot;&gt;
      the script will still run just fine&lt;/a&gt;.
      &lt;/p&gt;
    &lt;h3&gt;How does it work?&lt;/h3&gt;
    &lt;p&gt;How does it work?
      Actually, pose this question first:
      Can you tell where the statements end?
      If you not used to reading BNF, you might have trouble with this
      particular example but,
      for a language that you know, the answer is simple:
      Yes, of course you can.
      So really the question is,
      why do we expect the parser to be so stupid that it cannot?
    &lt;/p&gt;
    &lt;p&gt;
      The only trick is that this is done without trickery.
      Marpa's DSL is
      &lt;a href=&quot;https://metacpan.org/source/JKEGL/Marpa-R2-2.080000/lib/Marpa/R2/meta/metag.bnf&quot;&gt;
      written in itself&lt;/a&gt;,
      and Marpa's self-grammar describes exactly what a statement is
      and what it is not.
      The Marpa parser is powerful enough to simply take this self-describing DSL
      and act on it, finding where statements begin and end,
      much as a human reader
      would be able to in the same circumstance.
    &lt;/p&gt;
    &lt;h3&gt;To learn more&lt;/h3&gt;
    &lt;p&gt;
      This example was produced with the Marpa parser.
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2
        is available on CPAN&lt;/a&gt;.
	The code for this example is based on that in
	the synopsis for its top-level document,
	but it is isolated conveniently in
	&lt;a href=&quot;https://gist.github.com/jeffreykegler/9220695&quot;&gt;
	a Github gist&lt;/a&gt;.
      &lt;p&gt;
      &lt;/p&gt;
      A list of my Marpa tutorials can be found
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        here&lt;/a&gt;.
      There are
      new tutorials by
      &lt;a href=&quot;http://marpa-guide.github.io/chapter1.html&quot;&gt;Peter Stuifzand&lt;/a&gt;
      and
      &lt;a href=&quot;http://longanswers.blogspot.de/2013/06/transforming-syntax.html&quot;&gt;amon&lt;/a&gt;.
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
        The Ocean of Awareness blog&lt;/a&gt;
      focuses on Marpa,
      and it has
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html&quot;&gt;an annotated guide&lt;/a&gt;.
      Marpa also has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page&lt;/a&gt;.
      For questions, support and discussion, there is
      &lt;a href=&quot;http://groups.google.com/group/marpa-parser&quot;&gt;
        the &quot;marpa parser&quot;
        Google Group.&lt;/a&gt;
      Comments on this post can be made there.
    &lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;</description>
  </item>
  <item>
    <title>A Marpa-powered C parser</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/08/c2ast.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      Jean-Damien Durand has just released
      &lt;a href=&quot;https://metacpan.org/release/MarpaX-Languages-C-AST&quot;&gt;
        MarpaX::Languages::C::AST&lt;/a&gt;,
      which parses C language into an abstract syntax tree (AST).
      MarpaX::Languages::C::AST has been tested against
      Perl's C source code, as well as Marpa's own C source.
    &lt;/p&gt;
    &lt;p&gt;
      Because it is Marpa-powered,
      MarpaX::Languages::C::AST works differently from other C parsers.
      In the past,
      C parsers have been syntax-driven -- parsing was based on a BNF description
      of the C grammar.
      More recently, C parsers have used hand-written
      recursive descent -- they have been procedurally-driven.
    &lt;/p&gt;
    &lt;p&gt;
      MarpaX::Languages::C::AST uses both approaches.
      Marpa has the advantage that it makes full knowledge of the state of the parse
      available to the programmer,
      so that procedural logic and syntax-driven parsing can reinforce each other.
      The result is a combined lexer/parser
      which is very compact and easy to understand.
      Among the potential applications:
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Customized &quot;lints&quot;.
        You can write programs to enforce C language standards
        and restrictions specific to an individual, a company or a project.
      &lt;/li&gt;
      &lt;li&gt;C interpreters.
        By taking the AST and adding your own back end, you can create a special-purpose C interpreter
        or a special-purpose compiler.
      &lt;/li&gt;
      &lt;li&gt;C variants.
        Because the code for the parser is compact and easy to modify,
        it lends itself to language extension and experimentation.
        For example,
        you could reasonably implement compilers
        to try out the proposals submitted to
        a standards committee.
      &lt;/li&gt;
      &lt;li&gt;C supersets.
        Would you like to see some of the syntax from a favorite language available in C?
        Here's your chance.
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;h3&gt;The implementation&lt;/h3&gt;
    &lt;p&gt;A few of Jean-Damien's implementation choices are worth noting.
      A C parser can take one of two strategies: approximate or precise.
      A compiler has, of course, to be precise.
      Tools, such as cross-referencers, often decide to be approximate, or sloppy.
      Sloppiness is easier to implement and has other advantages:
      A sloppy tool can tolerate missing C flags: what the C flags should be
      can be one of the things it guesses at.
    &lt;/p&gt;
    &lt;p&gt;Of the two strategies, Jean-Damien decided to go with &quot;precise&quot;.
      MarpaX::Languages::C::AST follows the C11 standard,
      with either GCC or Microsoft extensions.
      This has the advantage that
      MarpaX::Languages::C::AST could be used as the front end of a compiler.
    &lt;/p&gt;
    &lt;p&gt;
      Because
      MarpaX::Languages::C::AST purpose is to take things as far as an AST,
      and let the user take over,
      it does not implement those constraints usually implemented in post-processing.
      One example of a post-syntactic constraint is the one that bans
      &quot;&lt;tt&gt;case&lt;/tt&gt;&quot; labels outside of switch statements.
      Perhaps a future version can include a default &quot;first phase&quot; post-processor to enforce
      the constraints from the standards.
      As currently implemented, the user can check for and enforce these constraints in any
      way he likes.
      This makes it easier for extensions and customizations,
      which I think of as the major purpose of MarpaX::Languages::C::AST.
    &lt;/p&gt;
    &lt;h3&gt;The parsing strategy&lt;/h3&gt;
    &lt;p&gt;
      Those familar with the C parsing and its special issues may be interested in
      Jean-Damien's approach to them.
      MarpaX::Languages::C::AST is, with a few exceptions, syntax-driven -- the parser works
      from Marpa's SLIF, an extended BNF variant.
      The SLIF-driven logic is sufficient to deal with the
      &lt;a href=&quot;http://en.wikipedia.org/wiki/Dangling_else&quot;&gt;if-then-else issue&lt;/a&gt;.
      Marpa handles right recursion in linear time,
      so that the if-then-else issue could have been dealt with by rewriting the relevant rules.
      But Jean-Damien wanted to have his BNF follow closely the grammar in the standards,
      and he decided to use Marpa's rule ranking facility instead.
    &lt;/p&gt;
    &lt;p&gt;More complicated is the ambiguity in C between variable names and types,
      which actually takes C beyond BNF and context-free grammars into context-sensitive
      territory.
      Most C parsers deal with this using
      &lt;a href=&quot;http://en.wikipedia.org/wiki/The_lexer_hack&quot;&gt;lexer
        or post-processing hacks&lt;/a&gt;.
      Marpa allows the parser to do this more elegantly.
      Marpa knows the parsing context at all times and can comnunicate this to a user's
      customized code.
      Marpa also has the ability to use the parsing context to
      decide when to
      switch control from the syntax-driven logic to
      a user's customized procedural logic,
      and for the syntax-driven logic to take control back
      when the procedural logic wants to give it back.
      This allows the variable-name-versus-type ambiguity to be handled by specifically targeted code
      which knows the full context of the decisions it needs to make.
      This code can be written more directly, simply and clearly
      than was possible with previous parsing methods.
    &lt;/p&gt;
    &lt;p&gt;
    &lt;/p&gt;&lt;h3&gt;Compilers?&lt;/h3&gt;
    &lt;p&gt;
      Above I mentioned special-purpose compilers.
      What about production compilers?
      MarpaX::Languages::C::AST's upper layers are in Perl,
      so the speed, while acceptable for special-purpose tools,
      will probably not be adequate for production.
      Perhaps a future Marpa-powered C parser will rewrite those
      upper layers in C, and make the race more interesting.
    &lt;/p&gt;
    &lt;h3&gt;To learn more&lt;/h3&gt;
    &lt;p&gt;
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2
        is available on CPAN&lt;/a&gt;.
      A list of my Marpa tutorials can be found
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        here&lt;/a&gt;.
      There are
      new tutorials by
      &lt;a href=&quot;http://marpa-guide.github.io/chapter1.html&quot;&gt;Peter Stuifzand&lt;/a&gt;
      and
      &lt;a href=&quot;http://longanswers.blogspot.de/2013/06/transforming-syntax.html&quot;&gt;amon&lt;/a&gt;.
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
        The Ocean of Awareness blog&lt;/a&gt;
      focuses on Marpa,
      and it has
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html&quot;&gt;an annotated guide&lt;/a&gt;.
      Marpa also has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page&lt;/a&gt;.
      For questions, support and discussion, there is
      &lt;a href=&quot;http://groups.google.com/group/marpa-parser&quot;&gt;
        the &quot;marpa parser&quot;
        Google Group.&lt;/a&gt;
      Comments on this post can be made there.
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>Parsing Ada Lovelace</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/07/lovelace.html</link>
    <description>  &lt;h3&gt;The application&lt;/h3&gt;&lt;p&gt;&lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      Abstract Syntax Forests (ASF's) are my most recent project.
      I am adding ASF's to my Marpa parser.
      &lt;a href=&quot;http://jeffreykegler.github.io/Marpa-web-site/&quot;&gt;
      Marpa&lt;/a&gt;
      has long supported ambiguous parsing,
      and allowed users to iterate through,
      and examine,
      all the parses of an ambiguous parse.
      This was enough for most applications.
    &lt;/p&gt;
    &lt;p&gt;
      Even applications which avoid ambiguity benefit from better ways to detect
      and locate it.
      And there are applications that require the ability to select among
      and 
      manipulate very large sets of ambiguous parses.
      Prominent among these is Natural Language Processing (NLP).
      This post will introduce an experiment.
    Marpa in fact seems to have some potential for NLP.
    &lt;/p&gt;
    &lt;p&gt;Writing an efficient ASF in not a simple matter.
      The naive implementation is to generate complete set
      of fully expanded abstract
      syntax trees (AST's).
      This approach consumes resources that can become
      exponential in the size of the input.
      Translation: the naive implementation quickly becomes unuseably slow.
      Marpa optimizes
      by aggressively identifying identical subtrees 
      of the AST's.
      Especially in highly ambiguous parses,
      many subtrees are identical,
      and this optimization is often a big win.
    &lt;/p&gt;
    &lt;h3&gt;Ada Lovelace&lt;/h3&gt;
    &lt;p&gt;
      My primary NLP example at this point
      is a quote from Ada Lovelace.
      It is a long sentence, possibly the longest, from her
      &lt;a href=&quot;http://www.fourmilab.ch/babbage/sketch.html&quot;&gt;
      Notes&lt;/a&gt; -- 158 words.
      A disadvantage of this example is that it is not typical 
      of normal NLP.
      By modern standards it is an unusually long and complex sentence.
      An advantage of it,
      and my reason for the choice,
      is that it stresses the parser.
    &lt;/p&gt;
    &lt;p&gt;
      The &quot;Note A&quot; from which this sentence is taken is
      one of Ada's notes on a translation of a paper
      on the work of her mentor and colleague, Charles Babbage.
      Ada's &quot;Notes&quot; are longer than the original paper,
      and far more important.
      In these &quot;Notes&quot; Ada makes
      the first distinction
      between a computer and a calculator,
      and between software and hardware.
      In their collaboration,
      Babbage did all of the hardware design,
      and he wrote most of the actual programs in her paper.
      But these two revolutionary ideas,
      and their elaboration, are Ada's.
    &lt;/p&gt;
    &lt;p&gt;
      Why would Babbage
      ignore obvious implications of his
      own invention?
      The answer is that,
      while these implications are obvious to us,
      they simply did not fit into the 1843 view of the world.
      In those days,
      algebra was leading-edge math.
      The ability to manipulate equations was considered
      an extremely advanced form of reason.
      For Babbage and his contemporaries, that sort of ability to reason
      certainly suggested the ability to distinguish between good and evil,
      and this in turn suggested possession of a soul.
      Ada's &quot;Notes&quot; were written 20 years after Mary Shelly,
      while visiting Ada's father in Switzerland,
      wrote
      the novel Frankenstein.
      For Ada's contemporaries,
      announcing that you planned to create a
      machine that composed music, or did
      advanced mathematical reasoning,
      was not very different
      from announcing that you planned
      to assemble a human being in your lab.
    &lt;/p&gt;
    &lt;p&gt;Ada was the daughter of the poet Byron.
      For her, pushing boundaries was a family tradition.
    Babbage was happy to leave these matters to Ada.
      As
      &lt;a href=&quot;http://www.fourmilab.ch/babbage/hpb.html&quot;&gt;Babbage's son put it&lt;/a&gt;,
      his father
    &lt;/p&gt;&lt;blockquote&gt;
      considered
      the Paper by Menabrea, translated with notes by Lady Lovelace,
      published in volume 3 of Taylor's 'Scientific Memoirs,&quot;
      as quite disposing of the mathematical aspect of the invention.
      My business now is not with that.
    &lt;/blockquote&gt;
    &lt;h3&gt;On reading Ada&lt;/h3&gt;
    &lt;p&gt;Ada's notes are worth reading,
    but the modern reader has to be prepared to face 
      several layers of difficulty:
      &lt;ul&gt;
    &lt;li&gt;They are in Victorian English.
      In modern English, a long complex sentence is usually considered a editing failure.
      In Ada's time, following Greek and Roman examples,
      a periodic sentence was considered especially appropriate when making an important point.
      And good literary style and good scientific style were considered one and the same.
      &lt;li&gt;They are mathematical,
      and none of math is of the kind currently studied by programmers.
      &lt;li&gt;Ada has literally no prior literature on software to build on,
      and has to invent her terminology.
      It is almost never the modern terminology, and it can be hard to guess
      how it relates to modern terminology.
      For example, does Ada forsee objects, methods and classes?
        Ada speaks of computing both symbolic results and numeric data,
        and attaching one to the other.
        She clearly understands that the symbolic results can represent operations.
        Ada also clearly understands that numeric data can
        represent not just the numbers themselves,
	but notes, positions in a loom, or computer operations.
        So we have arbitrary data, tagged with symbols that can be both names and operations.
	But are these objects?
      &lt;/li&gt;
      &lt;li&gt;Finally, she associates mathematics with philosophy.
      In her day, this was expected.
        Unfortunately, modern readers now often see that sort of discussion as
        irrelevant, or even as a sign of inability to come to the point.
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;p&gt;
    &lt;/p&gt;&lt;h3&gt;Ada's quote&lt;/h3&gt;
    &lt;blockquote&gt;
      Those who view mathematical science,
      not merely as a vast body of abstract and immutable truths,
      whose intrinsic beauty,
      symmetry and logical completeness,
      when regarded in their connexion together as a whole,
      entitle them to a prominent place in the interest of all profound
      and logical minds,
      but as possessing a yet deeper interest for the human race,
      when it is remembered that this science constitutes the language
      through which alone we can adequately express the great facts of
      the natural world,
      and those unceasing changes of mutual relationship which,
      visibly or invisibly,
      consciously or unconsciously to our immediate physical perceptions,
      are interminably going on in the agencies of the creation we live amidst:
      those who thus think on mathematical truth as the instrument through
      which the weak mind of man can most effectually read his Creator's
      works,
      will regard with especial interest all that can tend to facilitate
      the translation of its principles into explicit practical forms.
    &lt;/blockquote&gt;
    &lt;h3&gt;Ada, the bullet point version&lt;/h3&gt;
    &lt;p&gt;Ada's sentence may look like what happens
    when
      two pickups carrying out-of-date dictionaries to the landfill
      run into
      each other on the way.
      But there is, in fact,
      a good deal of structure and meaning in all those words.
      Let's take it as bullet points:
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;1. Math is awesome just for being itself.&lt;/li&gt;
      &lt;li&gt;2. Math describes and predicts the external world.&lt;/li&gt;
      &lt;li&gt;3. Math is the best way to get at
      what it is that is really behind existence.&lt;/li&gt;
      &lt;li&gt;4. If we can do more and better math, that has to be a good thing.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;p&gt;
      Ada is connecting her new science of software to
      the history of thought in the West,
      something which readers of the time would expect her to do.
      Bullet point 1 alludes to the Greek view of mathematics,
      especially Plato's.
      Bullet point 2 alludes to the scientific view, as pioneered by
      Galileo and Newton.
      Bullet point 3 alludes to the post-Classical world view,
      especially the Christian one.
      But while the language is Christian, Ada's idea is one that Einstein
      would have had no trouble with.
      And bullet 4 is the call to action.
    &lt;/p&gt;
    &lt;p&gt;
      When we come to discuss the parse in detail,
      we'll see that it follows this structure.
      As an aside,
      note Ada's mention of &quot;logical completeness&quot; as one of the virtues of math.
      G&amp;ouml;del came along nearly a century later and showed this vision,
      which went back to the Greeks, was an illusion.
      So Ada did not predict everything.
      On the other hand,
      G&amp;ouml;del's result was also a complete surprise to Johnny von Neumann,
      who was in the room that day.
    &lt;/p&gt;
    &lt;h3&gt;The experiment so far&lt;/h3&gt;
    &lt;p&gt;I've gotten Marpa to grind through this sentence,
    using the same framework as
    &lt;a href=&quot;http://nlp.stanford.edu:8080/parser/&quot;&gt;
    the Stanford NLP demo&lt;/a&gt;.
    That demo, in fact, refuses to even attempt any sentence longer than 70 words,
    so my Ada quote needs to be broken up.
    Even on the smaller pieces,
    the Stanford demo becomes quite slow.
    Marpa, by contrast, grinds through the whole thing quickly.
    The Stanford demo is based on a CYK parser, and presumably is O(n&lt;sup&gt;3&lt;/sup&gt;) -- cubic.
    Marpa seems to be exhibiting linear behavior.
    &lt;p&gt;Promising as this seems for Marpa,
    its first results may not hold up as the experiment gets more realistic.
    So far, I've only given Marpa enough English grammar and vocabulary to parse this one
    sentence.
    That is enough to make the grammar very complex and ambiguous,
    but even so it must be far less complex and ambiguous
    than the one behind the Stanford demo.
    Marpa will never have time worse than O(n&lt;sup&gt;3&lt;/sup&gt;),
    but it's quite possible that if Marpa's grammar were as ambiguous as the Stanford one,
    Marpa would be no faster.
    Marpa, in fact, could turn out to be slower by some linear factor.
    &lt;p&gt;There may never be a final decision based on speed.
    Marpa might turn out to represent one approach, good for certain purposes.
    And, especially when speed is indecisive,
    other abilities can prove more important.
    &lt;h3&gt;To learn more&lt;/h3&gt;
    &lt;p&gt;
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2
        is available on CPAN&lt;/a&gt;.
      A list of my Marpa tutorials can be found
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        here&lt;/a&gt;.
      There are
        new tutorials by
      &lt;a href=&quot;http://marpa-guide.github.io/chapter1.html&quot;&gt;Peter Stuifzand&lt;/a&gt;
      and &lt;a href=&quot;http://longanswers.blogspot.de/2013/06/transforming-syntax.html&quot;&gt;amon&lt;/a&gt;.
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
      The Ocean of Awareness blog&lt;/a&gt;
      focuses on Marpa,
      and it has
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html&quot;&gt;an annotated guide&lt;/a&gt;.
      Marpa also has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page&lt;/a&gt;.
      For questions, support and discussion, there is
      &lt;a href=&quot;http://groups.google.com/group/marpa-parser&quot;&gt;
      the &quot;marpa parser&quot;
      Google Group.&lt;/a&gt;
      Comments on this post can be made there.
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>Marpa v. Parse::RecDescent: a rematch</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/06/vs-prd-round-2.html</link>
    <description>  &lt;h3&gt;The application&lt;/h3&gt;&lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
--&gt;&lt;p&gt;
      In
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/individual/2013/06/mixing-procedural.html&quot;&gt;
      a recent post&lt;/a&gt;,
      I looked at an unusual language which serializes arrays and strings,
      using a mixture of counts and parentheses.  Here is an example:
    &lt;/p&gt;
&lt;blockquote&gt;&lt;pre&gt;
A2(A2(S3(Hey)S13(Hello, World!))S5(Ciao!))
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;
      The language is of special interest for comparison
      against recursive descent
      because, while simple, it requires procedural
      parsing -- a purely declarative BNF approach will not work.
      So it's a chance to find out if Marpa can play the game that is recursive descent's
      specialty.
      &lt;/p&gt;
      &lt;p&gt;
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/individual/2013/06/mixing-procedural.html&quot;&gt;
      The previous post&lt;/a&gt;
      focused on how to use Marpa to mix
      procedural and declarative parsing together smoothly,
      from a coding point of view.
      It only hinted at another aspect: speed.
    Over the last year, Marpa has greatly improved its speed for this kind of application.
      The latest release of Marpa::R2 now clocks in almost 100 times faster than Parse::RecDescent for long inputs.
    &lt;/p&gt;
    &lt;h3&gt;The benchmark&lt;/h3&gt;
    &lt;table align=&quot;center&quot; cellpadding=&quot;5&quot; border=&quot;1&quot; width=&quot;100%&quot;&gt;
      &lt;tbody&gt;&lt;tr&gt;&lt;th rowspan=&quot;2&quot;&gt;Length&lt;/th&gt;&lt;th colspan=&quot;3&quot;&gt;Seconds&lt;/th&gt;&lt;/tr&gt;
        &lt;tr&gt;
          &lt;th&gt;Marpa::R2&lt;/th&gt;
          &lt;th&gt;Marpa::XS&lt;/th&gt;
          &lt;th&gt;Parse::RecDescent
          &lt;/th&gt;&lt;/tr&gt;
        &lt;tr&gt;&lt;td&gt;1000
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;1.569
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;2.938
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;13.616
          &lt;/td&gt;&lt;/tr&gt;
        &lt;tr&gt;&lt;td&gt;2000
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;2.746
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;7.067
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;62.083
          &lt;/td&gt;&lt;/tr&gt;
        &lt;tr&gt;&lt;td&gt;3000
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;3.935
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;13.953
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;132.549
          &lt;/td&gt;&lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;10000
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;12.270
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;121.654
          &lt;/td&gt;&lt;td align=&quot;center&quot;&gt;1373.171
          &lt;/td&gt;&lt;/tr&gt;
      &lt;/tbody&gt;&lt;/table&gt;
    &lt;p&gt;Parse::RecDescent is pure Perl, while Marpa is based on a parse
      engine in a library written in
      hand-optimized C.
      You'd expect Marpa to win this race and it did.
    &lt;/p&gt;
    &lt;p&gt;
      And it is nice to see that the changes from Marpa::XS to Marpa::R2 have paid off.
      Included in the table are the Marpa numbers from my
      2012 benchmark of Marpa::XS.
      Marpa::R2 has a new interface
      and an internal lexer,
      and now beats Marpa::XS by a factor of up to 10.
      &lt;/p&gt;
      &lt;p&gt;
      While the benchmarked language is ideally suited to show recursive descent to
      advantage, the input lengths were picked to emphasize Marpa's strengths.
      Marpa optimizes by doing a lot of precomputation,
      and is written with long inputs in mind.
      Though these days, a 500K source,
      longer than the longest tested, would not exactly set a new industry record.
    &lt;/p&gt;
    &lt;h3&gt;To learn more&lt;/h3&gt;
    &lt;p&gt;
      There are fuller descriptions of the language in
      &lt;a href=&quot;http://blogs.perl.org/users/polettix/2012/04/parserecdescent-and-number-of-elements-read-on-the-fly.html&quot;&gt;
        Flavio's post and code&lt;/a&gt;,
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/individual/2013/06/mixing-procedural.html&quot;&gt;
      and my recent post on how to write a parser for this language&lt;/a&gt;.
      I talk more about the benchmark's methodology in
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/individual/2012/04/marpa-v-parserecdescent-some-numbers.html&quot;&gt;
      my post on the 2012 benchmark&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2
        is available on CPAN&lt;/a&gt;.
      A list of my Marpa tutorials can be found
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        here&lt;/a&gt;.
      There is
      &lt;a href=&quot;http://marpa-guide.github.io/chapter1.html&quot;&gt;
        a new tutorial by Peter Stuifzand&lt;/a&gt;.
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
        The Ocean of Awareness blog&lt;/a&gt;
      focuses on Marpa,
      and it has
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html&quot;&gt;an annotated guide&lt;/a&gt;.
      Marpa also has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page&lt;/a&gt;.
      For questions, support and discussion, there is a
      Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;.
      Comments on this post can be made there.
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>Mixing procedural and declarative parsing gracefully</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/06/mixing-procedural.html</link>
    <description>  &lt;h3&gt;Declarative and procedural parsing&lt;/h3&gt;
    &lt;p&gt;&lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
--&gt;A declarative parser
      takes a description of your language and parses it
      for you.
      On the face of it, this sounds like the way you'd want
      to go,
      and Marpa offers that possibility -- it generates
      a parser from anything you can write in BNF and,
      if the parser is in one of the classes currently in
      practical use,
      that parser will run in linear time.
    &lt;/p&gt;
    &lt;p&gt;
      But practical grammars often have context-sensitive parts --
      features which cannot be described in BNF.
      Nice as declarative parsing may sound,
      at least
      &lt;b&gt;some&lt;/b&gt;
      procedural parsing
      can be a necessity
      in real-life.
      In this post, I take a problem for which procedural
      parsing is essential,
      and create a fast, short solution that
      mixes procedural and declarative.
    &lt;/p&gt;
    &lt;h3&gt;The application&lt;/h3&gt;
    &lt;p&gt;This is a sample of the language:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
A2(A2(S3(Hey)S13(Hello, World!))S5(Ciao!))
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      It describes strings in nested arrays.
      The strings are introduced by the letter 'S', followed by a length count and then,
      in parentheses, the string itself.
      Arrays are introduced by the letter 'A' followed by an element count and, inside parentheses, the
      array's contents.
      These contents are a concatenated series of strings and other arrays.
      I call this a Dyck-Hollerith language because it
      combines
      &lt;a href=&quot;http://en.wikipedia.org/wiki/Hollerith_constant&quot;&gt;
        Hollerith constants&lt;/a&gt;
      (strings preceded by a count),
      with balanced parentheses
      (what is called
      &lt;a href=&quot;http://en.wikipedia.org/wiki/Dyck_language&quot;&gt;
        a Dyck language&lt;/a&gt;
      by mathematicians).
    &lt;/p&gt;
    &lt;p&gt;
      The language is one I've dealt with before.
      It is apparently from &quot;real life&quot;, and is described more fully
      in
      &lt;a href=&quot;http://blogs.perl.org/users/polettix/2012/04/parserecdescent-and-number-of-elements-read-on-the-fly.html&quot;&gt;
        a blog post by
        Flavio Poletti&lt;/a&gt;.
      Several people, Gabor Szabo among them, prodded me to show how
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;
        Marpa&lt;/a&gt;
      would do on this language.
      I did this
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/individual/2012/04/marpa-v-parserecdescent-some-numbers.html&quot;&gt;a year ago, using Marpa's previous version, Marpa::XS&lt;/a&gt;.
      The result was well-received and quite satisfactory.
    &lt;/p&gt;
    &lt;p&gt;
      This time around, I used
      Marpa's latest version, Marpa::R2,
      and its new interface, the SLIF.
      The solution presented here was
      much easer to write,
      and will be easier to read.
      It is also several times faster.
    &lt;/p&gt;
    &lt;h3&gt;The code&lt;/h3&gt;
    &lt;p&gt;The full code for this example is in
      &lt;a href=&quot;https://gist.github.com/jeffreykegler/5745272&quot;&gt;
        a Github gist&lt;/a&gt;.
      In what follows, I will assume the reader is
      interested in the ideas.
      Details of the interface,
      along with more detail-oriented tutorials,
      can be found
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;
        in Marpa's documentation&lt;/a&gt;.
      Other tutorials are
      on
      &lt;a href=http://jeffreykegler.github.io/Ocean-of-Awareness-blog/&quot;&gt;
        the Ocean of Awareness blog&lt;/a&gt;,
      and on
      &lt;a href=&quot;http://marpa-guide.github.io/index.html&quot;&gt;
        the Marpa Guide,
        a new website&lt;/a&gt;
      being
      built due to the generosity of Peter Stuifzand
      and Ron Savage.
    &lt;/p&gt;
    &lt;h3&gt;The DSL&lt;/h3&gt;
    &lt;p&gt;First off, let's look at the declarative part.
      The core of the parser is the following lines,
      containing the BNF for the language's top-level structure.
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
my $dsl = &amp;lt;&amp;lt;'END_OF_DSL';
# The BNF
:start ::= sentence
sentence ::= element
array ::= 'A' &amp;lt;array count&amp;gt; '(' elements ')'
    action =&amp;gt; check_array
string ::= ( 'S' &amp;lt;string length&amp;gt; '(' ) text ( ')' )
elements ::= element+
  action =&amp;gt; ::array
element ::= string | array
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;Details of this syntax are in Marpa's documentation,
      but it's a dialect of EBNF.
      Adverbs like
      &lt;tt&gt;action =&amp;gt; semantics&lt;/tt&gt;
      tell Marpa what the semantics will be.
      The default (which will be set below) is for a rule to return its first child.
      &lt;tt&gt;::array&lt;/tt&gt;
      semantics tell Marpa to return all every
      &lt;tt&gt;element&lt;/tt&gt;
      of
      &lt;tt&gt;elements&lt;/tt&gt;
      in an array.
      And
      &lt;tt&gt;check_array&lt;/tt&gt;
      is the name of a function providing
      the semantics, as will be seen below.
    &lt;/p&gt;
    &lt;p&gt;
      Single-quoted strings are looked for literally in the input.
      In the
      &lt;tt&gt;string&lt;/tt&gt;
      declaration,
      you'll note some parentheses which are not in quotes.
      The unquoted parentheses are part of the Marpa DSL's own syntax,
      telling Marpa to &quot;hide&quot; the parenthesized symbols from the
      semantics.
      Here, the effect is that
      &lt;tt&gt;text&lt;/tt&gt;
      is treated by the semantics as if it
      were the &quot;first&quot; symbol.
    &lt;/p&gt;
    &lt;p&gt;Marpa's SLIF provides a lexer for the user,
      and this Marpa-internal lexer will handle most
      of the symbols in this example.
      The single-quoted strings we saw in the BNF are actually instructions
      to the internal lexer.
      The next lines tell Marpa how to recognize
      &lt;tt&gt;&amp;lt;array count&amp;gt;&lt;/tt&gt;
      and
      &lt;tt&gt;&amp;lt;string length&amp;gt;&lt;/tt&gt;.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
&amp;lt;array count&amp;gt; ~ [\d]+
&amp;lt;string length&amp;gt; ~ [\d]+
text ~ [\d\D]
END_OF_DSL
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      &lt;tt&gt;&amp;lt;array_count&amp;gt;&lt;/tt&gt;
      and
      &lt;tt&gt;&amp;lt;string length&amp;gt;&lt;/tt&gt;
      are both declared to be a series of digits.
      &lt;tt&gt;text&lt;/tt&gt;
      is a stub.
      The length of
      &lt;tt&gt;text&lt;/tt&gt;
      depends on the numeric value of
      &lt;tt&gt;&amp;lt;string length&amp;gt;&lt;/tt&gt;, and dealing with that is beyond the power of
      the BNF.
      When it comes time to count out the symbols needed for
      &lt;tt&gt;text&lt;/tt&gt;,
      we will hand control over to an external lexer.
      For the purposes of Marpa's lexer,
      &lt;tt&gt;text&lt;/tt&gt;
      is described
      as a single character of any kind.
      Marpa's internal scanner uses a longest tokens match algorithm,
      and since we don't want the internal scanner to read
      &lt;tt&gt;text&lt;/tt&gt;
      lexemes,
      describing
      &lt;tt&gt;text&lt;/tt&gt;
      and other purely external lexemes
      as single characters is the right thing to do.
    &lt;/p&gt;
    &lt;p&gt;Now comes the weld between declarative and procedural ...
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
:lexeme ~ &amp;lt;string length&amp;gt; pause =&amp;gt; after
:lexeme ~ text pause =&amp;gt; before
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;These two statements tell Marpa that
      &lt;tt&gt;&amp;lt;string length&amp;gt;&lt;/tt&gt;
      and
      &lt;tt&gt;&amp;lt;text&amp;gt;&lt;/tt&gt;
      are two lexicals at which Marpa's own parsing should &quot;pause&quot;,
      handing over control to external procedural parsing logic.
      In the case of
      &lt;tt&gt;&amp;lt;string length&amp;gt;&lt;/tt&gt;,
      the pause should be after it is read.
      In the case of
      &lt;tt&gt;&amp;lt;text&amp;gt;&lt;/tt&gt;
      the pause should be before.
      What happens during the &quot;pause&quot;, we will soon see.
    &lt;/p&gt;
    &lt;h3&gt;Starting the parse&lt;/h3&gt;
    &lt;p&gt;Next follows the code to read the DSL,
      and start the parser.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
my $grammar = Marpa::R2::Scanless::G-&amp;gt;new(
    {   action_object  =&amp;gt; 'My_Actions',
        default_action =&amp;gt; '::first',
        source         =&amp;gt; \$dsl
    }
);

my $recce = Marpa::R2::Scanless::R-&amp;gt;new( { grammar =&amp;gt; $grammar } );
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;The previous lines tell Marpa that when its semantics
      are provided by a Perl closure, it is to look for that closure in a package called
      &lt;tt&gt;My_Actions&lt;/tt&gt;.
      The default semantics are
      &lt;tt&gt;::first&lt;/tt&gt;, which means simply pass the value of
      the first RHS symbol of a rule upwards.
    &lt;/p&gt;
    &lt;h3&gt;The main loop&lt;/h3&gt;
    &lt;p&gt;We saw our input above:&lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
$input = 'A2(A2(S3(Hey)S13(Hello, World!))S5(Ciao!))';
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;The block of code which follows is the main loop through the parse, including
      all the procedural parsing logic.
      Below, I will pull this
      procedural parsing logic out of the loop
      for separate examination.
    &lt;/p&gt;
    &lt;p&gt;
      Here the
      &lt;tt&gt;$recce-&amp;gt;read()&lt;/tt&gt;
      method performs the first read
      and sets up the input string.
      The interior of the loop is entered whenever Marpa &quot;pauses&quot;.
      Once the procedural parsing logic is done, Marpa resumes with
      the
      &lt;tt&gt;$recce-&amp;gt;resume()&lt;/tt&gt;
      call.
      Throughout,
      &lt;tt&gt;$pos&lt;/tt&gt;
      is used to track the current character
      in the input stream.
      The loop ends when
      &lt;tt&gt;$pos&lt;/tt&gt;
      is after the last character of
      &lt;tt&gt;$input&lt;/tt&gt;.
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
my $last_string_length;
my $input_length = length $input;
INPUT:
for (
    my $pos = $recce-&amp;gt;read( \$input );
    $pos &amp;lt; $input_length;
    $pos = $recce-&amp;gt;resume($pos)
    )
{
    my $lexeme = $recce-&amp;gt;pause_lexeme();
    die q{Parse exhausted in front of this string: &quot;},
        substr( $input, $pos ), q{&quot;}
        if not defined $lexeme;
    my ( $start, $lexeme_length ) = $recce-&amp;gt;pause_span();
    if ( $lexeme eq 'string length' ) {
        $last_string_length = $recce-&amp;gt;literal( $start, $lexeme_length ) + 0;
        $pos = $start + $lexeme_length;
        next INPUT;
    }
    if ( $lexeme eq 'text' ) {
        my $text_length = $last_string_length;
        $recce-&amp;gt;lexeme_read( 'text', $start, $text_length );
        $pos = $start + $text_length;
        next INPUT;
    } ## end if ( $lexeme eq 'text' )
    die &quot;Unexpected lexeme: $lexeme&quot;;
} ## end INPUT: for ( my $pos = $recce-&amp;gt;read( \$input ); $pos &amp;lt; $input_length...)
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;The procedural parsing&lt;/h3&gt;
    &lt;p&gt;In this language,
      we need the procedural parsing logic to count the
      &lt;tt&gt;text&lt;/tt&gt;
      strings properly.
      This is done in a very direct way.
      First we pull the count from
      &lt;tt&gt;&amp;lt;string length&amp;gt;&lt;/tt&gt;:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
    if ( $lexeme eq 'string length' ) {
        $last_string_length = $recce-&amp;gt;literal( $start, $lexeme_length ) + 0;
        $pos = $start + $lexeme_length;
        next INPUT;
    }
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      Above, we used
      &lt;tt&gt;pause_span()&lt;/tt&gt;
      to set
      &lt;tt&gt;$start&lt;/tt&gt;
      and
      &lt;tt&gt;$lexeme_length&lt;/tt&gt;
      to the start and length of the lexeme that
      Marpa's internal scanner found.
      Passed to
      &lt;tt&gt;$recce-&amp;gt;literal()&lt;/tt&gt;, these two values
      return the &quot;literal&quot; string value of the lexeme, which will
      be the ASCII representation of a decimal number.
      We convert it to numeric, salt it away in
      &lt;tt&gt;$last_string_length&lt;/tt&gt;,
      and set
      &lt;tt&gt;$pos&lt;/tt&gt;
      to the location just after the
      &lt;tt&gt;&amp;lt;string length&amp;gt;&lt;/tt&gt;
      lexeme.
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
    if ( $lexeme eq 'text' ) {
        my $text_length = $last_string_length;
        $recce-&amp;gt;lexeme_read( 'text', $start, $text_length );
        $pos = $start + $text_length;
        next INPUT;
    } ## end if ( $lexeme eq 'text' )
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;Now we come to counting out the characters for the
      &lt;tt&gt;text&lt;/tt&gt;
      lexeme.
      Recall that in the case of
      &lt;tt&gt;text&lt;/tt&gt;, we pause
      &lt;b&gt;before&lt;/b&gt;
      the lexeme, which means it will not have been read yet.
      With
      &lt;tt&gt;$recce-&amp;gt;lexeme_read()&lt;/tt&gt;, we tell Marpa
      that we want the next lexeme
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;to be of type
        &lt;tt&gt;text&lt;/tt&gt;,
      &lt;/li&gt;
      &lt;li&gt;to start at the already decided
        &lt;tt&gt;$start&lt;/tt&gt;
        position, and
      &lt;/li&gt;
      &lt;li&gt;
        to be of the length that
        we saved in
        &lt;tt&gt;$last_string_length&lt;/tt&gt;.
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;p&gt;
      We also set
      &lt;tt&gt;$pos&lt;/tt&gt;
      to be just after the
      end of the lexeme.
    &lt;/p&gt;
    &lt;p&gt;We've focused on the string lengths, but the Dyck-Hollerith language has
      a count of the number of elements in its array.
      Marpa's BNF-driven parsing logic has no trouble
      determining the number of elements from the array contents,
      and it does not need the count.
      What to do with it?
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
package My_Actions;
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
sub check_array {
    my ( undef, undef, $declared_size, undef, $array ) = @_;
    my $actual_size = @{$array};
    warn
        &quot;Array size ($actual_size) does not match that specified ($declared_size)&quot;
        if $declared_size != $actual_size;
    return $array;
} ## end sub check_array
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;Recall that Marpa promised special semantics for the
      &lt;tt&gt;array&lt;/tt&gt;
      rule
      in its DSL.
      Here they are.
      The first parameter to Marpa's semantic closures is a per-parse variable, here unused.
      The rest are the values of the RHS symbols, in order.
      We only care about the second (for
      &lt;tt&gt;&amp;lt;array count&amp;gt;&lt;/tt&gt;),
      and the fourth (for
      &lt;tt&gt;elements&lt;/tt&gt;).
      We determine a
      &lt;tt&gt;$declared_size&lt;/tt&gt;
      from
      &lt;tt&gt;&amp;lt;array count&amp;gt;&lt;/tt&gt;;
      and an
      &lt;tt&gt;$actual_size&lt;/tt&gt;
      by looking at the array referenced by
      &lt;tt&gt;$array&lt;/tt&gt;.
      If these differ, we choose to warn the user.
      Depending on your purposes,
      anything from ignoring the issue
      to throwing a fatal error may be equally or more reasonable.
    &lt;/p&gt;
    &lt;h3&gt;The result of the the parse&lt;/h3&gt;
    &lt;p&gt;And now we are ready to take the result of the parse.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
my $result = $recce-&amp;gt;value();
die 'No parse' if not defined $result;
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;For more about Marpa&lt;/h3&gt;
    &lt;p&gt;The techniques described apply to problems considerably
      larger than the example of this post.
      Jean-Damien Durand is using them to create
      &lt;a href=&quot;https://github.com/jddurand/MarpaX-Languages-C-AST&quot;&gt;
        a C-to-AST tool&lt;/a&gt;.
      This
      takes C language and converts it to an AST,
      following the C11
      specification carefully.
      The AST can then be manipulated
      as you wish.
    &lt;/p
    &lt;p&gt;&lt;p&gt;
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2
        is available on CPAN&lt;/a&gt;.
      A list of my Marpa tutorials can be found
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        here&lt;/a&gt;.
      There is
      &lt;a href=&quot;http://marpa-guide.github.io/chapter1.html&quot;&gt;
        a new tutorial by Peter Stuifzand&lt;/a&gt;.
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
        The Ocean of Awareness blog&lt;/a&gt;
      focuses on Marpa,
      and it has
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html&quot;&gt;an annotated guide&lt;/a&gt;.
      Marpa also has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page&lt;/a&gt;.
      For questions, support and discussion, there is a
      Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;.
      Comments on this post can be made there.
    &lt;/p&gt;</description>
  </item>
  </channel>
</rss>
