<?xml version="1.0"?>
<!-- name="generator" content="blosxom/2.0" -->
<!DOCTYPE rss PUBLIC "-//Netscape Communications//DTD RSS 0.91//EN" "http://my.netscape.com/publish/formats/rss-0.91.dtd">

<rss version="0.91">
  <channel>
    <title>Ocean of Awareness   </title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog</link>
    <description>Ocean of Awareness.</description>
    <language>en</language>

  <item>
    <title>Language design: Exploiting ambiguity</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2014/08/ambig.html</link>
    <description>&lt;html&gt;
  &lt;head&gt;
  &lt;/head&gt;
  &lt;body&gt;&lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      Currently, in designing lanuages,
      we don't allow ambiguitites --
      not even potential ones.
      We insist that it must not be
      even
      &lt;b&gt;possible&lt;/b&gt;
      to write an ambiguous program.
      This is unnecessarily restrictive.
    &lt;/p&gt;
    &lt;p&gt;
      This post is written in English, which is full of ambiguities.
      Natural languages are always ambiguous,
      because human beings find that that's best way for versatile,
      rapid, easy communication.
      Human beings arrange things so that every
      sentence is unambiguous in context.
      Mistakes happen, and ambiguous sentences occur,
      but in practice, the problem is manageable.
      In a conversation, for example,
      we would just ask for clarification.
    &lt;/p&gt;
    &lt;p&gt;
      If we allow our computer languages to take their most natural forms,
      they will often have the
      &lt;b&gt;potential&lt;/b&gt;
      for ambiguity.
      This is even less of a problem on a computer than it is in
      conversation -- a computer can always spot an actual ambiguity
      immediately.
      When
      &lt;b&gt;actual&lt;/b&gt;
      ambiguities occur, we can deal them
      in exactly the same way that we deal with
      any other syntax problem:
      The computer catches it and reports it,
      and we fix it.
    &lt;/p&gt;
    &lt;h3&gt;An example&lt;/h3&gt;
    &lt;p&gt;
      To illustrate,
      I'll use a DSL-writing DSL language.
      It'll be tiny -- just lexeme declarations and BNF rules.
      Newlines will
      &lt;b&gt;not&lt;/b&gt;
      be significant.
      Statements can end with a semicolon, but that's optional.
      (The code for this post is in
      &lt;a href=&quot;https://gist.github.com/jeffreykegler/ed64bf00983f7be666bc&quot;&gt;
        a Github gist&lt;/a&gt;.)
    &lt;/p&gt;
    &lt;p&gt;Here is a toy calculator written in our tiny DSL-writing language:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
  Number matches '\d+'
  E ::= T '*' F
  E ::= T
  T ::= F '+' Number
  T ::= Number
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;Trying an improvement&lt;/h3&gt;
    &lt;p&gt;With a grammar this small, just about
      &lt;b&gt;anything&lt;/b&gt;
      is readable.
      But let's assume we want to improve it, and that we decide
      that the lexeme declaration of
      &lt;tt&gt;Number&lt;/tt&gt;
      really belongs
      after the rules which use it.
      (If our grammar was longer, this could make a real difference.)
      So we move the lexeme declaration to the end:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
  E ::= T '*' F
  E ::= T
  T ::= F '+' Number
  T ::= Number
  Number matches '\d+'
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;But there's an issue&lt;/h3&gt;
    &lt;p&gt;
      It turns out the grammar for our toy DSL-writer is ambiguous.
      When a lexeme declaration follows a BNF rule,
      there's no way to tell whether or not it is actually a
      lexeme declaration, or part of the BNF rule.
      Our parser catches that:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
Parse of BNF/Scanless source is ambiguous
Length of symbol &quot;Statement&quot; at line 4, column 1 is ambiguous
  Choices start with: T ::= Number
  Choice 1, length=12, ends at line 4, column 12
  Choice 1: T ::= Number
  Choice 2, length=33, ends at line 5, column 20
  Choice 2: T ::= Number\nNumber matches '\\d
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;
      Here Marpa tells you why it thinks your script is ambiguous.
      Two different statements can start at line 4.
      Both of them are BNF rules, but one is longer than the other.
    &lt;/p&gt;
    &lt;h3&gt;Just another syntax error&lt;/h3&gt;
    &lt;p&gt;Instead of having to design a language where ambiguity was not
      even possible, we designed one where ambiguities can happen.
      This allows us to design a much more flexible language,
      like the ones we choose when we humans communicate with each other.
      The downside is that actual ambiguities will occur,
      but they can be reported, and fixed,
      just like any other syntax error.
    &lt;/p&gt;&lt;p&gt;In this case, we
      recall we allowed semi-colons to terminate a rule,
      and our fix is easy:
    &lt;/p&gt;
    &lt;p&gt;
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
  E ::= T '*' F
  E ::= T
  T ::= F '+' Number
  T ::= Number ;
  Number matches '\d+'
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;To learn more&lt;/h3&gt;
    &lt;p&gt;
      The code for this post is
      &lt;a href=&quot;https://gist.github.com/jeffreykegler/ed64bf00983f7be666bc&quot;&gt;
        a gist on Github&lt;/a&gt;.
      It was written using
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2,
        which is available on CPAN&lt;/a&gt;.
      A list of my Marpa tutorials can be found
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        here&lt;/a&gt;.
      There are
      new tutorials by
      &lt;a href=&quot;http://marpa-guide.github.io/chapter1.html&quot;&gt;Peter Stuifzand&lt;/a&gt;
      and
      &lt;a href=&quot;http://longanswers.blogspot.de/2013/06/transforming-syntax.html&quot;&gt;amon&lt;/a&gt;.
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
        The Ocean of Awareness blog&lt;/a&gt;
      focuses on Marpa,
      and it has
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html&quot;&gt;an annotated guide&lt;/a&gt;.
      Marpa has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page that I maintain&lt;/a&gt;
      and Ron Savage maintains
      &lt;a href=&quot;http://savage.net.au/Perl-modules/html/marpa.papers/index.html&quot;&gt;
        another&lt;/a&gt;.
      For questions, support and discussion, there is
      &lt;a href=&quot;http://groups.google.com/group/marpa-parser&quot;&gt;
        a &quot;marpa parser&quot;
        Google Group&lt;/a&gt;
      and an IRC channel:
      &lt;tt&gt;#marpa&lt;/tt&gt;
      at
      &lt;tt&gt;irc.freenode.net&lt;/tt&gt;.
    &lt;/p&gt;
    &lt;h3&gt;Comments&lt;/h3&gt;
    &lt;p&gt;
      Comments on this post can be made in
      &lt;a href=&quot;http://groups.google.com/group/marpa-parser&quot;&gt;
        Marpa's Google group&lt;/a&gt;.
    &lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;</description>
  </item>
  <item>
    <title>Evolvable languages</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2014/03/kv.html</link>
    <description>&lt;html&gt;
  &lt;head&gt;
  &lt;/head&gt;
  &lt;body&gt;&lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      Ideally, if a syntax is useful and clear,
      and a programmer can easily read it at a glance,
      you should be able to add it to an existing language.
      In this post, I will describe
      a modest incremental change to the Perl syntax.
    &lt;/p&gt;
    &lt;p&gt;
      It's one I like, because that's beside the point, for two
      reasons.
      First, it's simply intended as an example of language evolution.
      Second, regardless of its merits, it is unlikely to happen,
      because of the way that Perl 5 is parsed.
      In this post I will demonstrate a way of writing a parser,
      so that this change,
      or others, can be made in a straightforward way,
      and without designing your language into a corner.
    &lt;/p&gt;
    &lt;p&gt;
      When initializing a hash, Perl 5 allows you to use not just commas,
      but also the so-called &quot;wide comma&quot; (&lt;tt&gt;=&amp;gt;&lt;/tt&gt;).
      The wide comma is suggestive visually, and it also has some smarts
      about what a hash key is:
      The hash key is always converted into a string, so that wide comma
      knows that in a key-value pair like this:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
    key1 =&gt; 711,
&lt;/pre&gt;
    &lt;/blockquote&gt;&lt;p&gt;
      that
      &lt;tt&gt;key1&lt;/tt&gt;
      is intended as a string.
    &lt;/p&gt;
    &lt;p&gt;
      But what about something like this?
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
  {
   company name =&gt; 'Kamamaya Technology',
   employee 1 =&gt; first name =&gt; 'Jane',
   employee 1 =&gt; last name =&gt; 'Doe',
   employee 1 =&gt; title =&gt; 'President',
   employee 2 =&gt; first name =&gt; 'John',
   employee 2 =&gt; last name =&gt; 'Smith',
   employee 3 =&gt; first name =&gt; 'Clarence',
   employee 3 =&gt; last name =&gt; 'Darrow',
  }
&lt;/pre&gt;
    &lt;/blockquote&gt;&lt;p&gt;
      Here I think the intent is obvious -- to create an employee database in the form
      of a hash of hashes, allowing spaces in the keys.
      In Data::Dumper format, the result would look like:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
{
              'employee 2' =&gt; {
                                'last name' =&gt; '\'Smith\'',
                                'first name' =&gt; '\'John\''
                              },
              'company name' =&gt; '\'Kamamaya Technology\'',
              'employee 3' =&gt; {
                                'last name' =&gt; '\'Darrow\'',
                                'first name' =&gt; '\'Clarence\''
                              },
              'employee 1' =&gt; {
                                'title' =&gt; '\'President\'',
                                'last name' =&gt; '\'Doe\'',
                                'first name' =&gt; '\'Jane\''
                              }
            }
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;And in fact, that is the output of the script in
      &lt;a href=&quot;https://gist.github.com/jeffreykegler/9478391&quot;&gt;
    this Github gist&lt;/a&gt;,
        which parses the previous &quot;extended Perl 5&quot; snippet using a Marpa
        grammar before passing it on to Perl.
      &lt;/p&gt;
      &lt;p&gt;Perl 5 does not allow a syntax like this,
      and looking at its parsing code will tell you why -- it's already
      a maintenance nightmare.
      The extension I've described above could, in theory, be added to Perl
      5, but doing so would aggravate an already desperate maintenance situation.
    &lt;p&gt;
      Now, depending on taste,
      you may be just as happy that you'll never
      see the extensions I have just outlined in Perl 5.
      But I don't think it is as easy to
      be happy about a parsing technology that
      quickly paints the languages which use it into a corner.
    &lt;/p&gt;
    &lt;h3&gt;How it works&lt;/h3&gt;
    &lt;p&gt;
      The code is in
      &lt;a href=&quot;https://gist.github.com/jeffreykegler/9478391&quot;&gt;
        a Github gist&lt;/a&gt;.
	For the purposes of the example, I've implemented
	a toy subset of Perl.
	But this approach has been shown to scale.
	There are full Marpa-powered parsers of
	&lt;a href=&quot;https://metacpan.org/release/MarpaX-Languages-C-AST&quot;&gt;C&lt;/a&gt;,
	&lt;a href=&quot;https://metacpan.org/release/MarpaX-Languages-ECMAScript-AST&quot;&gt;ECMAScript&lt;/a&gt;,
	&lt;a href=&quot;https://metacpan.org/release/MarpaX-xPathLike&quot;&gt;XPath&lt;/a&gt;, and
	&lt;a href=&quot;https://metacpan.org/pod/distribution/Marpa-R2/html/pod/HTML.pod&quot;&gt;liberal HTML&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;Marpa is a general BNF parser, which means that anything you can write in BNF, Marpa can parse.
    For practical parsing, what matters are those grammars that can be parsed in linear time,
    and with Marpa that class is vast, including all the classes of grammar currently in practical use.
    To describe the class of grammars that Marpa parses in linear time,
    assume that you have either a left or right parser,
    with infinite lookahead,
    that uses regular expressions.
    (A parser like this is called LR-regular.)
    Assume that this LR-regular parser parses your grammar.
    In that case,
    you can be sure that
    Marpa will parse that grammar in linear time, and without doing the lookahead.
    (Instead Marpa tracks possibilities in a highly-optimized table.)
    Marpa also parses many grammars that are not LR-regular in linear time,
    but just LR-regular is very likely to include any class of grammar that you will be
    interested in parsing.
    The LR-regular grammars easily include all those that can be
    parsed using yacc, recursive descent or regular expressions.
    &lt;/p&gt;
    &lt;p&gt;
    Marpa excels at those special hacks so necessary in recursive descent and other techniques.
    Marpa allows you to define events that will stop it at symbols or rules, both before and after.
    While stopped,
    you can hand processing over to your own custom code.
    Your custom code can feed your own tokens to the parse for as long as you like.
    In doing so, it can
    consult Marpa to determine exactly what symbols and rules have been recognized and
    which ones are expected.
    Once finished with custom processing,
    you can then ask Marpa to pick up again at any point you wish.
    &lt;/p&gt;
    &lt;h3&gt;The craps game is over&lt;/h3&gt;
    &lt;p&gt;The bottom line is that if you can describe your language extension in BNF,
    or in BNF plus some hacks,
    you can rely on Marpa parsing it in reasonable time.
    Language design has been like shooting crap in a casino
    that sets you up to
    win a lot of the first rolls before
    the laws of probability grind you down.
    Marpa changes the game.
    &lt;/p&gt;
    &lt;h3&gt;To learn more&lt;/h3&gt;
    &lt;p&gt;
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2
        is available on CPAN&lt;/a&gt;.
      A list of my Marpa tutorials can be found
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        here&lt;/a&gt;.
      There are
      new tutorials by
      &lt;a href=&quot;http://marpa-guide.github.io/chapter1.html&quot;&gt;Peter Stuifzand&lt;/a&gt;
      and
      &lt;a href=&quot;http://longanswers.blogspot.de/2013/06/transforming-syntax.html&quot;&gt;amon&lt;/a&gt;.
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
        The Ocean of Awareness blog&lt;/a&gt;
      focuses on Marpa,
      and it has
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html&quot;&gt;an annotated guide&lt;/a&gt;.
      Marpa has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page that I maintain&lt;/a&gt;
      and Ron Savage maintains
      &lt;a href=&quot;http://savage.net.au/Perl-modules/html/marpa.papers/index.html&quot;&gt;
        another&lt;/a&gt;.
      For questions, support and discussion, there is
      &lt;a href=&quot;http://groups.google.com/group/marpa-parser&quot;&gt;
        the &quot;marpa parser&quot;
        Google Group.&lt;/a&gt;
    &lt;/p&gt;
    &lt;h3&gt;Comments&lt;/h3&gt;
    &lt;p&gt;
      Comments on this post can be made in
      &lt;a href=&quot;http://groups.google.com/group/marpa-parser&quot;&gt;
      Marpa's Google group&lt;/a&gt;.
      &lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;</description>
  </item>
  <item>
    <title>Significant newlines?  Or semicolons?</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2014/02/semantic_ws.html</link>
    <description>&lt;html&gt;
  &lt;head&gt;
  &lt;/head&gt;
  &lt;body&gt;&lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      Should statements have explicit terminators, like the semicolon of Perl and
      the C language?
      Or should they avoid the clutter, and separate statements by giving whitespace
      syntactic significance and a real effect on
      the semantics,
      as is done in Python and Javascript?
    &lt;/p&gt;
    &lt;p&gt;
      Actually we don't have to go either way.
      As an example, let's look at some BNF-ish DSL.
      It defines a small calculator.
      At first glance, it looks as if this language has taken the
      significant-whitespace route -- there certainly are no explicit statement
      terminators.
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
:default ::= action =&amp;gt; ::first
:start ::= Expression
Expression ::= Term
Term ::=
      Factor
    | Term '+' Term action =&amp;gt; do_add
Factor ::=
      Number
    | Factor '*' Factor action =&amp;gt; do_multiply
Number ~ digits
digits ~ [\d]+
:discard ~ whitespace
whitespace ~ [\s]+
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;The rule is that there isn't one&lt;/h3&gt;
    &lt;p&gt;
      If we don't happen to like the layout of the above DSL,
      and rearrange it in various ways,
      we'll find that everything we try works.
      If we become curious about what exactly what the rules for newlines are,
      and look at
      &lt;a href=&quot;https://metacpan.org/pod/distribution/Marpa-R2/pod/Scanless/DSL.pod&quot;&gt;
        the documentation&lt;/a&gt;,
      we won't find any.
      That's because there aren't any.
    &lt;/p&gt;
    &lt;p&gt;
      We can see this by thoroughly messing up the line structure:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
:default ::= action =&amp;gt; ::first :start ::= Expression Expression ::= Term
Term ::= Factor | Term '+' Term action =&amp;gt; do_add Factor ::= Number |
Factor '*' Factor action =&amp;gt; do_multiply Number ~ digits digits ~
[\d]+ :discard ~ whitespace whitespace ~ [\s]+
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;The &lt;a href=&quot;https://gist.github.com/jeffreykegler/9220695&quot;&gt;
      script&lt;/a&gt; will continue to run just fine.
    &lt;/p&gt;
    &lt;h3&gt;How does it work?&lt;/h3&gt;
    &lt;p&gt;How does it work?
      Actually, pose the question this way:
      Can a human reader tell where the statements end?
      If the reader is not used to reading BNF,
      he might have trouble with this
      particular example but,
      for a language that he knows, the answer is simple:
      Yes, of course he can.
      So really the question is,
      why do we expect the parser to be so stupid that it cannot?
    &lt;/p&gt;
    &lt;p&gt;
      The only trick is that this is done without trickery.
      Marpa's DSL is
      &lt;a href=&quot;https://metacpan.org/source/JKEGL/Marpa-R2-2.080000/lib/Marpa/R2/meta/metag.bnf&quot;&gt;
        written in itself&lt;/a&gt;,
      and Marpa's self-grammar describes exactly what a statement is
      and what it is not.
      The Marpa parser is powerful enough to simply take this self-describing DSL
      and act on it, finding where statements begin and end,
      much as a human reader is able to.
    &lt;/p&gt;
    &lt;h3&gt;To learn more&lt;/h3&gt;
    &lt;p&gt;
      This example was produced with the Marpa parser.
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2
        is available on CPAN&lt;/a&gt;.
      The code for this example is based on that in
      the synopsis for its top-level document,
      but it is isolated conveniently in
      &lt;a href=&quot;https://gist.github.com/jeffreykegler/9220695&quot;&gt;
        a Github gist&lt;/a&gt;.
    &lt;/p&gt;&lt;p&gt;
    &lt;/p&gt;&lt;p&gt;
      A list of my Marpa tutorials can be found
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        here&lt;/a&gt;.
      There are
      new tutorials by
      &lt;a href=&quot;http://marpa-guide.github.io/chapter1.html&quot;&gt;Peter Stuifzand&lt;/a&gt;
      and
      &lt;a href=&quot;http://longanswers.blogspot.de/2013/06/transforming-syntax.html&quot;&gt;amon&lt;/a&gt;.
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
        The Ocean of Awareness blog&lt;/a&gt;
      focuses on Marpa,
      and it has
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html&quot;&gt;an annotated guide&lt;/a&gt;.
      Marpa has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page that I maintain&lt;/a&gt;
      and Ron Savage maintains
      &lt;a href=&quot;http://savage.net.au/Perl-modules/html/marpa.papers/index.html&quot;&gt;
        another&lt;/a&gt;.
      For questions, support and discussion, there is
      &lt;a href=&quot;http://groups.google.com/group/marpa-parser&quot;&gt;
        the &quot;marpa parser&quot;
        Google Group.&lt;/a&gt;
      Comments on this post can be made there.
    &lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;</description>
  </item>
  <item>
    <title>A Marpa-powered C parser</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/08/c2ast.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      Jean-Damien Durand has just released
      &lt;a href=&quot;https://metacpan.org/release/MarpaX-Languages-C-AST&quot;&gt;
        MarpaX::Languages::C::AST&lt;/a&gt;,
      which parses C language into an abstract syntax tree (AST).
      MarpaX::Languages::C::AST has been tested against
      Perl's C source code, as well as Marpa's own C source.
    &lt;/p&gt;
    &lt;p&gt;
      Because it is Marpa-powered,
      MarpaX::Languages::C::AST works differently from other C parsers.
      In the past,
      C parsers have been syntax-driven -- parsing was based on a BNF description
      of the C grammar.
      More recently, C parsers have used hand-written
      recursive descent -- they have been procedurally-driven.
    &lt;/p&gt;
    &lt;p&gt;
      MarpaX::Languages::C::AST uses both approaches.
      Marpa has the advantage that it makes full knowledge of the state of the parse
      available to the programmer,
      so that procedural logic and syntax-driven parsing can reinforce each other.
      The result is a combined lexer/parser
      which is very compact and easy to understand.
      Among the potential applications:
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Customized &quot;lints&quot;.
        You can write programs to enforce C language standards
        and restrictions specific to an individual, a company or a project.
      &lt;/li&gt;
      &lt;li&gt;C interpreters.
        By taking the AST and adding your own back end, you can create a special-purpose C interpreter
        or a special-purpose compiler.
      &lt;/li&gt;
      &lt;li&gt;C variants.
        Because the code for the parser is compact and easy to modify,
        it lends itself to language extension and experimentation.
        For example,
        you could reasonably implement compilers
        to try out the proposals submitted to
        a standards committee.
      &lt;/li&gt;
      &lt;li&gt;C supersets.
        Would you like to see some of the syntax from a favorite language available in C?
        Here's your chance.
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;h3&gt;The implementation&lt;/h3&gt;
    &lt;p&gt;A few of Jean-Damien's implementation choices are worth noting.
      A C parser can take one of two strategies: approximate or precise.
      A compiler has, of course, to be precise.
      Tools, such as cross-referencers, often decide to be approximate, or sloppy.
      Sloppiness is easier to implement and has other advantages:
      A sloppy tool can tolerate missing C flags: what the C flags should be
      can be one of the things it guesses at.
    &lt;/p&gt;
    &lt;p&gt;Of the two strategies, Jean-Damien decided to go with &quot;precise&quot;.
      MarpaX::Languages::C::AST follows the C11 standard,
      with either GCC or Microsoft extensions.
      This has the advantage that
      MarpaX::Languages::C::AST could be used as the front end of a compiler.
    &lt;/p&gt;
    &lt;p&gt;
      Because
      MarpaX::Languages::C::AST purpose is to take things as far as an AST,
      and let the user take over,
      it does not implement those constraints usually implemented in post-processing.
      One example of a post-syntactic constraint is the one that bans
      &quot;&lt;tt&gt;case&lt;/tt&gt;&quot; labels outside of switch statements.
      Perhaps a future version can include a default &quot;first phase&quot; post-processor to enforce
      the constraints from the standards.
      As currently implemented, the user can check for and enforce these constraints in any
      way he likes.
      This makes it easier for extensions and customizations,
      which I think of as the major purpose of MarpaX::Languages::C::AST.
    &lt;/p&gt;
    &lt;h3&gt;The parsing strategy&lt;/h3&gt;
    &lt;p&gt;
      Those familar with the C parsing and its special issues may be interested in
      Jean-Damien's approach to them.
      MarpaX::Languages::C::AST is, with a few exceptions, syntax-driven -- the parser works
      from Marpa's SLIF, an extended BNF variant.
      The SLIF-driven logic is sufficient to deal with the
      &lt;a href=&quot;http://en.wikipedia.org/wiki/Dangling_else&quot;&gt;if-then-else issue&lt;/a&gt;.
      Marpa handles right recursion in linear time,
      so that the if-then-else issue could have been dealt with by rewriting the relevant rules.
      But Jean-Damien wanted to have his BNF follow closely the grammar in the standards,
      and he decided to use Marpa's rule ranking facility instead.
    &lt;/p&gt;
    &lt;p&gt;More complicated is the ambiguity in C between variable names and types,
      which actually takes C beyond BNF and context-free grammars into context-sensitive
      territory.
      Most C parsers deal with this using
      &lt;a href=&quot;http://en.wikipedia.org/wiki/The_lexer_hack&quot;&gt;lexer
        or post-processing hacks&lt;/a&gt;.
      Marpa allows the parser to do this more elegantly.
      Marpa knows the parsing context at all times and can comnunicate this to a user's
      customized code.
      Marpa also has the ability to use the parsing context to
      decide when to
      switch control from the syntax-driven logic to
      a user's customized procedural logic,
      and for the syntax-driven logic to take control back
      when the procedural logic wants to give it back.
      This allows the variable-name-versus-type ambiguity to be handled by specifically targeted code
      which knows the full context of the decisions it needs to make.
      This code can be written more directly, simply and clearly
      than was possible with previous parsing methods.
    &lt;/p&gt;
    &lt;p&gt;
    &lt;/p&gt;&lt;h3&gt;Compilers?&lt;/h3&gt;
    &lt;p&gt;
      Above I mentioned special-purpose compilers.
      What about production compilers?
      MarpaX::Languages::C::AST's upper layers are in Perl,
      so the speed, while acceptable for special-purpose tools,
      will probably not be adequate for production.
      Perhaps a future Marpa-powered C parser will rewrite those
      upper layers in C, and make the race more interesting.
    &lt;/p&gt;
    &lt;h3&gt;To learn more&lt;/h3&gt;
    &lt;p&gt;
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2
        is available on CPAN&lt;/a&gt;.
      A list of my Marpa tutorials can be found
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        here&lt;/a&gt;.
      There are
      new tutorials by
      &lt;a href=&quot;http://marpa-guide.github.io/chapter1.html&quot;&gt;Peter Stuifzand&lt;/a&gt;
      and
      &lt;a href=&quot;http://longanswers.blogspot.de/2013/06/transforming-syntax.html&quot;&gt;amon&lt;/a&gt;.
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
        The Ocean of Awareness blog&lt;/a&gt;
      focuses on Marpa,
      and it has
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html&quot;&gt;an annotated guide&lt;/a&gt;.
      Marpa also has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page&lt;/a&gt;.
      For questions, support and discussion, there is
      &lt;a href=&quot;http://groups.google.com/group/marpa-parser&quot;&gt;
        the &quot;marpa parser&quot;
        Google Group.&lt;/a&gt;
      Comments on this post can be made there.
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>Parsing Ada Lovelace</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/07/lovelace.html</link>
    <description>  &lt;h3&gt;The application&lt;/h3&gt;&lt;p&gt;&lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      Abstract Syntax Forests (ASF's) are my most recent project.
      I am adding ASF's to my Marpa parser.
      &lt;a href=&quot;http://jeffreykegler.github.io/Marpa-web-site/&quot;&gt;
      Marpa&lt;/a&gt;
      has long supported ambiguous parsing,
      and allowed users to iterate through,
      and examine,
      all the parses of an ambiguous parse.
      This was enough for most applications.
    &lt;/p&gt;
    &lt;p&gt;
      Even applications which avoid ambiguity benefit from better ways to detect
      and locate it.
      And there are applications that require the ability to select among
      and 
      manipulate very large sets of ambiguous parses.
      Prominent among these is Natural Language Processing (NLP).
      This post will introduce an experiment.
    Marpa in fact seems to have some potential for NLP.
    &lt;/p&gt;
    &lt;p&gt;Writing an efficient ASF in not a simple matter.
      The naive implementation is to generate complete set
      of fully expanded abstract
      syntax trees (AST's).
      This approach consumes resources that can become
      exponential in the size of the input.
      Translation: the naive implementation quickly becomes unuseably slow.
      Marpa optimizes
      by aggressively identifying identical subtrees 
      of the AST's.
      Especially in highly ambiguous parses,
      many subtrees are identical,
      and this optimization is often a big win.
    &lt;/p&gt;
    &lt;h3&gt;Ada Lovelace&lt;/h3&gt;
    &lt;p&gt;
      My primary NLP example at this point
      is a quote from Ada Lovelace.
      It is a long sentence, possibly the longest, from her
      &lt;a href=&quot;http://www.fourmilab.ch/babbage/sketch.html&quot;&gt;
      Notes&lt;/a&gt; -- 158 words.
      A disadvantage of this example is that it is not typical 
      of normal NLP.
      By modern standards it is an unusually long and complex sentence.
      An advantage of it,
      and my reason for the choice,
      is that it stresses the parser.
    &lt;/p&gt;
    &lt;p&gt;
      The &quot;Note A&quot; from which this sentence is taken is
      one of Ada's notes on a translation of a paper
      on the work of her mentor and colleague, Charles Babbage.
      Ada's &quot;Notes&quot; are longer than the original paper,
      and far more important.
      In these &quot;Notes&quot; Ada makes
      the first distinction
      between a computer and a calculator,
      and between software and hardware.
      In their collaboration,
      Babbage did all of the hardware design,
      and he wrote most of the actual programs in her paper.
      But these two revolutionary ideas,
      and their elaboration, are Ada's.
    &lt;/p&gt;
    &lt;p&gt;
      Why would Babbage
      ignore obvious implications of his
      own invention?
      The answer is that,
      while these implications are obvious to us,
      they simply did not fit into the 1843 view of the world.
      In those days,
      algebra was leading-edge math.
      The ability to manipulate equations was considered
      an extremely advanced form of reason.
      For Babbage and his contemporaries, that sort of ability to reason
      certainly suggested the ability to distinguish between good and evil,
      and this in turn suggested possession of a soul.
      Ada's &quot;Notes&quot; were written 20 years after Mary Shelly,
      while visiting Ada's father in Switzerland,
      wrote
      the novel Frankenstein.
      For Ada's contemporaries,
      announcing that you planned to create a
      machine that composed music, or did
      advanced mathematical reasoning,
      was not very different
      from announcing that you planned
      to assemble a human being in your lab.
    &lt;/p&gt;
    &lt;p&gt;Ada was the daughter of the poet Byron.
      For her, pushing boundaries was a family tradition.
    Babbage was happy to leave these matters to Ada.
      As
      &lt;a href=&quot;http://www.fourmilab.ch/babbage/hpb.html&quot;&gt;Babbage's son put it&lt;/a&gt;,
      his father
    &lt;/p&gt;&lt;blockquote&gt;
      considered
      the Paper by Menabrea, translated with notes by Lady Lovelace,
      published in volume 3 of Taylor's 'Scientific Memoirs,&quot;
      as quite disposing of the mathematical aspect of the invention.
      My business now is not with that.
    &lt;/blockquote&gt;
    &lt;h3&gt;On reading Ada&lt;/h3&gt;
    &lt;p&gt;Ada's notes are worth reading,
    but the modern reader has to be prepared to face 
      several layers of difficulty:
      &lt;ul&gt;
    &lt;li&gt;They are in Victorian English.
      In modern English, a long complex sentence is usually considered a editing failure.
      In Ada's time, following Greek and Roman examples,
      a periodic sentence was considered especially appropriate when making an important point.
      And good literary style and good scientific style were considered one and the same.
      &lt;li&gt;They are mathematical,
      and none of math is of the kind currently studied by programmers.
      &lt;li&gt;Ada has literally no prior literature on software to build on,
      and has to invent her terminology.
      It is almost never the modern terminology, and it can be hard to guess
      how it relates to modern terminology.
      For example, does Ada forsee objects, methods and classes?
        Ada speaks of computing both symbolic results and numeric data,
        and attaching one to the other.
        She clearly understands that the symbolic results can represent operations.
        Ada also clearly understands that numeric data can
        represent not just the numbers themselves,
	but notes, positions in a loom, or computer operations.
        So we have arbitrary data, tagged with symbols that can be both names and operations.
	But are these objects?
      &lt;/li&gt;
      &lt;li&gt;Finally, she associates mathematics with philosophy.
      In her day, this was expected.
        Unfortunately, modern readers now often see that sort of discussion as
        irrelevant, or even as a sign of inability to come to the point.
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;p&gt;
    &lt;/p&gt;&lt;h3&gt;Ada's quote&lt;/h3&gt;
    &lt;blockquote&gt;
      Those who view mathematical science,
      not merely as a vast body of abstract and immutable truths,
      whose intrinsic beauty,
      symmetry and logical completeness,
      when regarded in their connexion together as a whole,
      entitle them to a prominent place in the interest of all profound
      and logical minds,
      but as possessing a yet deeper interest for the human race,
      when it is remembered that this science constitutes the language
      through which alone we can adequately express the great facts of
      the natural world,
      and those unceasing changes of mutual relationship which,
      visibly or invisibly,
      consciously or unconsciously to our immediate physical perceptions,
      are interminably going on in the agencies of the creation we live amidst:
      those who thus think on mathematical truth as the instrument through
      which the weak mind of man can most effectually read his Creator's
      works,
      will regard with especial interest all that can tend to facilitate
      the translation of its principles into explicit practical forms.
    &lt;/blockquote&gt;
    &lt;h3&gt;Ada, the bullet point version&lt;/h3&gt;
    &lt;p&gt;Ada's sentence may look like what happens
    when
      two pickups carrying out-of-date dictionaries to the landfill
      run into
      each other on the way.
      But there is, in fact,
      a good deal of structure and meaning in all those words.
      Let's take it as bullet points:
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;1. Math is awesome just for being itself.&lt;/li&gt;
      &lt;li&gt;2. Math describes and predicts the external world.&lt;/li&gt;
      &lt;li&gt;3. Math is the best way to get at
      what it is that is really behind existence.&lt;/li&gt;
      &lt;li&gt;4. If we can do more and better math, that has to be a good thing.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;p&gt;
      Ada is connecting her new science of software to
      the history of thought in the West,
      something which readers of the time would expect her to do.
      Bullet point 1 alludes to the Greek view of mathematics,
      especially Plato's.
      Bullet point 2 alludes to the scientific view, as pioneered by
      Galileo and Newton.
      Bullet point 3 alludes to the post-Classical world view,
      especially the Christian one.
      But while the language is Christian, Ada's idea is one that Einstein
      would have had no trouble with.
      And bullet 4 is the call to action.
    &lt;/p&gt;
    &lt;p&gt;
      When we come to discuss the parse in detail,
      we'll see that it follows this structure.
      As an aside,
      note Ada's mention of &quot;logical completeness&quot; as one of the virtues of math.
      G&amp;ouml;del came along nearly a century later and showed this vision,
      which went back to the Greeks, was an illusion.
      So Ada did not predict everything.
      On the other hand,
      G&amp;ouml;del's result was also a complete surprise to Johnny von Neumann,
      who was in the room that day.
    &lt;/p&gt;
    &lt;h3&gt;The experiment so far&lt;/h3&gt;
    &lt;p&gt;I've gotten Marpa to grind through this sentence,
    using the same framework as
    &lt;a href=&quot;http://nlp.stanford.edu:8080/parser/&quot;&gt;
    the Stanford NLP demo&lt;/a&gt;.
    That demo, in fact, refuses to even attempt any sentence longer than 70 words,
    so my Ada quote needs to be broken up.
    Even on the smaller pieces,
    the Stanford demo becomes quite slow.
    Marpa, by contrast, grinds through the whole thing quickly.
    The Stanford demo is based on a CYK parser, and presumably is O(n&lt;sup&gt;3&lt;/sup&gt;) -- cubic.
    Marpa seems to be exhibiting linear behavior.
    &lt;p&gt;Promising as this seems for Marpa,
    its first results may not hold up as the experiment gets more realistic.
    So far, I've only given Marpa enough English grammar and vocabulary to parse this one
    sentence.
    That is enough to make the grammar very complex and ambiguous,
    but even so it must be far less complex and ambiguous
    than the one behind the Stanford demo.
    Marpa will never have time worse than O(n&lt;sup&gt;3&lt;/sup&gt;),
    but it's quite possible that if Marpa's grammar were as ambiguous as the Stanford one,
    Marpa would be no faster.
    Marpa, in fact, could turn out to be slower by some linear factor.
    &lt;p&gt;There may never be a final decision based on speed.
    Marpa might turn out to represent one approach, good for certain purposes.
    And, especially when speed is indecisive,
    other abilities can prove more important.
    &lt;h3&gt;To learn more&lt;/h3&gt;
    &lt;p&gt;
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2
        is available on CPAN&lt;/a&gt;.
      A list of my Marpa tutorials can be found
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        here&lt;/a&gt;.
      There are
        new tutorials by
      &lt;a href=&quot;http://marpa-guide.github.io/chapter1.html&quot;&gt;Peter Stuifzand&lt;/a&gt;
      and &lt;a href=&quot;http://longanswers.blogspot.de/2013/06/transforming-syntax.html&quot;&gt;amon&lt;/a&gt;.
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
      The Ocean of Awareness blog&lt;/a&gt;
      focuses on Marpa,
      and it has
      &lt;a href=&quot;http://jeffreykegler.github.io/Ocean-of-Awareness-blog/metapages/annotated.html&quot;&gt;an annotated guide&lt;/a&gt;.
      Marpa also has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page&lt;/a&gt;.
      For questions, support and discussion, there is
      &lt;a href=&quot;http://groups.google.com/group/marpa-parser&quot;&gt;
      the &quot;marpa parser&quot;
      Google Group.&lt;/a&gt;
      Comments on this post can be made there.
    &lt;/p&gt;</description>
  </item>
  </channel>
</rss>
