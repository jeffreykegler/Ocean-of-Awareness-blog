<?xml version="1.0"?>
<!-- name="generator" content="blosxom/2.0" -->
<!DOCTYPE rss PUBLIC "-//Netscape Communications//DTD RSS 0.91//EN" "http://my.netscape.com/publish/formats/rss-0.91.dtd">

<rss version="0.91">
  <channel>
    <title>Ocean of Awareness   </title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog</link>
    <description>Ocean of Awareness.</description>
    <language>en</language>

  <item>
    <title>Smart Whitespace and the Ruby Slippers</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/12/whitespace.html</link>
    <description>  &lt;h3&gt;Scannerless parsing&lt;/h3&gt;
    &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      I've been working,
      (and am quite far along)
      on a &quot;scannerless&quot; Marpa interface.
      That is, the lexer (scanner) is included in the parser.
      One of my working examples is
      the synopsis from
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;
      the main Marpa::R2 POD page&lt;/a&gt;,
      rewritten to do its own lexing:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
    &lt;tt&gt;
:start ::= Expression
Expression ::=
       Number
    || Expression '*' Expression action =&gt; do_multiply
    || Expression '+' Expression action =&gt; do_add
Number ~ digits '.' digits action =&gt; do_literal
Number ~ digits action =&gt; do_literal
digits ~ [\d]+
    &lt;/tt&gt;
      &lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;Here the notation is that of
    &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/iterative.html&quot;&gt;
    my last post&lt;/a&gt;,
    as
    &lt;a href=&quot;https://metacpan.org/module/Marpa::R2::BNF&quot;&gt;
    documented here&lt;/a&gt;.
    New for the scannerless parser is
    &lt;ul&gt;
    &lt;li&gt;
    the &lt;tt&gt;:start&lt;/tt&gt;
    pseudo-symbol, which indicates the start rule
    &lt;li&gt;
    Rules with a tilde (&quot;&lt;tt&gt;~&lt;/tt&gt;&quot;) to separate 
    LHS from RHS: these indicate rules whose
    whitespace is to be left as-is.
    &lt;li&gt;Single-quoted strings, to tell Marpa which
    character to look for.
    &lt;li&gt;Square-bracketed character classes, to
    tell Marpa to look for a class of characters.
    Their interpretation is done by Perl,
    and therefore the allowed classes are exactly those
    accepted by your version of Perl.
    &lt;/ul&gt;
    &lt;p&gt;My recent posts has been tutorial.
    My work on scannerless parsing is well advanced,
    but not quite ready for a tutorial presentation,
    so this post will be conceptual.
    It will discuss an interesting issues that arises in
    scannerless parsing,
    one which Perl 6 also had to solve,
    and which Marpa solves it in a new and different way.
    That issue is whitespace.
    &lt;/p&gt;
    &lt;h3&gt;Dealing with whitespace&lt;/h3&gt;
    &lt;p&gt;For the statements with a declaration operator of &lt;tt&gt;::=&lt;/tt&gt;,
    whitespace is handled automatically by Marpa.
    Valid strings in the above language, are
    &quot;&lt;tt&gt;42*3+7&lt;/tt&gt;&quot;,
    &quot;&lt;tt&gt;42 * 3 + 7&lt;/tt&gt;&quot; and
    &quot;&lt;tt&gt;42 * 3+7&lt;/tt&gt;&quot;,
    all which yield 133 as the answer.
    One trick is to, on one hand, allow whitespace to be optional
    and, on the other hand, recognize that strings like &quot;&lt;tt&gt;42&lt;/tt&gt;&quot;
    must be a single number.
    That is the parser should not recognizer optional whitespace
    between the two digits and decide there are two numbers:
    &quot;&lt;tt&gt;4&lt;/tt&gt;&quot; and 
    &quot;&lt;tt&gt;2&lt;/tt&gt;&quot;.
    &lt;/p&gt;
    &lt;p&gt;
    The Perl 6 project has already taken on scannerless parsing,
    and it can solve problems of this sort using &quot;smart whitespace&quot;.
    Smart whitespace is whitespace which is optional, except between
    word characters.
    Stated another way, smart whitespace is either explicit whitespace,
    or a word boundary.
    (The term &quot;smart whitespace&quot; is mine,
    but the idea is from Perl 6.)
    In the case of &quot;&lt;tt&gt;42&lt;/tt&gt;&quot;,
    &quot;&lt;tt&gt;4&lt;/tt&gt;&quot; and 
    &quot;&lt;tt&gt;2&lt;/tt&gt;&quot; are both word characters, so there is no
    word boundary between them, and therefore no smart whitespace.
    &lt;/p&gt;
    &lt;h3&gt;Code and comments&lt;/h3&gt;
    &lt;p&gt;
      Comments on this post
      can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>Announcing a full release of Marpa::R2</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/announce_r2.html</link>
    <description>  &lt;h3&gt;Announcing Marpa::R2&lt;/h3&gt;
    &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
    &lt;p&gt;
      &lt;a href=&quot;https://metacpan.org/release/Marpa-R2&quot;&gt;
        Marpa::R2&lt;/a&gt;
      is now in full, official release.
      For those new to this blog, Marpa::R2 is an efficient, practical general
      BNF parser, targeted at applications too complex for
      regular expressions.
      Marpa::R2 is based on
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;
        the Marpa parsing algorithm&lt;/a&gt;.
      New, but squarely based on the published literature,
      the Marpa algorithm
      parses every class of grammar in practical use today
      in linear time.
    &lt;/p&gt;
    &lt;p&gt;Marpa::R2 is the successor to Marpa::XS and
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;installs and runs on Windows.
        &lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;has better error reporting.
        &lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;is faster.
        &lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;
          has a cleaner, simpler interface.
        &lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;p&gt;
    &lt;a href=&quot;https://metacpan.org/module/Marpa::XS&quot;&gt;Marpa::XS&lt;/a&gt;
    remains available and,
      since changes to it are now on a &quot;bug fix only&quot; basis,
      should be quite stable.
      While Marpa::R2's interface will have a familiar look
      to users of Marpa::XS, it is not fully compatible:
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2::Changes&quot;&gt;
      changes are documented here&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      Those who have been following this blog may have noticed
      that
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2::Changes&quot;&gt;
      a new BNF interface&lt;/a&gt;
      has been added to Marpa::R2.
      This is growing --
      I am currently adding scannerless parsing to it,
      which means that applications will be able to run
      Marpa::R2 without a lexer.
      Because the BNF interface is new
      and still under very active development,
      it is being kept in beta status for the time being.
    &lt;/p&gt;
    &lt;h3&gt;Comments&lt;/h3&gt;
    &lt;p&gt;
      The Windows port of Marpa was the work of Jean-Damien Durand,
      who utilized Alberto Sim&amp;otilde;es'
      &lt;a href=&quot;http://search.cpan.org/dist/Config-AutoConf/&quot;&gt;
        Config::AutoConf&lt;/a&gt;.
      Comments on this post
      can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>A Marpa tutorial: iterative parser development</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/iterative.html</link>
    <description>  &lt;h3&gt;Developing a parser iteratively&lt;/h3&gt;
    &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      This post describes a manageable way
      to write a complex parser,
      a little bit at a time, testing as you go.
      This tutorial will &quot;iterate&quot; a parser
      through one development step.
      As the first iteration step,
      we will use the example parser from
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html&quot;&gt;
        the previous tutorial in this series&lt;/a&gt;,
      which parsed a Perl subset.
    &lt;/p&gt;
    &lt;p&gt;
      You may recall that the topic of that previous tutorial was pattern search.
      Pattern search and iterative parser development are
      essentially the same thing,
      and the same approach can be used for both.
      Each development stage of our Perl parser will do a pattern search
      for the Perl subset it parses.
      We can use the accuracy of this pattern search
      to check our progress.
      The subset we are attempting to parse is our &quot;search target&quot;.
      When our &quot;searches&quot; succeed in finding all instances
      of the target,
      we have successfully written a parser for that subset,
      and can move on to the next step of the iteration.
    &lt;/p&gt;
    &lt;h3&gt;What we need to do&lt;/h3&gt;
    &lt;p&gt;
      This tutorial is the latest of
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/metapages/annotated.html#TUTORIAL&quot;&gt;
        a series&lt;/a&gt;,
      each of which describes one self-contained example of a Marpa-based parser.
      In this tutorial we use the example from
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html&quot;&gt;
        the previous tutorial&lt;/a&gt;
      as the first iteration step
      in the iterative development of a Perl parser.
      For the iteration step in this example, we will add two features.
    &lt;/p&gt;&lt;ul&gt;
      &lt;li&gt;&lt;p&gt;The previous iteration step was more of a recognizer than a parser.
          In particular, its grammar was too simplified to support a semantics,
          even for the Perl subset it recognized.
          We will fix that.
        &lt;/p&gt;&lt;/li&gt;&lt;li&gt;Having amplified the grammar, we will add a semantics,
        simple, but quite powerful enough to use in checking our progress
        in developing the parser.
      &lt;/li&gt;&lt;/ul&gt;
    &lt;h3&gt;The grammar&lt;/h3&gt;
    &lt;p&gt;
    Here is our grammar from the previous post:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
    &lt;tt&gt;
start ::= prefix target
prefix ::= any_token*
target ::= expression
expression ::=
       number | scalar | scalar postfix_op
    || op_lparen expression op_rparen assoc =&amp;gt; group
    || unop expression
    || expression binop expression
    &lt;/tt&gt;
    &lt;/pre&gt;
    &lt;/blockquote&gt;&lt;p&gt;
    &lt;a href=&quot;https://metacpan.org/module/Marpa::R2::BNF&quot;&gt;
      The format is documented here&lt;/a&gt;.
      These eight lines were enough to descibe arithmetic expressions sufficiently well
      for a recognizer, as well as to provide the &quot;scaffolding&quot; for the unanchored search.
      Nice compression, but now that we are talking about supporting a Perl semantics,
      we will need more.
    &lt;/p&gt;&lt;p&gt;Adding the appropriate grammar is a matter of turning to the
      &lt;a href=&quot;http://perldoc.perl.org/perlop.html#Operator-Precedence-and-Associativity&quot;&gt;
        appropriate section of the
        &lt;tt&gt;perlop&lt;/tt&gt;
        man page&lt;/a&gt;
      and copying it.
      I needed to change the format and name the operators,
      but the process was pretty much rote, as you can see:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
    &lt;tt&gt;
my $perl_grammar = Marpa::R2::Grammar-&amp;gt;new(
    {   start          =&amp;gt; 'start',
        actions        =&amp;gt; 'main',
        default_action =&amp;gt; 'do_what_I_mean',
        rules          =&amp;gt; [ &amp;lt;&amp;lt;'END_OF_RULES' ]
start ::= prefix target action =&amp;gt; do_arg1
prefix ::= any_token* action =&amp;gt; do_undef
target ::= expression action =&amp;gt; do_target
expression ::=
     number
   | scalar
   | op_lparen expression op_rparen assoc =&amp;gt; group
  || op_predecrement expression
   | op_preincrement expression
   | expression op_postincrement
   | expression op_postdecrement
  || expression op_starstar expression assoc =&amp;gt; right
  || op_uminus expression
   | op_uplus expression
   | op_bang expression
   | op_tilde expression
  || expression op_star expression
   | expression op_slash expression
   | expression op_percent expression
   | expression kw_x expression
  || expression op_plus expression
   | expression op_minus expression
  || expression op_ltlt expression
   | expression op_gtgt expression
  || expression op_ampersand expression
  || expression op_vbar expression
   | expression op_caret expression
  || expression op_equal expression assoc =&amp;gt; right
  || expression op_comma expression
END_OF_RULES
    }
);
    &lt;/tt&gt;
    &lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;The lexer&lt;/h3&gt;
    &lt;p&gt;
      The lexer is table-driven.
      I've used this same approach to lexing in every post
      in this tutorial series.
      Those interested in
      an explanation of how the lexer works can
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html&quot;&gt;
        find one in the first tutorial&lt;/a&gt;.
      Having broken out the operators, I had to rewrite
      the lexing table,
      but that was even more rote than rewriting
      the grammar.
      I won't repeat the
      lexer table here --
      it can be found in
      &lt;a href=&quot;https://gist.github.com/4093504&quot;&gt;the Github gist&lt;/a&gt;.
    &lt;/p&gt;
    &lt;h3&gt;Adding the semantics&lt;/h3&gt;
    &lt;p&gt;Our semantics will create a syntax tree.
      Here is that logic.
      (Note that the first argument to these semantic closures
      is a per-parse &quot;object&quot;,
      which we don't use here.)
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
    &lt;tt&gt;
sub do_undef       { undef; }
sub do_arg1        { $_[2]; }
sub do_what_I_mean { shift; return $_[0] if scalar @_ == 1; return \@_ }

sub do_target {
    my $origin = ( Marpa::R2::Context::location() )[0];
    return if $origin != $ORIGIN;
    return $_[1];
} ## end sub do_target
    &lt;/tt&gt;
    &lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      There is some special logic in the
      &lt;tt&gt;do_target()&lt;/tt&gt;
      method,
      involving the &quot;origin&quot;, or starting location of the target.
      Perl arithmetic expressions,
      when they are the target of an unanchored search,
      are ambiguous.
      For example, in the string &quot;&lt;tt&gt;abc 1 + 2 + 3 xyz&lt;/tt&gt;&quot;,
      there are two targets ending at the same position:
      &quot;&lt;tt&gt;2 + 3&lt;/tt&gt;&quot; and &quot;&lt;tt&gt;1 + 2 + 3&lt;/tt&gt;&quot;.
      We are interested only in longest of these,
      whose start location is indicated by the
      &lt;tt&gt;$ORIGIN&lt;/tt&gt;
      variable.
    &lt;/p&gt;&lt;p&gt;The next logic will be familiar from our
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html&quot;&gt;
        pattern search tutorial&lt;/a&gt;.
      It repeatedly looks for non-overlapping occurrences of
      &lt;tt&gt;target&lt;/tt&gt;,
      starting from the end and going back to the beginning of the input.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
    &lt;tt&gt;
my $end_of_search;
my @results = ();
RESULTS: while (1) {
    my ( $origin, $end ) =
        $self-&amp;gt;last_completed_range( 'target', $end_of_search );
    last RESULTS if not defined $origin;
    push @results, [ $origin, $end ];
    $end_of_search = $origin;
} ## end RESULTS: while (1)
    &lt;/tt&gt;
    &lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;This final code sample is the logic
      that unites pattern search with incremental
      parsing.
      It is a loop through
      &lt;tt&gt;@results&lt;/tt&gt;
      that prints the original text
      and, depending on a flag,
      its syntax tree.
    &lt;/p&gt;
    &lt;p&gt;
      Near the top of the loop,
      the &quot;&lt;tt&gt;$recce-&amp;gt;set( { end =&amp;gt; $end } )&lt;/tt&gt;&quot;
      call sets the end of parse location to the current
      result.
      At the bottom of the loop,
      we call
      &quot;&lt;tt&gt;$recce-&amp;gt;reset_evaluation()&lt;/tt&gt;&quot;.
      This is necessary to allow us to evaluate the
      input stream again, but with a new
      &lt;tt&gt;$end&lt;/tt&gt;
      location.
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
    &lt;tt&gt;
RESULT: for my $result ( reverse @results ) {
    my ( $origin, $end ) = @{$result};

    &lt;big&gt;&lt;b&gt;... Print out the original text ...&lt;/b&gt;&lt;/big&gt;

    $recce-&amp;gt;set( { end =&amp;gt; $end } );
    my $value;
    VALUE: while ( not defined $value ) {
        local $main::ORIGIN = $origin;
        my $value_ref = $recce-&amp;gt;value();
        last VALUE if not defined $value_ref;
        $value = ${$value_ref};
    } ## end VALUE: while ( not defined $value )
    if ( not defined $value ) {
        say 'No parse'
            or die &quot;say() failed: $ERRNO&quot;;
        next RESULT;
    }
    say Data::Dumper::Dumper($value)
        or die &quot;say() failed: $ERRNO&quot;
        if not $quiet_flag;
    $recce-&amp;gt;reset_evaluation();
} ## end RESULT: for my $result ( reverse @results )
    &lt;/tt&gt;
    &lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;The
      &lt;tt&gt;VALUE&lt;/tt&gt;
      sub-loop is
      where the
      &lt;tt&gt;$ORIGIN&lt;/tt&gt;
      variable
      was set.
      In the semantics,
      &lt;tt&gt;do_target()&lt;/tt&gt;
      checks this.
      In the case of an ambiguous parse,
      &lt;tt&gt;do_target()&lt;/tt&gt;
      turns any target which does not
      cover the full span from
      &lt;tt&gt;$origin&lt;/tt&gt;
      to
      &lt;tt&gt;$end&lt;/tt&gt;
      into a Perl
      &lt;tt&gt;undef&lt;/tt&gt;,
      which will
      eventually become
      the value of its parse.
      The logic in the
      &lt;tt&gt;VALUE&lt;/tt&gt;
      loop
      ignores parses whose value is a Perl &lt;tt&gt;undef&lt;/tt&gt;,
      so that only the longest target for each
      &lt;tt&gt;$end&lt;/tt&gt;
      location is printed.
    &lt;/p&gt;
    &lt;h3&gt;Code and comments&lt;/h3&gt;
    &lt;p&gt;The example in this post is available as
      &lt;a href=&quot;https://gist.github.com/4093504&quot;&gt;a Github gist&lt;/a&gt;.
      It was run with
      &lt;a href=&quot;https://metacpan.org/release/JKEGL/Marpa-R2-2.024000/&quot;&gt;
        Marpa::R2 2.024000&lt;/a&gt;,
      as of this writing the latest full release.
      Its main test, which is included in the gist,
      used displays from the
      &lt;a href=&quot;http://perldoc.perl.org/perlop.html&quot;&gt;perlop man page&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      Comments on this post
      can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>A Marpa tutorial: pattern searches</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/11/pattern_search.html</link>
    <description>  &lt;h3&gt;Pattern searches&lt;/h3&gt;
    &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      We use regular expressions for pattern searching these days.
      But what if your search target is not a regular expression?
      In this post I will show how to use Marpa to search text files for
      arbitrary context-free expressions.
    &lt;/p&gt;
    &lt;p&gt;
      This tutorial builds on earlier tutorials.
      It is possible to simply dive into it,
      but it may be easier
      to start with two of my earlier posts,
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html&quot;&gt;here&lt;/a&gt;
      and
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html&quot;&gt;here&lt;/a&gt;.
    &lt;/p&gt;
    &lt;h3&gt;The grammar&lt;/h3&gt;
    &lt;p&gt;
      I will use arithmetic expressions as
      the example of a search target.
      Even the arithmetic subset of Perl expressions is quite complex,
      but in this case we can get the job done
      with eight lines of grammar and a lexer driven
      by a table of just over a dozen lines.
      Here is the grammar:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
    &lt;tt&gt;
start ::= prefix target
prefix ::= any_token*
target ::= expression
expression ::=
       number | scalar | scalar postfix_op
    || op_lparen expression op_rparen assoc =&amp;gt; group
    || unop expression
    || expression binop expression`
    &lt;/tt&gt;
    &lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      This grammar uses
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2::BNF&quot;&gt;
        Marpa::R2's BNF interface&lt;/a&gt;.
      It takes considerable advantage of the fact that we are not
      &lt;b&gt;parsing&lt;/b&gt;
      these expressions, but
      &lt;b&gt;recognizing&lt;/b&gt;
      them.
      Because of this, we don't have to specify whether expressions left- or right-associate.
      We can also ignore what operators mean and group them according to syntax only
      -- binary, prefix unary and postfix unary.
      Similarly, we can ignore the precedence within these large groups.
      This leaves us with numbers, scalars,
      parentheses,
      and binary, prefix unary and postfix unary operators.
      (To keep this example simple, we restrict the primaries
      to numeric constants and Perl scalars.)
    &lt;/p&gt;
    &lt;p&gt;
      What we are searching for is defined by the
      &lt;tt&gt;target&lt;/tt&gt;
      symbol.
      For
      &lt;tt&gt;target&lt;/tt&gt;
      you could substitute
      the start symbol of
      any context-free grammar,
      and the structure of this example will still work.
      To turn a parser for
      &lt;tt&gt;target&lt;/tt&gt;
      into a pattern searcher, we add a new start
      symbol (unimaginatively named &quot;&lt;tt&gt;start&lt;/tt&gt;&quot;)
      and two rules that
      allow the target to have a
      &lt;tt&gt;prefix&lt;/tt&gt;.
    &lt;/p&gt;
    &lt;h3&gt;Ambiguous parsing&lt;/h3&gt;
    &lt;p&gt;To do an anchorless pattern search,
      this example will use ambiguous parsing.
      This grammar always has at least one parse going,
      representing the prefix for
      the zero or more targets
      that our parser
      expects to find in the future.
      The prefix will never end, because
      any token (as indicated by a token
      named, literally,
      &lt;tt&gt;any_token&lt;/tt&gt;)
      extends it.
    &lt;/p&gt;
    &lt;p&gt;
      If we are in the process of recognizing a
      &lt;tt&gt;target&lt;/tt&gt;,
      we will have one or more other parses going.
      I say &quot;one or more&quot; because the search method
      described in this post
      allows &lt;tt&gt;target&lt;/tt&gt; to be ambiguous.
      But arithmetic expressions,
      the target pattern used in this example,
      are not ambiguous.
      So our example will have
      at most two parses active at any point:
      one for the prefix and another for the target.
    &lt;/p&gt;
    &lt;p&gt;
      Ambiguous parsing has a serious potential downside --
      it is not necessarily linear
      and therefore not necessarily efficient.
      But Marpa can parse many classes of ambiguous grammar in linear time.
      Grammars like the one in this post --
      a prefix and an unambiguous search target --
      fall into one of the linearly parseable classes.
      Keeping the prefix going requires a tiny constant overhead per token.
    &lt;/p&gt;
    &lt;h3&gt;The lexer table&lt;/h3&gt;
    &lt;p&gt;
      The lexer is driven by a table of pairs: token name and regex.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
&lt;tt&gt;
my @lexer_table = (
    [ number     =&amp;gt; qr/(?:\d+(?:\.\d*)?|\.\d+)/xms ],
    [ scalar     =&amp;gt; qr/ [\$] \w+ \b/xms ],
    [ postfix_op =&amp;gt; qr/ [-][-] | [+][+] /xms ],
    [ unop       =&amp;gt; qr/ [-][-] | [+][+] /xms ],
    [   binop =&amp;gt; qr/
          [*][*] | [&amp;gt;][&amp;gt;] | [&amp;lt;][&amp;lt;]
        | [*] | [\/] | [%] | [x] \b
        | [+] | [-] | [&amp;amp;] | [|] | [=] | [,]
    /xms
    ],
    [   unop =&amp;gt; qr/ [-] | [+] | [!] | [~] /xms
    ],
    [ op_lparen =&amp;gt; qr/[(]/xms ],
    [ op_rparen =&amp;gt; qr/[)]/xms ],
);
&lt;/tt&gt;
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      Order is significant here.
      In particular
      two-character operators are checked for first.
      This guarantees that
      two consecutive minus signs
      will be seen as an
      decrement operator, and not as a double negation.
    &lt;/p&gt;
    &lt;h3&gt;Ambiguous lexing&lt;/h3&gt;
    &lt;p&gt;The very careful reader may have noticed that
      &lt;tt&gt;any_token&lt;/tt&gt;
      is not in the lexing table.
      The main loop is written so that every token is read as an
      &lt;tt&gt;any_token&lt;/tt&gt;.
      If no token from the lexing table is accepted,
      the next character in the input stream
      is read as an
      &lt;tt&gt;any_token&lt;/tt&gt;.
      If a token from the lexing table
      &lt;b&gt;is&lt;/b&gt;
      accepted,
      then it gets read twice,
      once as an
      &lt;tt&gt;any_token&lt;/tt&gt;,
      and once as the token type taken from the lexing table
      entry.
    &lt;/p&gt;
    &lt;p&gt;Ambiguous lexing is a familiar technique to
      the Natural Language Processing community.
      Engish, in particular, is a language that abounds
      in lexemes that can play multiple roles.
      The word &quot;sort&quot;, for example, can easily be
      an noun, a verb or an adjective.
    &lt;/p&gt;
    &lt;h3&gt;The Ruby Slippers&lt;/h3&gt;
    &lt;p&gt;The main loop will also be a simple case of the use
      of the Ruby Slippers.
      For those unfamiliar,
      the &quot;Ruby Slippers&quot; parsing technique handles difficult lexing
      and parsing problems by asking the parser, at the problem point,
      what it is looking for,
      and providing it.
      This seems a fairly obvious approach,
      but the Ruby Slippers are new with Marpa --
      traditional parsers could not easily
      determine where they were in a parse.
    &lt;/p&gt;
    &lt;p&gt;
      One way to use the Ruby Slippers is to ask the parser in
      advance what it is looking for.
      The code that follows uses another method.
      Instead of determining in advance what tokens to read,
      it simply feeds tokens to the parser.
    &lt;/p&gt;
    &lt;p&gt;
      Token rejection is a &quot;soft&quot; error -- it costs
      little to try, and little to retry.
      The following code can
      efficiently determine which entry in the lexing table is appropriate,
      simply by trying each of them in order.
      If the
      &lt;tt&gt;alternative()&lt;/tt&gt;
      method returns a Perl
      &lt;tt&gt;undef&lt;/tt&gt;,
      indicating that a token was rejected,
      then the main loop will try later entries in the lexing table.
    &lt;/p&gt;
    &lt;p&gt;
      When a token is accepted,
      the main loop can safely assume that it is on the right track.
      Marpa is 100% accurate about
      which tokens can and cannot result in a successful parse.
    &lt;/p&gt;
    &lt;h3&gt;The main loop&lt;/h3&gt;
    &lt;p&gt;
      The main loop iterates through input looking for tokens.
      Whitespace is skipped.
      Comments are not skipped.
      Finding arithmetic expressions in
      strings and/or comments can be useful.
      We will assume that is the case here.
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
&lt;tt&gt;
my $length = length $string;
pos $string = $positions[-1];
TOKEN: while ( pos $string &amp;lt; $length ) {
    next TOKEN if $string =~ m/\G\s+/gcxms;    # skip whitespace
    my $position = pos $string;
    FIND_ALTERNATIVE: {
        TOKEN_TYPE: for my $t (@lexer_table) {
            my ( $token_name, $regex ) = @{$t};
            next TOKEN_TYPE if not $string =~ m/\G($regex)/gcxms;
            if ( not defined $recce-&amp;gt;alternative($token_name) ) {
                pos $string = $position;       # reset position for matching
                next TOKEN_TYPE;
            }
            $recce-&amp;gt;alternative('any_token');
            last FIND_ALTERNATIVE;
        } ## end TOKEN_TYPE: for my $t (@lexer_table)
        ## Nothing in the lexer table matched
        ## Just read the currrent character as an 'any_token'
        pos $string = $position + 1;
        $recce-&amp;gt;alternative('any_token');
    } ## end FIND_ALTERNATIVE:
    $recce-&amp;gt;earleme_complete();
    my $latest_earley_set_ID = $recce-&amp;gt;latest_earley_set();
    $positions[$latest_earley_set_ID] = pos $string;
} ## end TOKEN: while ( pos $string &amp;lt; $length )
&lt;/tt&gt;
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
      The
      &lt;tt&gt;earleme_complete()&lt;/tt&gt;
      method tells Marpa that all the alternatives
      at one location have been entered,
      and that the parse should now move on to the next location.
      (Marpa's idea of location is called an &quot;earleme&quot;, in honor of the great
      parsing theorist, Jay Earley.)
    &lt;/p&gt;
    &lt;h3&gt;How to parse without really trying&lt;/h3&gt;
    &lt;p&gt;
    At this point, I want to draw the reader's attention to the code
    that deals with special cases for the minus sign.
    Specifically, to the fact that there is no such code.
    The more familiar you are with PPI and/or
      &lt;tt&gt;perly.y&lt;/tt&gt;,
      the more remarkable this will seem.
      &lt;/p&gt;
      &lt;p&gt;
      To take one example, PPI correctly realizes that the minus
      sign in
      &quot;&lt;tt&gt;1+2-3&lt;/tt&gt;&quot; is a binary operator.
      However PPI fails on &quot;&lt;tt&gt;(1+2)-3&lt;/tt&gt;&quot; --
      it thinks the minus sign is part of the number &quot;-3&quot;.
      Why don't the authors of PPI just look at the Perl
      interpreter and copy the logic there?
      Take a glance at &lt;tt&gt;perly.y&lt;/tt&gt;
      and &lt;tt&gt;toke.c&lt;/tt&gt; 
      and you will know the answer to that question.
      &lt;/p&gt;
      &lt;p&gt;What is PPI's problem here?
      The problem is that,
      without knowing where you are in the expression,
      you cannot tell whether a minus sign is a unary
      operator or a binary operator.
      And the parse engines for PPI and for Perl itself,
      while quite different in many respects,
      share a property common to traditional parsers --
      in determining context
      they offer the lexer, respectively,
      little and no help.
      &lt;/p&gt;
      &lt;p&gt;
      In the code in this example,
      Marpa's &lt;tt&gt;alternative()&lt;/tt&gt; method is, by accepting
      and rejecting tokens, guiding the lexer to the right choice.
      Because of Perl's grammar, a minus sign at a given position
      cannot be both a unary operator and a binary operator.
      And Marpa is 100% accurate in its knowledge of which
      tokens are possible.
      So Marpa's
      &lt;tt&gt;alternative()&lt;/tt&gt; method
      always knows whether a minus sign can be
      a unary or binary operator and accepts
      or rejects the token accordingly.
    &lt;/p&gt;
    &lt;p&gt;
      This is the Ruby Slippers in action --
      a very simple solution to what for the Perl
      interpreter and PPI
      is a very complicated problem.
      When I developed the Ruby Slippers technique,
      my most serious problem 
      was convincing myself that something
      so simple could really work.
    &lt;/p&gt;
    &lt;h3&gt;Finding the targets&lt;/h3&gt;
    &lt;p&gt;
      Once the parse is complete, it remains to find
      and print the &quot;targets&quot; found
      by the search.
      In
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html&quot;&gt;
      a previous post&lt;/a&gt;,
      I showed how, 
      given a symbol name,
      to find the last occurrence of the symbol in a Marpa parse.
      That routine needed to be modified to allow repeated searches,
      but the change was straightforward.
      The code is in the
      &lt;a href=&quot;https://gist.github.com/4057239&quot;&gt;
      gist&lt;/a&gt;,
      and the ideas behind it were explained
      in
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/error.html&quot;&gt;
      the previous post&lt;/a&gt;,
      so I won't repeat them here.
    &lt;/p&gt;
    &lt;h3&gt;Code and comments&lt;/h3&gt;
    &lt;p&gt;The example in this post is available as
    &lt;a href=&quot;https://gist.github.com/4057239&quot;&gt;
      a Github gist&lt;/a&gt;.
      It was run with
      &lt;a href=&quot;https://metacpan.org/release/JKEGL/Marpa-R2-2.024000/&quot;&gt;
      Marpa::R2 2.024000&lt;/a&gt;,
      as of this writing the latest full release.
      My main test, which is included in the gist,
      used displays from the
      &lt;a href=&quot;http://perldoc.perl.org/perlop.html&quot;&gt;perlop man page&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      Comments on this post
      can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>A grammar that exemplifies, describes and parses itself</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/self_parse.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      I've written a grammar in Marpa's new BNF interface,
      to parse Marpa's new BNF interface.
      In the 70's, when I learned parsing theory,
      this was a very fashionable thing to do, perhaps because
      yacc had done it,
      in Appendix B of
      &lt;a href=&quot;http://dinosaur.compilertools.net/yacc/&quot;&gt;
        the original 1975 paper&lt;/a&gt;.
      By 1979, Hoftstadter's book Godel-Escher-Bach (GEB) was out,
      and the next year it took the Pulitzer for
      General Nonfiction.
      Self-description, recursion, self-reference, self-embedding,
      you
      (preferably
      &lt;a href=&quot;http://en.wikipedia.org/wiki/Autological_word&quot;&gt;autologically&lt;/a&gt;)
      name it,
      these things were all the rage.
    &lt;/p&gt;
    &lt;p&gt;Reading code
    that is at once both self-example and self-description
    still holds a certain magic for me.
      Regular expressions cannot describe themselves.
      Recursive descent parsers are hand-written
      in another general-purpose language,
      so there can be no concise self-description.
      Ironically, yacc actually cannot parse its own description language.
      (&quot;Ironically&quot; is the word used in the paper.)
      Like almost all useful grammars, yacc's description language
      goes beyond the capabilities of yacc's LALR parser,
      and a lexer hack is needed to make the code in Appendix B work.
    &lt;/p&gt;
    &lt;p&gt;Marpa is a general BNF parser and requires no special hacks
    to parse the following efficiently:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
rules ::= rule+ action =&gt; do_rules
rule ::= empty_rule | priority_rule | quantified_rule
priority_rule ::= lhs op_declare priorities
  action =&gt; do_priority_rule
empty_rule ::= lhs op_declare adverb_list
  action =&gt; do_empty_rule
quantified_rule ::= lhs op_declare name quantifier adverb_list
    action =&gt; do_quantified_rule
priorities ::= alternatives+
    separator =&gt; op_tighter proper =&gt; 1
    action =&gt; do_discard_separators
alternatives ::= alternative+
    separator =&gt; op_eq_pri proper =&gt; 1
    action =&gt; do_discard_separators
alternative ::= rhs adverb_list action =&gt; do_alternative
adverb_list ::= adverb_item* action =&gt; do_adverb_list
adverb_item ::=
      action
    | left_association | right_association | group_association
    | separator_specification | proper_specification

action ::= kw_action op_arrow name action =&gt; do_action
left_association ::= kw_assoc op_arrow kw_left
  action =&gt; do_left_association
right_association ::= kw_assoc op_arrow kw_right
  action =&gt; do_right_association
group_association ::= kw_assoc op_arrow kw_group
  action =&gt; do_group_association
separator_specification ::= kw_separator op_arrow name
  action =&gt; do_separator_specification
proper_specification ::= kw_proper op_arrow boolean
action =&gt; do_proper_specification

lhs ::= name action =&gt; do_lhs
rhs ::= names
quantifier ::= op_star | op_plus
names ::= name+ action =&gt; do_array
name ::= bare_name | reserved_word | quoted_name
name ::= bracketed_name action =&gt; do_bracketed_name

reserved_word ::= kw_action | kw_assoc | kw_separator | kw_proper
  | kw_left | kw_right | kw_group
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
    The conventions are standard or transparent.
    The &quot;&lt;tt&gt;::=&lt;/tt&gt;&quot; symbol separates the left and right hand sides of rules.
    The &quot;&lt;tt&gt;|&lt;/tt&gt;&quot; symbol separates alternative right hand sides.
    The &quot;&lt;tt&gt;*&lt;/tt&gt;&quot; and
    &quot;&lt;tt&gt;+&lt;/tt&gt;&quot; are quantifiers, similar to those in regular expressions,
    and indicate, respectively, zero or more repetitions and one or more repetitions
    of the preceding symbol.
    Adverbs take the form &quot;&lt;tt&gt;keyword =&gt; value&lt;/tt&gt;&quot;,
    and indicate semantics or the style of sequence separation.
    Full documentation can be found
    &lt;a href=&quot;https://metacpan.org/module/JKEGL/Marpa-R2-2.023_010/pod/BNF.pod&quot;&gt;
    here&lt;/a&gt;.
    &lt;p&gt;
      Self-parsing compiler compilers ruled the earth
      in the age of bellbottoms.
      Self-parsing has lasted better, but not by much.
      When some years I wrote a self-describing language as an interface to
      Marpa, it seemed to confuse people.
      They wondered what Marpa did --
      parsing your own description did not seem to be
      about &lt;b&gt;doing&lt;/b&gt; anything.
      These days my examples feature a lot of calculators.
      (&quot;Ironically&quot;, Hofstadter seems to have had the same problem with
      GEB -- he felt that
      people did not understand what his book was saying --
      even those who liked it.)
    &lt;/p&gt;
    &lt;p&gt;
      But ideas from Larry Wall and Peter Stuifzand
      have re-ignited my interest in self-parsing.
      And this time the self-parsing parser was written
      with a specific purpose.
      I plan to enhance this language.
      I have found that the convenience of this interface
      more than compensates for the circular
      dependency issues.
      The BNF source in this post is
      &lt;a href=&quot;https://metacpan.org/source/JKEGL/Marpa-R2-2.023_010/lib/Marpa/R2/meta/Stuifzand.bnf&quot;&gt;
      the source&lt;/a&gt;
      for its own parser,
      and I plan to use it
      to produce improved versions
      of itself.
    &lt;/p&gt;
    &lt;h3&gt;Comments&lt;/h3&gt;
    &lt;p&gt;
      Comments on this post can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  </channel>
</rss>
