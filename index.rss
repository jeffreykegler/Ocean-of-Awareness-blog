<?xml version="1.0"?>
<!-- name="generator" content="blosxom/2.0" -->
<!DOCTYPE rss PUBLIC "-//Netscape Communications//DTD RSS 0.91//EN" "http://my.netscape.com/publish/formats/rss-0.91.dtd">

<rss version="0.91">
  <channel>
    <title>Ocean of Awareness   </title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog</link>
    <description>Ocean of Awareness.</description>
    <language>en</language>

  <item>
    <title>What if languages were free?</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/03/what_if_free.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
    &lt;/p&gt;
    &lt;p&gt;In 1980, George Copeland wrote an
      article titled &quot;What if Mass Storage were Free?&quot;.
      (It's behind a paywall
      &lt;a href=&quot;http://dl.acm.org/citation.cfm?id=802685&quot;&gt;here&lt;/a&gt;.)
      Costs of mass storage were showing signs
      that they might fall dramatically.
      Copeland, as a thought exercise, took this trend to its extreme.
      Among other things, he predicted that deletion would become
      unnecessary, and in fact, undesirable.
    &lt;/p&gt;
    &lt;p&gt;Copeland's
      thought experiment has proved prophetic.
      For many purposes, mass storage is treated as if it were free.
      For example, you probably retrieved this blog post from a server
      provided to me at no charge, in the hope
      that I might write and upload something interesting.
    &lt;/p&gt;
    &lt;p&gt;
      Until now languages were high-cost efforts.
      Worse, language projects ran a high risk of disappointment,
      up to and including total failure.
      I believe those days are coming to an end.
    &lt;/p&gt;
    &lt;h3&gt;Small languages, shaped to the problem domain&lt;/h3&gt;
    &lt;p&gt;What if whenever you needed a new language, poof, it was there?
      You would be encouraged to solve problems with new languages
      precisely shaped to the problem domain.
      Since each language is no larger than its problem domain,
      learning a language would be essentially the same as learning
      the problem domain.
      The incremental effort required to learn the language
      itself would head toward zero.
    &lt;/p&gt;
    &lt;h3&gt;No more language bloat&lt;/h3&gt;
    &lt;p&gt;Language bloat would end.
      Currently, the risk and cost of developing languages
      make it imperative to extend the ones we have.
      Free languages mean fewer reasons to add features
      to existing languages.
    &lt;/p&gt;
    &lt;h3&gt;No more search for THE perfect language&lt;/h3&gt;
    &lt;p&gt;
      No language is perfect for all tasks.
      But because the cost of languages imposes
      the need to use large, general-purpose languages,
      we are compelled to try for perfection anyway.
      Ironically, we are often making the language worse,
      and we know it.
    &lt;/p&gt;
    &lt;h3&gt;A world full of perfect languages&lt;/h3&gt;
    &lt;p&gt;An older sense of the word perfect is
      &quot;having all the properties or qualities requisite to its nature and kind&quot;.
      The C language might be called perfect in this sense.
      C lacks a lot of features that are highly desirable in most contexts.
      But for programming close to the hardware, but portably,
      the C language is perfect or close to it.
    If languages were free, this is the kind of perfection
      that we would seek --
      languages precisely fitted to their domain,
      so that adding to them cannot make them better.
    &lt;/p&gt;
    &lt;h3&gt;Moving toward free&lt;/h3&gt;
    &lt;p&gt;
      It was many years after I read Copeland before his vision was
      anything but a pleasant daydream.
      But the plummet in the cost of languages is already underway.
      My own effort to contribute to this, the Marpa parser,
      produces a reasonable parser for every language you can write in BNF,
      from the BNF, and without futher effort.
      If the BNF is for a grammar in any of the classes currently in practical
      use, the parser Marpa produces will have linear speed.
    &lt;/p&gt;
    &lt;p&gt;
      In one case, using Marpa,
      &lt;a href=&quot;https://gist.github.com/4447349&quot;&gt;a targeted language&lt;/a&gt;
      was written
      in less than an hour.
      &lt;a href=&quot;http://blogs.perl.org/users/jeffrey_kegler/2013/01/a-language-for-writing-languages.html&quot;&gt;
        More typically&lt;/a&gt;, Marpa reduce the time needed to create new languages to hours.
    &lt;/p&gt;
    &lt;p&gt;As one example of going from &quot;impossible&quot; to &quot;easy&quot;,
      I have written a drop-in solution to an example in the
      &lt;a href=&quot;http://en.wikipedia.org/wiki/Design_Patterns&quot;&gt;Gang
      of Four book&lt;/a&gt;.
      The Gang of Four described a language
      and its interpretation,
      but they did not include a parser.
      Creating a parser
      to fit their example would have been
      impossibly hard when the Gang of Four wrote.
      Using Marpa, it is easy.
      The parser can be found in
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/03/bnf_to_ast.html&quot;&gt;this
        earlier blog post&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      Marpa's latest version is
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2,
        which is available on CPAN&lt;/a&gt;.
      Recently, it has gained immensely in &quot;whipitupitude&quot; with
      &lt;a href=&quot;https://metacpan.org/module/JKEGL/Marpa-R2-2.048000/pod/Scanless/DSL.pod&quot;&gt;
        a new interface&lt;/a&gt;,
      which has tutorials
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/dsl_simpler2.html&quot;&gt;here
      &lt;/a&gt;
      and
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/announce_scanless.html&quot;&gt;
        here&lt;/a&gt;.
      Marpa has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page&lt;/a&gt;,
      and of course it is the focus of
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
        my &quot;Ocean of Awareness&quot; blog&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      Comments on this post
      can be sent to the Marpa's Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>The Interpreter Design Pattern</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/03/interpreter.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
    &lt;/p&gt;
    &lt;p&gt;The influential
      &lt;a href=&quot;http://en.wikipedia.org/wiki/Design_Patterns&quot;&gt;
        &lt;em&gt;Design Patterns&lt;/em&gt;
        book&lt;/a&gt;
      lays out 23 patterns for programming.
      One of them, the Interpreter Pattern, is rarely used.
      Steve Yegge puts it a bit more strikingly -- he says
      that the book contains
      &lt;a href=&quot;https://sites.google.com/site/steveyegge2/ten-great-books&quot;&gt;22
        patterns and a practical joke&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;That sounds (and in fact is) negative, but
      &lt;a href=&quot;http://steve-yegge.blogspot.com/2007/12/codes-worst-enemy.html&quot;&gt;
        elsewhere&lt;/a&gt;
      Yegge says that
      &quot;[t]ragically, the only [Go4] pattern that can help code get smaller
      (Interpreter) is utterly ignored by programmers&quot;.
      (The
      &lt;i&gt;Design Patterns&lt;/i&gt;
      book has four authors,
      and is often called the Gang of Four book, or Go4.)
    &lt;/p&gt;
    &lt;p&gt;
      In fact, under various names and definitions, the
      Interpreter Pattern and its close relatives and/or identical twins
      are widely cited,
      much argued and highly praised&lt;a href=&quot;#NOTE1&quot;&gt;[1]&lt;/a&gt;.
          As they should be.
          Languages are the most powerful and flexible design pattern of all.
          A language can include all, and only, the concepts relevent
          to your domain.
          A language can allow you to relate them in all, and only, the appropriate ways.
          A language can identify errors with pinpoint precision,
          hide implementation details,
          allow invisible &quot;drop-in&quot; enhancements, etc., etc., etc.
        &lt;/p&gt;
    &lt;p&gt;
      In fact languages are so powerful and flexible,
      that their use is pretty much universal.
      The choice is not whether or not to use a language to solve
      the problem,
      but whether to use
      a general-purpose language,
      or a domain-specific language.
      Put another way,
      if you decide not to use a language targeted
      to your domain,
      it almost always means that you
      are choosing to use another language that is not specifically
      fitted to your domain.
    &lt;/p&gt;
    &lt;p&gt;
      Why then, is the Interpreter Pattern so little used?
      Why does Yegge call it a practical joke?
    &lt;/p&gt;
    &lt;h3&gt;There's a problem&lt;/h3&gt;
    &lt;p&gt;The problem with the Interpreter Pattern is that you must
      turn your language into an AST --
      that is,
      you must parse it somehow.
      Simplifying the language can help here.
      But if the point is to be simple at the expense of power
      and flexibility,
      you might as well
      stick with the other 22 design patterns.
    &lt;/p&gt;
    &lt;p&gt;
      On the other hand,
      creating a parser for anything but the simplest languages
      has been a time-consuming effort,
      and one of a kind known for disappointing results.
      In fact,
      language development efforts run
      a real risk of total failure.
    &lt;/p&gt;
    &lt;p&gt;How did the Go4 deal with this?
      They defined the problem away.
      They stated that the parsing issue was separate from the
      Interpreter Pattern, which was limited to what you did with the AST
      once you'd somehow come up with one.
    &lt;/p&gt;
    &lt;p&gt;
      But AST's don't (so to speak) grow on trees.
      You have to get one from somewhere.
      In their example, the Go4 simply built an AST in their code,
      node by node.
      In doing this, they bypassed the BNF and the problem of parsing.
      But they also bypassed their language and the whole point
      of the Interpreter Pattern.
    &lt;/p&gt;
    &lt;p&gt;
      Which is why Yegge characterized the chapter as a practical joke.
      And why other programming techniques and patterns are almost
      always preferred to the Interpreter Pattern.
    &lt;/p&gt;
    &lt;h3&gt;Finding that one missing piece&lt;/h3&gt;
    &lt;p&gt;So that's how the Go4 left things.
      A potentially great programming technique,
      made almost useless because
      of a missing piece.
      There was no easy, general, and practical way to generate AST's.
    &lt;/p&gt;
    &lt;p&gt;
      Few expected that to change.
      I was more optimistic than most.
      In 2007 I embarked on a full-time project:
      to create a parser based on Earley's algorithm.
      I was sure that it would fulfill two of the criteria --
      it would be easy to use, and it would be general.
      As for practical -- well, a lot of parsing problems
      are small, and a lot of applications don't require a lot
      of speed, and for these I expected the result to be good enough.
    &lt;/p&gt;
    &lt;p&gt;What I didn't realize was that
      all of the problems preventing
      Earley's from seeing real, practical use
      has already been solved in the academic literature.
      I was not alone in not having put the picture together.
      The people who had solved the problems
      had focused on two disjoint sets of issues,
      and were unaware of each other's
      work.
      In 1991, in the Netherlands,
      the mathematican Joop Leo had
      arrived at an astounding result --
      he showed how to make Earley's run in linear time for LR-regular grammars.
      LR-regular is a vast class of grammars.
      It easily includes, as a proper subset, every class of grammar now
      in practical use -- regular expressions, PEG, recursive descent,
      the LALR on which yacc and bison are based, you name it.
      (For those into the math,
      LR-regular includes LR(k)
      for all &lt;i&gt;k&lt;/i&gt;,
      and therefore LL(k),
      also for all &lt;i&gt;k&lt;/i&gt;.)
      &lt;/p&gt;
      &lt;p&gt;
      Leo's mathematical approach did not address some nagging practical issues,
      foremost among them the handling of nullable rules and symbols.
      But ten years later in Canada,
      Aycock and Horspool focused on exactly these issues,
      and solved them.
      Aycock-Horspool
      seem to have been unaware of Leo's earlier result.
      The time complexity of the Aycock-Horspool
      algorithm was essentially that of
      Earley's original algorithm.
    &lt;/p&gt;
    &lt;p&gt;
      Because of Leo's work,
      for any grammar in any class currently in practical use,
      an Earley's parser could be fast.
      If only it could be combined with the approach
      of Aycock and Horspool, I realized,
      Leo's speeds could be available in an everyday programming tool.
    &lt;/p&gt;
    &lt;p&gt;
      In changing the Earley parse engine,
      Aycock-Horspool and Leo had branched off in different directions.
      It was not obvious that their approaches could be combined, much less how.
      And in fact, the combination of the two is not a simple algorithm.
      But it is fast,
      and the new Marpa parse engine makes full information
      about the state of the parse (rules recognized, symbols expected, etc.)
      available as it proceeds.
      This is very convenient for, among other things, error reporting.
    &lt;/p&gt;
    &lt;h3&gt;Eureka and all that&lt;/h3&gt;
    &lt;p&gt;The result is an algorithm which parses anything
      you can write in BNF and
      does it in times considered optimal in practice.
      Unlike recursive descent, you don't have to write out the parser --
      Marpa generates a parser for you, from the BNF.
      It's the easy, &quot;drop-in&quot; solution that the Go4 needed and did not have.
      A reworking of the Go4 example, with the missing parser added,
      is in
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/03/bnf_to_ast.html&quot;&gt;a
        previous blog post&lt;/a&gt;, and the code for the reworking is in
      &lt;a href=&quot;https://gist.github.com/jeffreykegler/5121769&quot;&gt;
        a Github gist&lt;/a&gt;.
    &lt;/p&gt;
    &lt;h3&gt;More about Marpa&lt;/h3&gt;
    &lt;p&gt;
      Marpa's latest version is
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2,
        which is available on CPAN&lt;/a&gt;.
      Recently, it has gained immensely in &quot;whipitupitude&quot; with
      &lt;a href=&quot;https://metacpan.org/module/JKEGL/Marpa-R2-2.048000/pod/Scanless/DSL.pod&quot;&gt;
        a new interface&lt;/a&gt;,
      which has tutorials
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/dsl_simpler2.html&quot;&gt;here
      &lt;/a&gt;
      and
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/announce_scanless.html&quot;&gt;
        here&lt;/a&gt;.
      Marpa has
      &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;a web page&lt;/a&gt;,
      and of course it is the focus of
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/&quot;&gt;
        my &quot;Ocean of Awareness&quot; blog&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      Comments on this post
      can be sent to the Marpa's Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;
    &lt;h3&gt;Notes&lt;/h3&gt;
    &lt;p&gt;&lt;a name=&quot;NOTE1&quot;&gt;Note 1&lt;/a&gt;:
      For example,
      &lt;a href=&quot;http://en.wikipedia.org/wiki/Domain-specific_language&quot;&gt;the Wikipedia article on DSL's&lt;/a&gt;;
      &lt;a href=&quot;http://www.faqs.org/docs/artu/minilanguageschapter.html&quot;&gt;Eric Raymond discussing mini-languages&lt;/a&gt;;
      &lt;a href=&quot;http://www.dmst.aueb.gr/dds/pubs/jrnl/2000-JSS-DSLPatterns/html/dslpat.html&quot;&gt;
        &quot;Notable Design Patterns for Domain-Specific Languages&quot;&lt;/a&gt;, Diomidis Spinellis; and
      &lt;a href=&quot;http://www.c2.com/cgi/wiki?DomainSpecificLanguage&quot;&gt;the c2.com wiki&lt;/a&gt;.
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>BNF to AST</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/03/bnf_to_ast.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      The latest version of
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;
      Marpa&lt;/a&gt; takes parsing &quot;whipitupitude&quot; one step further.
      You can now go straight from
      a BNF description of your language,
      and an input string,
      to an abstract syntax tree (AST).
    &lt;/p&gt;
    &lt;p&gt;To illustrate, I'll use an example from the
      Gang of Four's (Go4's) chapter
      on the Interpreter pattern.
      (It's pages 243-255 of the
      &lt;a href=&quot;http://en.wikipedia.org/wiki/Design_Patterns&quot;&gt;
      &lt;em&gt;Design Patterns&lt;/em&gt; book&lt;/a&gt;.)
      The Go4 knew of no easy general way to go from BNF to AST,
      so they dealt with that part of the interpreter problem
      by punting --
      they did not even try to parse the input string.
      Instead they constructed the BNF they'd just presented and
      constructed an AST directly in their code.
    &lt;/p&gt;
    &lt;p&gt;The reason the Go4 didn't know of an easy,
    generally-applicable way
      to parse their example was that
      there was none.
      Now there is.
      In this post, Marpa will take us
      quickly and easily
      from BNF to AST.
      (Full code for this post can
      be found in
      &lt;a href=&quot;https://gist.github.com/jeffreykegler/5121769&quot;&gt;a Github gist&lt;/a&gt;.)
    &lt;/p&gt;
    &lt;p&gt;
      The Go4's example was a simple boolean expression language,
      whose primary input was
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
true and x or y and not x
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;Here, in full, is the BNF for an slight elaboration of the
      Go4 example.
      It is written in the DSL for Marpa's Scanless interface (SLIF DSL),
      and includes specifications for building the AST.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
:default ::= action =&amp;gt; ::array

:start ::= &amp;lt;boolean expression&amp;gt;
&amp;lt;boolean expression&amp;gt; ::=
       &amp;lt;variable&amp;gt; bless =&amp;gt; variable
     | '1' bless =&amp;gt; constant
     | '0' bless =&amp;gt; constant
     | ('(') &amp;lt;boolean expression&amp;gt; (')') action =&amp;gt; ::first bless =&amp;gt; ::undef
    || ('not') &amp;lt;boolean expression&amp;gt; bless =&amp;gt; not
    || &amp;lt;boolean expression&amp;gt; ('and') &amp;lt;boolean expression&amp;gt; bless =&amp;gt; and
    || &amp;lt;boolean expression&amp;gt; ('or') &amp;lt;boolean expression&amp;gt; bless =&amp;gt; or

&amp;lt;variable&amp;gt; ~ [[:alpha:]] &amp;lt;zero or more word characters&amp;gt;
&amp;lt;zero or more word characters&amp;gt; ~ [\w]*

:discard ~ whitespace
whitespace ~ [\s]+
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;This syntax should be fairly transparent.
      In previous posts I've given
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/dsl_simpler2.html&quot;&gt;
        a tutorial&lt;/a&gt;,
      and a
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/announce_scanless.html&quot;&gt;a
        mini-tutorial&lt;/a&gt;.
      And of course, the interface is
      &lt;a href=&quot;https://metacpan.org/module/JKEGL/Marpa-R2-2.048000/pod/Scanless/DSL.pod&quot;&gt;
        documented&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;For those skimming, here are a few quick comments on less-obvious features.
      To guide Marpa in building the AST,
      the BNF statements have
      &lt;tt&gt;action&lt;/tt&gt;
      and
      &lt;tt&gt;bless&lt;/tt&gt;
      adverbs.
      The
      &lt;tt&gt;bless&lt;/tt&gt;
      adverbs indicate a Perl class into which the node should be
      blessed.
      This is convenient for using an object-oriented approach with the AST.
      The
      &lt;tt&gt;action&lt;/tt&gt;
      adverb tells Marpa how to build the nodes.
      &quot;&lt;tt&gt;action =&amp;gt; ::array&lt;/tt&gt;&quot; means the result of the rule should
      be an array containing its child nodes.
      &quot;&lt;tt&gt;action =&amp;gt; ::first&lt;/tt&gt;&quot; means the result of the rule should just be
      its first child.
      Many of the child symbols,
      especially literal strings of a structural nature,
      are in parentheses.
      This makes them invisible to
      the semantics.
    &lt;/p&gt;
    &lt;p&gt;A
      &lt;tt&gt;:default&lt;/tt&gt;
      pseudo-rule specifies the defaults -- in this case the
      &quot;&lt;tt&gt;action =&amp;gt; ::array&lt;/tt&gt;&quot; adverb setting.
      The
      &lt;tt&gt;:start&lt;/tt&gt;
      pseudo-rule specified the start symbol.
      The &lt;tt&gt;:discard&lt;/tt&gt; pseudo-rule
      indicates that whitespace is to be discarded.
    &lt;/p&gt;
    &lt;p&gt;The Go4 did not deal with precedence.
      In their example, the input string is fully parenthesized,
      even though its priorities are the standard ones.
      I've eliminated the parentheses, because
      the standard precedence is implemented in SLIF grammar.
      The double vertical bar (&quot;&lt;tt&gt;||&lt;/tt&gt;&quot;) is a &quot;loosen&quot; operator --
      an alternative after &quot;loosen&quot; operator will be
      at a looser precedence than the one before.
      Alternatives separated by a single bar are at the same precedence.
    &lt;/p&gt;&lt;h3&gt;Creating the AST&lt;/h3&gt;&lt;p&gt;
      Creating the AST is simple.
      First, we use Marpa to turn the above DSL for boolean expressions
      into a parser.
      (We'd saved the SLIF DSL source in the string
      &lt;tt&gt;$rules&lt;/tt&gt;.)
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
my $grammar = Marpa::R2::Scanless::G-&gt;new(
    {   bless_package =&gt; 'Boolean_Expression',
        source        =&gt; \$rules,
    }   
);  
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;Next we define a closure that uses
      &lt;tt&gt;$grammar&lt;/tt&gt;
      to turn
      BNF into AST's.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
sub bnf_to_ast {
    my ($bnf) = @_;
    my $recce = Marpa::R2::Scanless::R-&gt;new( { grammar =&gt; $grammar } );
    $recce-&gt;read( \$bnf );
    my $value_ref = $recce-&gt;value();
    if ( not defined $value_ref ) {
        die &quot;No parse for $bnf&quot;;
    }
    return ${$value_ref};
} ## end sub bnf_to_ast
&lt;/pre&gt;
    &lt;/blockquote&gt;&lt;p&gt;
Where &lt;tt&gt;$bnf&lt;/tt&gt; is our input string,
we run it as follows:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
my $ast1 = bnf_to_ast($bnf);
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;The AST&lt;/h3&gt;
    &lt;p&gt;If we use Data::Dumper to examine the AST,
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
say Data::Dumper::Dumper($ast1) if $verbose_flag;
&lt;/pre&gt;
    &lt;/blockquote&gt;&lt;p&gt;
      we see this:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
$VAR1 = bless( [
                 bless( [
                          bless( [
                                   'true'
                                 ], 'Boolean_Expression::variable' ),
                          bless( [
                                   'x'
                                 ], 'Boolean_Expression::variable' )
                        ], 'Boolean_Expression::and' ),
                 bless( [
                          bless( [
                                   'y'
                                 ], 'Boolean_Expression::variable' ),
                          bless( [
                                   bless( [
                                            'x'
                                          ], 'Boolean_Expression::variable' )
                                 ], 'Boolean_Expression::not' )
                        ], 'Boolean_Expression::and' )
               ], 'Boolean_Expression::or' );
&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;h3&gt;Processing the AST&lt;/h3&gt;
    &lt;p&gt;In their example,
    the Go4 processed their AST in several ways:
    straight evaluation, copying,
      and substitution of the occurrences of a variable in one boolean expression
      by another boolean expression.
      It is obvious that the AST above is the computational
      equivalent of the Go4's AST,
      but for the sake of completeness I carry out the same operations
      &lt;a href=&quot;https://gist.github.com/jeffreykegler/5121769&quot;&gt;in the Github gist&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      AST creation via Marpa's SLIF is self-hosting --
      the SLIF DSL is parsed into an AST,
      and a parser created by interpreting the AST.
      The Marpa SLIF DSL source file in this post,
      that describes boolean expressions,
      was itself turned into an AST on its way to becoming a parser
      that turns boolean expressions into AST's.
    &lt;/p&gt;&lt;h3&gt;Comments&lt;/h3&gt;
    &lt;p&gt;
      Comments on this post
      can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>A language for writing languages</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/language_for_languages.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      &lt;a href=&quot;https://metacpan.org/release/Marpa-R2&quot;&gt;
      Marpa::R2&lt;/a&gt;'s
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/announce_scanless.html&quot;&gt;
      Scanless interface&lt;/a&gt;
      is not yet two weeks old,
      but already there are completed applications.
      Significantly, two of them are for work.
      &lt;h3&gt;A JSON Parser&lt;/h3&gt;
      &lt;p&gt;The non-work-related application is
      &lt;a href=&quot;https://gist.github.com/4447349&quot;&gt;
      a JSON parser&lt;/a&gt;.
      Given what it does,
      it easily could have been work-related.
      (It's been available for a few days as a gist,
      so it may well be in production use somewhere.)
      It was written by Peter Stuifzand,
      runs 185 lines
      and took him less than 30 minutes to write.
      Peter reports that it was a matter of
      typing in the grammar,
      and adding a few Perl functions to provide the semantics.
      &lt;p&gt;
      There are, of course, other JSON parsers out there,
      many of which run faster.
      These, however, took weeks to write.
      If you are, for example,
      thinking of
      &lt;a href=&quot;http://bolinfest.com/essays/json.html&quot;&gt;
      extending JSON&lt;/a&gt;,
      and development time is a major consideration,
      the Marpa-based solution will be attractive.
      &lt;h3&gt;Printer escape codes&lt;/h3&gt;
      Peter also did
      &lt;a href=&quot;https://groups.google.com/d/msg/marpa-parser/n4ouLW0e6P8/vdrku9fczZEJ&quot;&gt;
      a Marpa-based language for work&lt;/a&gt; --
      a solution to the problem of printer escape codes.
      For those unfamilar, a printer's special features can often be invoked
      by &quot;escape sequences&quot; --
      byte sequences which control things like cursor motion, color, character sets,
      graphics, etc., etc.
      It's nice to invoke them with a set of well-named functions.
      &lt;p&gt;Escape sequences are usually repetitive,
      and when complex, are usually not complex in an interesting way.
      They can be programmed with regex or eval hacks.
      But this time
      Peter chose to write 
      a mini-language that specifies 
      escape sequences,
      and to use Marpa to
      compile the mini-language into Perl code.
      He was done in a hour.
      &lt;h3&gt;A log file query language&lt;/h3&gt;
      &lt;p&gt;Meanwhile, an interesting and adventurous language effort
      was underway on
      the other side of the Atlantic, where Paul Bennett,
      faced with analyzing lots of nginx log files,
      &lt;a href=&quot;https://plus.google.com/u/0/110360907592575381901/posts/XdTPRHvbA8w#110360907592575381901/posts/XdTPRHvbA8w&quot;&gt;
      decided a powerful custom log query language was
      the best way to address his issue&lt;/a&gt;.
      Paul needed to design and specify his language from scratch.
      Paul was also facing a learning curve,
      but he read the gist for a Scanless interface example,
      and apparently was able to teach himself quickly from there.
      (He doesn't say, but it might have been the one for
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/dsl_simpler2.html&quot;&gt;
      this post&lt;/a&gt;.)
      &lt;p&gt;Like Peter's escape sequence language,
      Paul's log query language program compiles to Perl.
      Its writing and debugging
      were spread out over 3 days.
      Paul reports that his language is on the job already,
      but that
      it needs some clean-up before going onto CPAN.
      &lt;p&gt;
      The snippets Paul shows are enticing.
      The language seems to include 
      strings, integers and timestamps as supported types;
      regexes;
      a full set of comparison and boolean operators;
      and helpful new &quot;any&quot;, &quot;between&quot; and &quot;one&quot; operators.
      Pretty good for three days.
      A lot of nasty problems snuggled away
      in log files may find their
      hiding places are not nearly as safe 
      as they have been able to expect.
    &lt;h3&gt;Where to start&lt;/h3&gt;
    &lt;p&gt;If you're interested in learning more about Marpa's Scanless
    interface, there is
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/dsl_simpler2.html&quot;&gt;
      a tutorial&lt;/a&gt;.
      Additionally,
      the announcement of the Scanless interface contained
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/announce_scanless.html&quot;&gt;a
      mini-tutorial&lt;/a&gt;.
    &lt;h3&gt;Comments&lt;/h3&gt;
    &lt;p&gt;
      Comments on this post
      can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  <item>
    <title>Making DSL's even simpler</title>
    <link>http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2013/01/dsl_simpler2.html</link>
    <description>  &lt;p&gt;
      &lt;!--
      marpa_r2_html_fmt --no-added-tag-comment --no-ws-ok-after-start-tag
      --&gt;
      &lt;a href=&quot;http://jeffreykegler.github.com/Ocean-of-Awareness-blog/individual/2012/dsl.html&quot;&gt;
        In a previous post&lt;/a&gt;, I described a method of writing
	powerful domain-specific languages (DSLs),
	one that was simpler and faster
	than previous approaches.
      This post takes things significantly further.
      &lt;p&gt;
      The approach described in the previous post was not itself directly
      DSL-based,
      and it required the programmer to write a separate lexer.
      This post uses
      &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2&lt;/a&gt;'s
      new Scanless interface.
      &lt;a href=&quot;https://metacpan.org/module/JKEGL/Marpa-R2-2.040000/pod/Scanless.pod&quot;&gt;
      The Scanless interface&lt;/a&gt;
      is a DSL for writing DSL's
      and it incorporates the specification of the lexer into
      the language description.
    &lt;/p&gt;
    &lt;p&gt;
      When it comes to dealing with a programming problem,
      no tool is as powerful and flexible as
      a custom language targeted to the problem domain.
      But writing a domain specific language (DSL) is among the
      least used approaches,
      and for what has been a very good reason --
      in the past,
      DSL's have been very difficult to write.
    &lt;/p&gt;
    &lt;p&gt;This post takes a tutorial approach.
      It does
      &lt;b&gt;not&lt;/b&gt;
      assume knowledge of the previous tutorials
      on this blog.
    &lt;/p&gt;&lt;p&gt;
      The full code for this post is in
      &lt;a href=&quot;https://gist.github.com/4480523&quot;&gt;
        a Github gist&lt;/a&gt;.
      Our example DSL is a calculator,
      one whose features
      are chosen for the purpose of illustration.
      It is not a &quot;toy&quot; example -- its error reporting
      is quite good and it has a test suite.
      Nonetheless, it is both short and easy to read,
      capable of being
      written quickly and maintained and extended easily.
    &lt;/p&gt;
    &lt;h3&gt;The Grammar&lt;/h3&gt;
    &lt;p&gt;
      The grammar for our calculator
      divides naturally into two parts.  Here is the first:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
:start ::= script
script ::= expression
script ::= script ';' expression action =&amp;gt; do_arg2
&amp;lt;reduce op&amp;gt; ::= '+' | '-' | '/' | '*'
expression ::=
     number
   | variable action =&amp;gt; do_is_var
   | '(' expression ')' assoc =&amp;gt; group action =&amp;gt; do_arg1
  || '-' expression action =&amp;gt; do_negate
  || expression '^' expression action =&amp;gt; do_caret assoc =&amp;gt; right
  || expression '*' expression action =&amp;gt; do_star
   | expression '/' expression action =&amp;gt; do_slash
  || expression '+' expression action =&amp;gt; do_plus
   | expression '-' expression action =&amp;gt; do_minus
  || expression ',' expression action =&amp;gt; do_array
  || &amp;lt;reduce op&amp;gt; 'reduce' expression action =&amp;gt; do_reduce
  || variable '=' expression action =&amp;gt; do_set_var
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;The format of the grammar is documented
      &lt;a href=&quot;https://metacpan.org/module/JKEGL/Marpa-R2-2.040000/pod/Scanless.pod&quot;&gt;
        here&lt;/a&gt;.
      It consists of a series of rules.
      Each rule has a
      left hand side (LHS)
      and a right hand side (RHS),
      which are separated by a rule operator.
      In the rules above, the rule operator is the BNF operator (&lt;tt&gt;::=&lt;/tt&gt;).
      &lt;p&gt;
      The first rule is a pseudo-rule -- its LHS is the pseudo-symbol
      &lt;tt&gt;:start&lt;/tt&gt;,
      and indicates that
      &lt;tt&gt;script&lt;/tt&gt;
      is the grammar's start symbol.
      The next two rules indicate that
      &lt;tt&gt;script&lt;/tt&gt;
      is a series of one
      or more
      &lt;tt&gt;expression&lt;/tt&gt;'s, separated by a semicolon.
    &lt;/p&gt;&lt;p&gt;
      Rules can have action &quot;adverbs&quot;
      to describe the semantics.
      For example, the adverb &quot;&lt;tt&gt;action =&amp;gt; do_args&lt;/tt&gt;&quot;
      says that the semantics for
      the preceding RHS are implemented by a Perl closure named
      &lt;tt&gt;do_args&lt;/tt&gt;.
    &lt;/p&gt;&lt;p&gt;The rule for
      &lt;tt&gt;&amp;lt;reduce op&amp;gt;&lt;/tt&gt;
      introduces two new features: symbols names
      in angle brackets, and alternatives,
      separated by a veritcal bar, (&quot;&lt;tt&gt;|&lt;/tt&gt;&quot;).
    &lt;/p&gt;
    &lt;p&gt;The last and longest rule, defined an
      &lt;tt&gt;expression&lt;/tt&gt;,
      is a precedence rule.
      It is a series of alternatives, some separated by
      a single vertical bar,
      and others separated by a double vertical bar (&quot;&lt;tt&gt;||&lt;/tt&gt;&quot;).
      The double vertical bar indicates that the alternatives after it
      are at a looser (&quot;lower&quot;) precedence than the alternatives before it.
      The single vertical bar separates alternatives at the same precedence level.
    &lt;/p&gt;&lt;p&gt;
      While Marpa's Scanless interface allows lexical and structural rules
      to be intermixed,
      it is usually convenient to have the lexical rules come after
      the structural rules:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
number ~ [\d]+
variable ~ [\w]+
:discard ~ whitespace
whitespace ~ [\s]+
# allow comments
:discard ~ &amp;lt;hash comment&amp;gt;
&amp;lt;hash comment&amp;gt; ~ &amp;lt;terminated hash comment&amp;gt; | &amp;lt;unterminated
   final hash comment&amp;gt;
&amp;lt;terminated hash comment&amp;gt; ~ '#' &amp;lt;hash comment body&amp;gt; &amp;lt;vertical space char&amp;gt;
&amp;lt;unterminated final hash comment&amp;gt; ~ '#' &amp;lt;hash comment body&amp;gt;
&amp;lt;hash comment body&amp;gt; ~ &amp;lt;hash comment char&amp;gt;*
&amp;lt;vertical space char&amp;gt; ~ [\x{A}\x{B}\x{C}\x{D}\x{2028}\x{2029}]
&amp;lt;hash comment char&amp;gt; ~ [^\x{A}\x{B}\x{C}\x{D}\x{2028}\x{2029}]
END_OF_GRAMMAR
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;
      Rules in this second set of rules have
      the same syntax as rules in the first set,
      but instead of the BNF operator (&lt;tt&gt;::=&lt;/tt&gt;),
      they have a match operator (&lt;tt&gt;~&lt;/tt&gt;) separating the LHS and RHS.
      The BNF operator can be seen as telling Marpa, &quot;When it comes to whitespace and comments,
      do what I
      &lt;b&gt;mean&lt;/b&gt;&quot;.
      The match operator tells Marpa to &quot;Do exactly what I
      &lt;b&gt;say&lt;/b&gt;
      on a literal,
      character-by-character basis.&quot;
    &lt;/p&gt;&lt;p&gt;
      The first two lines indicate how
      &lt;tt&gt;number&lt;/tt&gt;'s and
      &lt;tt&gt;variable&lt;/tt&gt;'s
      are formed.
      The square bracketed character classes accept anything acceptable to Perl.
      &lt;tt&gt;:discard&lt;/tt&gt;
      is another pseudo-symbol -- any lexeme recognized as a
      &lt;tt&gt;:discard&lt;/tt&gt;
      symbol is thrown away.
    &lt;/p&gt;&lt;p&gt;
      This is how whitespace and comments are dealt with.
      Note that our calculator recognizes &quot;hash comments&quot;,
      and takes some care to do the right thing even when the hash comment is at
      the end of a string which does not end in vertical whitespace.
      It is interesting to compare the representation of hash comments here with
      the usual regular expression notation.
      Regular expressions are much more concise, but the BNF-ish form
      can be easier to read.
      In this example,
      long descriptive angle-bracketed symbol names
      save the reader the trouble of
      puzzling out the purpose of some of the more obscure cases.
    &lt;/p&gt;
    &lt;p&gt;
      Now that we have defined the grammar, we need to pre-process it:
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
      my $grammar = Marpa::R2::Scanless::G-&amp;gt;new(
	{ action_object  =&amp;gt; 'My_Actions',
	  default_action =&amp;gt; 'do_arg0',
	  source =&amp;gt; \$rules,
	}
      );
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;
      The
      &lt;tt&gt;action_object&lt;/tt&gt;
      named argument specifies a package to implement
      the semantics -- Marpa will look up the names of the Perl closures in that
      package.
      The
      &lt;tt&gt;default_action&lt;/tt&gt;
      named argument specified the action name for RHS's
      which do not explicitly specify one with an
      &lt;tt&gt;action&lt;/tt&gt;
      adverb.
    &lt;/p&gt;
    &lt;h3&gt;Running a parse&lt;/h3&gt;
    &lt;p&gt;
      The &lt;tt&gt;calculate()&lt;/tt&gt; closure uses our grammar to parse a string.
    &lt;/p&gt;
    &lt;blockquote&gt;
      &lt;pre&gt;
sub calculate {
    my ($p_string) = @_;

    my $recce = Marpa::R2::Scanless::R-&amp;gt;new( { grammar =&amp;gt; $grammar } );

    my $self = bless { grammar =&amp;gt; $grammar }, 'My_Actions';
    $self-&amp;gt;{recce}        = $recce;
    $self-&amp;gt;{symbol_table} = {};
    local $My_Actions::SELF = $self;

    if ( not defined eval { $recce-&amp;gt;read($p_string); 1 } ) {

        # Add last expression found, and rethrow
        my $eval_error = $EVAL_ERROR;
        chomp $eval_error;
        die $self-&amp;gt;show_last_expression(), &quot;\n&quot;, $eval_error, &quot;\n&quot;;
    } ## end if ( not defined eval { $recce-&amp;gt;read($p_string); 1 })
    my $value_ref = $recce-&amp;gt;value();
    if ( not defined $value_ref ) {
        die $self-&amp;gt;show_last_expression(), &quot;\n&quot;,
            &quot;No parse was found, after reading the entire input\n&quot;;
    }
    return ${$value_ref}, $self-&amp;gt;{symbol_table};

} ## end sub calculate

&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;p&gt;Walking through the code,
    we first create a recognizer (&quot;recce&quot; for short) from our grammar.
      Next, we define a parse object named &quot;&lt;tt&gt;$self&lt;/tt&gt;&quot;.
      (Object enthusiasts will, I hope, forgive a certain awkwardness at this stage.)
    &lt;p&gt;
    Next, we call the
      &lt;tt&gt;read()&lt;/tt&gt;
      method on the recognizer with our string.
      We then check the result of the &lt;tt&gt;read()&lt;/tt&gt; method for errors.
      &lt;p&gt;
      Finally, we return our results.
      This calculator allows variables, whose values it keeps in a symbol table.
      Since these can be important side effects, the symbol table is returned
      as part of the results.
    &lt;/p&gt;
    &lt;h3&gt;Dealing with errors&lt;/h3&gt;
    &lt;p&gt;This calculator has error reporting that compares favorably with
      production languages.
      (Unfortunately, these often do not set the bar very high.)
      The methods of the Scanless interface return diagnostics that
      pinpoint where things
      went wrong from the technical point of view,
      and what the problem was from the technical point of view.
      As a diagnostic, this is often adequate, but not always.
      Marpa's diagnostics have 100% technical accuracy, but
      the parsing may have ceased to reflect the programmer's intent before
      there is a technical problem.
    &lt;/p&gt;
    &lt;p&gt;To help the programmer sync his intent to what Marpa is seeing,
    when there is a problem,
      this calculator reports to the user the text for the last
      &lt;tt&gt;expression&lt;/tt&gt;
      that was successfully
      recognized.
      Here's the code that finds it:
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
sub show_last_expression {
    my ($self) = @_;
    my $recce = $self-&amp;gt;{recce};
    my ( $start, $end ) = $recce-&amp;gt;last_completed_range('expression');
    return 'No expression was successfully parsed' if not defined $start;
    my $last_expression = $recce-&amp;gt;range_to_string( $start, $end );
    return &quot;Last expression successfully parsed was: $last_expression&quot;;
} ## end sub show_last_expression
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;h3&gt;The semantics&lt;/h3&gt;
    &lt;p&gt;Here is a snippet of the semantics, with a few of the simpler semantic closures.
    &lt;/p&gt;&lt;blockquote&gt;
      &lt;pre&gt;
package My_Actions;
our $SELF;
sub new { return $SELF }
sub do_set_var {
    my ( $self, $var, undef, $value ) = @_;
    return $self-&amp;gt;{symbol_table}-&amp;gt;{$var} = $value;
}
sub do_negate { return -$_[2]; }
sub do_arg0 { return $_[1]; }
sub do_arg1 { return $_[2]; }
sub do_arg2 { return $_[3]; }
&lt;/pre&gt;&lt;/blockquote&gt;
    &lt;h3&gt;About this example&lt;/h3&gt;
    &lt;p&gt;Full code for this example can be found in 
      &lt;a href=&quot;https://gist.github.com/4480523&quot;&gt;a Github gist&lt;/a&gt;.
      Semantics, legalese, a test suite and other packaging
      bring its total length to not quite 300 lines.
    It uses the latest indexed CPAN release
    of &lt;a href=&quot;https://metacpan.org/module/Marpa::R2&quot;&gt;Marpa::R2&lt;/a&gt;.
    Marpa also has &lt;a href=&quot;http://jeffreykegler.github.com/Marpa-web-site/&quot;&gt;
    a web page&lt;/a&gt;.
    &lt;h3&gt;Comments&lt;/h3&gt;
    &lt;p&gt;
      Comments on this post
      can be sent to the Marpa Google Group:
      &lt;code&gt;marpa-parser@googlegroups.com&lt;/code&gt;
    &lt;/p&gt;</description>
  </item>
  </channel>
</rss>
